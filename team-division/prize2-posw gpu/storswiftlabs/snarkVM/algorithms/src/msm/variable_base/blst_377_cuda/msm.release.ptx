//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-29373293
// Cuda compilation tools, release 11.2, V11.2.67
// Based on NVVM 7.0.1
//

.version 7.2
.target sm_52
.address_size 64

	// .globl	msm4_evaluate
.extern .func _Z35blst_p1_add_affines_into_projectiveP7blst_p1PK14blst_p1_affineS3_
(
	.param .b64 _Z35blst_p1_add_affines_into_projectiveP7blst_p1PK14blst_p1_affineS3__param_0,
	.param .b64 _Z35blst_p1_add_affines_into_projectiveP7blst_p1PK14blst_p1_affineS3__param_1,
	.param .b64 _Z35blst_p1_add_affines_into_projectiveP7blst_p1PK14blst_p1_affineS3__param_2
)
;
.extern .func _Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2_
(
	.param .b64 _Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2__param_0,
	.param .b64 _Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2__param_1,
	.param .b64 _Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2__param_2
)
;
.extern .func _Z32blst_p1_add_affine_to_projectiveP7blst_p1PKS_PK14blst_p1_affine
(
	.param .b64 _Z32blst_p1_add_affine_to_projectiveP7blst_p1PKS_PK14blst_p1_affine_param_0,
	.param .b64 _Z32blst_p1_add_affine_to_projectiveP7blst_p1PKS_PK14blst_p1_affine_param_1,
	.param .b64 _Z32blst_p1_add_affine_to_projectiveP7blst_p1PKS_PK14blst_p1_affine_param_2
)
;
.global .align 8 .b8 __nv_static_52__39_tmpxft_00002134_00000000_11_msm_cpp1_ii_a96a0d9d_BLS12_377_P[48] = {1, 0, 0, 0, 0, 192, 8, 133, 0, 0, 0, 48, 68, 93, 11, 23, 0, 72, 9, 186, 47, 98, 243, 30, 143, 19, 245, 0, 243, 217, 34, 26, 59, 73, 161, 108, 192, 5, 59, 198, 234, 16, 197, 23, 70, 58, 174, 1};
.global .align 8 .b8 __nv_static_52__39_tmpxft_00002134_00000000_11_msm_cpp1_ii_a96a0d9d_BLS12_377_ZERO[48];
.global .align 8 .b8 __nv_static_52__39_tmpxft_00002134_00000000_11_msm_cpp1_ii_a96a0d9d_BLS12_377_ONE[48] = {104, 255, 255, 255, 255, 255, 205, 2, 177, 255, 255, 127, 131, 159, 64, 81, 242, 63, 125, 138, 169, 179, 125, 159, 5, 99, 124, 110, 183, 151, 78, 123, 232, 132, 60, 128, 191, 149, 244, 76, 154, 244, 253, 226, 97, 102, 141, 0};
.global .align 8 .b8 __nv_static_52__39_tmpxft_00002134_00000000_11_msm_cpp1_ii_a96a0d9d_BLS12_377_R2[48] = {34, 205, 0, 148, 108, 104, 134, 183, 177, 49, 4, 176, 170, 252, 41, 3, 109, 180, 214, 98, 17, 241, 165, 34, 172, 195, 125, 130, 3, 125, 223, 191, 249, 11, 121, 65, 240, 146, 126, 131, 136, 75, 145, 30, 203, 252, 109, 0};
.global .align 8 .u64 __nv_static_52__39_tmpxft_00002134_00000000_11_msm_cpp1_ii_a96a0d9d_BLS12_377_p0 = -8860621160618917889;
.global .align 8 .u64 __nv_static_52__39_tmpxft_00002134_00000000_11_msm_cpp1_ii_a96a0d9d_BLS12_377_FR_INV = 725501752471715839;
.global .align 8 .b8 __nv_static_52__39_tmpxft_00002134_00000000_11_msm_cpp1_ii_a96a0d9d_BLS12_377_FR_MODULUS[32] = {1, 0, 0, 0, 0, 128, 17, 10, 1, 0, 0, 208, 254, 118, 170, 89, 1, 176, 55, 92, 30, 77, 180, 96, 86, 165, 44, 154, 94, 101, 171, 18};
.global .align 8 .b8 __nv_static_52__39_tmpxft_00002134_00000000_11_msm_cpp1_ii_a96a0d9d_BLS12_377_FR_ONE[32] = {243, 255, 255, 255, 255, 127, 28, 125, 242, 255, 255, 111, 15, 245, 87, 114, 238, 15, 44, 81, 117, 21, 216, 22, 157, 154, 187, 43, 50, 218, 75, 13};
// _ZZ10msm6_pixelE11scalarCache has been demoted
.extern .global .align 8 .b8 BLS12_377_ZERO_PROJECTIVE[144];
.extern .shared .align 8 .b8 sdata[];

.visible .entry msm4_evaluate(
	.param .u64 msm4_evaluate_param_0,
	.param .u64 msm4_evaluate_param_1,
	.param .u64 msm4_evaluate_param_2,
	.param .u64 msm4_evaluate_param_3
)
{
	.local .align 16 .b8 	__local_depot0[144];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<20>;
	.reg .b32 	%r<19>;
	.reg .b64 	%rd<302>;


	mov.u64 	%SPL, __local_depot0;
	ld.param.u64 	%rd72, [msm4_evaluate_param_1];
	add.u64 	%rd1, %SPL, 0;
	add.u64 	%rd2, %SPL, 96;
	mov.u32 	%r1, %ctaid.x;
	cvt.u64.u32 	%rd3, %r1;
	mov.u32 	%r4, 0;
	ld.param.u64 	%rd75, [msm4_evaluate_param_2];
	st.local.v2.u64 	[%rd1], {%rd75, %rd75};
	ld.param.u64 	%rd76, [msm4_evaluate_param_3];
	add.s64 	%rd77, %rd76, 1048576;
	st.local.v2.u64 	[%rd1+16], {%rd76, %rd77};
	st.local.v2.u64 	[%rd1+32], {%rd76, %rd77};
	st.local.v2.u64 	[%rd1+48], {%rd76, %rd77};
	add.u64 	%rd79, %SPL, 64;
	mov.u32 	%r5, 32767;
	mov.u32 	%r6, 32768;
	st.local.v4.u32 	[%rd79], {%r6, %r5, %r6, %r5};
	st.local.v4.u32 	[%rd79+16], {%r6, %r5, %r6, %r5};
	st.local.u32 	[%rd2], %r4;
	st.local.u32 	[%rd2+4], %r6;
	mov.u32 	%r7, 65535;
	st.local.u32 	[%rd2+8], %r7;
	mov.u32 	%r8, 98303;
	st.local.u32 	[%rd2+12], %r8;
	mov.u32 	%r9, 131070;
	st.local.u32 	[%rd2+16], %r9;
	mov.u32 	%r10, 163838;
	st.local.u32 	[%rd2+20], %r10;
	mov.u32 	%r11, 196605;
	st.local.u32 	[%rd2+24], %r11;
	mov.u32 	%r12, 229373;
	st.local.u32 	[%rd2+28], %r12;
	mov.u32 	%r13, 262140;
	st.local.u32 	[%rd2+32], %r13;
	mul.wide.u32 	%rd80, %r1, 4;
	add.s64 	%rd81, %rd79, %rd80;
	ld.local.u32 	%r2, [%rd81];
	mov.u32 	%r3, %tid.x;
	shl.b32 	%r14, %r3, 7;
	cvt.u64.u32 	%rd285, %r14;
	setp.ge.u32 	%p1, %r14, %r2;
	@%p1 bra 	LBB0_19;

	shl.b64 	%rd87, %rd3, 2;
	add.s64 	%rd88, %rd2, %rd87;
	ld.local.u32 	%rd89, [%rd88];
	mov.u64 	%rd298, 0;
	shl.b64 	%rd90, %rd3, 3;
	add.s64 	%rd91, %rd1, %rd90;
	ld.local.u64 	%rd92, [%rd91];
	cvt.u64.u32 	%rd93, %r2;
	add.s64 	%rd94, %rd285, 128;
	min.u64 	%rd5, %rd94, %rd93;
	shl.b64 	%rd95, %rd285, 5;
	add.s64 	%rd96, %rd92, %rd95;
	add.s64 	%rd272, %rd96, 16;
	add.s64 	%rd97, %rd89, %rd285;
	cvta.to.global.u64 	%rd98, %rd72;
	shl.b64 	%rd99, %rd97, 5;
	add.s64 	%rd100, %rd98, %rd99;
	add.s64 	%rd271, %rd100, 16;
	mov.u64 	%rd299, %rd298;
	mov.u64 	%rd300, %rd298;
	mov.u64 	%rd276, %rd298;

LBB0_2:
	mov.u64 	%rd286, 0;
	ld.global.u64 	%rd109, [%rd271+-16];
	ld.global.u64 	%rd110, [%rd271+-8];
	ld.global.u64 	%rd111, [%rd271];
	ld.global.u64 	%rd112, [%rd271+8];
	ld.u64 	%rd113, [%rd272+-16];
	ld.u64 	%rd114, [%rd272+-8];
	ld.u64 	%rd115, [%rd272];
	ld.u64 	%rd116, [%rd272+8];
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 nc;
	.reg .u64 t;
	mad.lo.cc.u64  %rd297, %rd109, %rd113, 0;
	madc.hi.cc.u64  c, %rd109, %rd113, 0;
	madc.lo.cc.u64 %rd296, %rd109, %rd114, c;
	madc.hi.cc.u64  c, %rd109, %rd114, 0;
	madc.lo.cc.u64 %rd295, %rd109, %rd115, c;
	madc.hi.cc.u64  c, %rd109, %rd115, 0;
	madc.lo.cc.u64 %rd294, %rd109, %rd116, c;
	madc.hi.u64    %rd293, %rd109, %rd116, 0;
	mad.lo.cc.u64  %rd296, %rd110, %rd113, %rd296;
	madc.hi.cc.u64  c, %rd110, %rd113, 0;
	addc.cc.u64     t, %rd295, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd295, %rd110, %rd114, t;
	madc.hi.cc.u64  c, %rd110, %rd114, nc;
	addc.cc.u64     t, %rd294, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd294, %rd110, %rd115, t;
	madc.hi.cc.u64  c, %rd110, %rd115, nc;
	addc.cc.u64     t, %rd293, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd293, %rd110, %rd116, t;
	madc.hi.u64    %rd292, %rd110, %rd116, nc;
	mad.lo.cc.u64  %rd295, %rd111, %rd113, %rd295;
	madc.hi.cc.u64  c, %rd111, %rd113, 0;
	addc.cc.u64     t, %rd294, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd294, %rd111, %rd114, t;
	madc.hi.cc.u64  c, %rd111, %rd114, nc;
	addc.cc.u64     t, %rd293, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd293, %rd111, %rd115, t;
	madc.hi.cc.u64  c, %rd111, %rd115, nc;
	addc.cc.u64     t, %rd292, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd292, %rd111, %rd116, t;
	madc.hi.u64    %rd291, %rd111, %rd116, nc;
	mad.lo.cc.u64  %rd294, %rd112, %rd113, %rd294;
	madc.hi.cc.u64  c, %rd112, %rd113, 0;
	addc.cc.u64     t, %rd293, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd293, %rd112, %rd114, t;
	madc.hi.cc.u64  c, %rd112, %rd114, nc;
	addc.cc.u64     t, %rd292, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd292, %rd112, %rd115, t;
	madc.hi.cc.u64  c, %rd112, %rd115, nc;
	addc.cc.u64     t, %rd291, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd291, %rd112, %rd116, t;
	madc.hi.u64    %rd290, %rd112, %rd116, nc;
	}
	// end inline asm
	or.b64  	%rd129, %rd297, %rd296;
	or.b64  	%rd130, %rd129, %rd295;
	or.b64  	%rd131, %rd130, %rd294;
	or.b64  	%rd132, %rd131, %rd293;
	or.b64  	%rd133, %rd132, %rd292;
	or.b64  	%rd134, %rd133, %rd291;
	or.b64  	%rd135, %rd134, %rd290;
	setp.eq.s64 	%p2, %rd135, 0;
	mov.u64 	%rd287, %rd286;
	mov.u64 	%rd288, %rd286;
	mov.u64 	%rd289, %rd286;
	@%p2 bra 	LBB0_10;

	mul.lo.s64 	%rd146, %rd297, 725501752471715839;
	mov.u64 	%rd192, 725501752471715841;
	mov.u64 	%rd193, 6461107452199829505;
	mov.u64 	%rd194, 6968279316240510977;
	mov.u64 	%rd195, 1345280370688173398;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd146, %rd192, %rd297;
	madc.hi.cc.u64 c, %rd146, %rd192, 0;
	addc.cc.u64 t, %rd296, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd296, %rd146, %rd193, t;
	madc.hi.cc.u64 c, %rd146, %rd193, nc;
	addc.cc.u64 t, %rd295, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd295, %rd146, %rd194, t;
	madc.hi.cc.u64 c, %rd146, %rd194, nc;
	addc.cc.u64 t, %rd294, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd294, %rd146, %rd195, t;
	madc.hi.cc.u64 c, %rd146, %rd195, nc;
	addc.cc.u64 %rd293, %rd293, c;
	addc.u64 %rd174, 0, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd162, %rd296, 725501752471715839;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd162, %rd192, %rd296;
	madc.hi.cc.u64 c, %rd162, %rd192, 0;
	addc.cc.u64 t, %rd295, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd295, %rd162, %rd193, t;
	madc.hi.cc.u64 c, %rd162, %rd193, nc;
	addc.cc.u64 t, %rd294, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd294, %rd162, %rd194, t;
	madc.hi.cc.u64 c, %rd162, %rd194, nc;
	addc.cc.u64 t, %rd293, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd293, %rd162, %rd195, t;
	madc.hi.cc.u64 c, %rd162, %rd195, nc;
	addc.cc.u64 c, c, %rd174;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd292, %rd292, c;
	addc.u64 %rd174, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd179, %rd295, 725501752471715839;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd179, %rd192, %rd295;
	madc.hi.cc.u64 c, %rd179, %rd192, 0;
	addc.cc.u64 t, %rd294, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd294, %rd179, %rd193, t;
	madc.hi.cc.u64 c, %rd179, %rd193, nc;
	addc.cc.u64 t, %rd293, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd293, %rd179, %rd194, t;
	madc.hi.cc.u64 c, %rd179, %rd194, nc;
	addc.cc.u64 t, %rd292, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd292, %rd179, %rd195, t;
	madc.hi.cc.u64 c, %rd179, %rd195, nc;
	addc.cc.u64 c, c, %rd174;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd291, %rd291, c;
	addc.u64 %rd174, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd196, %rd294, 725501752471715839;
	mov.u64 	%rd188, %rd292;
	mov.u64 	%rd190, %rd290;
	mov.u64 	%rd189, %rd291;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd196, %rd192, %rd294;
	madc.hi.cc.u64 c, %rd196, %rd192, 0;
	addc.cc.u64 t, %rd293, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd293, %rd196, %rd193, t;
	madc.hi.cc.u64 c, %rd196, %rd193, nc;
	addc.cc.u64 t, %rd188, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd188, %rd196, %rd194, t;
	madc.hi.cc.u64 c, %rd196, %rd194, nc;
	addc.cc.u64 t, %rd189, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd189, %rd196, %rd195, t;
	madc.hi.cc.u64 c, %rd196, %rd195, nc;
	addc.cc.u64 c, c, %rd174;
	addc.cc.u64 %rd190, %rd190, c;
	}
	// end inline asm
	setp.lt.u64 	%p3, %rd190, 1345280370688173398;
	mov.u64 	%rd286, %rd190;
	mov.u64 	%rd287, %rd189;
	mov.u64 	%rd288, %rd188;
	mov.u64 	%rd289, %rd293;
	mov.u64 	%rd290, %rd190;
	mov.u64 	%rd291, %rd189;
	mov.u64 	%rd292, %rd188;
	@%p3 bra 	LBB0_10;

	setp.ne.s64 	%p4, %rd190, 1345280370688173398;
	@%p4 bra 	LBB0_9;

	mov.u64 	%rd286, 1345280370688173398;
	setp.lt.u64 	%p5, %rd189, 6968279316240510977;
	mov.u64 	%rd287, %rd189;
	mov.u64 	%rd288, %rd188;
	mov.u64 	%rd289, %rd293;
	mov.u64 	%rd290, %rd286;
	mov.u64 	%rd291, %rd189;
	mov.u64 	%rd292, %rd188;
	@%p5 bra 	LBB0_10;

	setp.ne.s64 	%p6, %rd189, 6968279316240510977;
	@%p6 bra 	LBB0_9;

	mov.u64 	%rd286, 1345280370688173398;
	mov.u64 	%rd287, 6968279316240510977;
	setp.lt.u64 	%p7, %rd188, 6461107452199829505;
	mov.u64 	%rd288, %rd188;
	mov.u64 	%rd289, %rd293;
	mov.u64 	%rd290, %rd286;
	mov.u64 	%rd291, %rd287;
	mov.u64 	%rd292, %rd188;
	@%p7 bra 	LBB0_10;

	mov.u64 	%rd286, 1345280370688173398;
	mov.u64 	%rd287, 6968279316240510977;
	mov.u64 	%rd288, 6461107452199829505;
	setp.eq.s64 	%p8, %rd188, 6461107452199829505;
	setp.lt.u64 	%p9, %rd293, 725501752471715841;
	and.pred  	%p10, %p8, %p9;
	mov.u64 	%rd289, %rd293;
	mov.u64 	%rd290, %rd286;
	mov.u64 	%rd291, %rd287;
	mov.u64 	%rd292, %rd288;
	@%p10 bra 	LBB0_10;

LBB0_9:
	mov.u64 	%rd265, 1345280370688173398;
	mov.u64 	%rd264, 6968279316240510977;
	mov.u64 	%rd259, 6461107452199829505;
	mov.u64 	%rd258, 725501752471715841;
	// begin inline asm
	sub.cc.u64  %rd289, %rd293, %rd258;
	subc.cc.u64 %rd288, %rd188, %rd259;
	subc.cc.u64 %rd287, %rd189, %rd264;
	subc.u64    %rd286, %rd190, %rd265;
	
	// end inline asm
	mov.u64 	%rd290, %rd190;
	mov.u64 	%rd291, %rd189;
	mov.u64 	%rd292, %rd188;

LBB0_10:
	// begin inline asm
	add.cc.u64  %rd276, %rd276, %rd289;
	addc.cc.u64 %rd227, %rd300, %rd288;
	addc.cc.u64 %rd228, %rd299, %rd287;
	addc.u64    %rd229, %rd298, %rd286;
	
	// end inline asm
	setp.lt.u64 	%p11, %rd229, 1345280370688173398;
	mov.u64 	%rd298, %rd229;
	mov.u64 	%rd299, %rd228;
	mov.u64 	%rd300, %rd227;
	@%p11 bra 	LBB0_17;

	setp.ne.s64 	%p12, %rd229, 1345280370688173398;
	@%p12 bra 	LBB0_16;

	setp.lt.u64 	%p13, %rd228, 6968279316240510977;
	mov.u64 	%rd298, 1345280370688173398;
	mov.u64 	%rd299, %rd228;
	mov.u64 	%rd300, %rd227;
	@%p13 bra 	LBB0_17;

	setp.ne.s64 	%p14, %rd228, 6968279316240510977;
	@%p14 bra 	LBB0_16;

	setp.lt.u64 	%p15, %rd227, 6461107452199829505;
	mov.u64 	%rd299, 6968279316240510977;
	mov.u64 	%rd300, %rd227;
	@%p15 bra 	LBB0_17;

	setp.eq.s64 	%p16, %rd227, 6461107452199829505;
	mov.u64 	%rd300, 6461107452199829505;
	setp.lt.u64 	%p17, %rd276, 725501752471715841;
	and.pred  	%p18, %p16, %p17;
	@%p18 bra 	LBB0_17;

LBB0_16:
	mov.u64 	%rd252, 725501752471715841;
	mov.u64 	%rd253, 6461107452199829505;
	mov.u64 	%rd254, 6968279316240510977;
	mov.u64 	%rd255, 1345280370688173398;
	// begin inline asm
	sub.cc.u64  %rd276, %rd276, %rd252;
	subc.cc.u64 %rd300, %rd227, %rd253;
	subc.cc.u64 %rd299, %rd228, %rd254;
	subc.u64    %rd298, %rd229, %rd255;
	
	// end inline asm

LBB0_17:
	add.s64 	%rd272, %rd272, 32;
	add.s64 	%rd271, %rd271, 32;
	add.s64 	%rd285, %rd285, 1;
	setp.lt.u64 	%p19, %rd285, %rd5;
	@%p19 bra 	LBB0_2;

	ld.param.u64 	%rd262, [msm4_evaluate_param_0];
	cvta.to.global.u64 	%rd261, %rd262;
	mov.u32 	%r18, %tid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r15, %ntid.x;
	mad.lo.s32 	%r16, %r17, %r15, %r18;
	mul.wide.u32 	%rd256, %r16, 32;
	add.s64 	%rd257, %rd261, %rd256;
	st.global.u64 	[%rd257], %rd276;
	st.global.u64 	[%rd257+8], %rd300;
	st.global.u64 	[%rd257+16], %rd299;
	st.global.u64 	[%rd257+24], %rd298;

LBB0_19:
	ret;

}
	// .globl	msm4_sum
.visible .entry msm4_sum(
	.param .u64 msm4_sum_param_0,
	.param .u64 msm4_sum_param_1,
	.param .u32 msm4_sum_param_2,
	.param .u32 msm4_sum_param_3
)
{
	.reg .pred 	%p<47>;
	.reg .b32 	%r<30>;
	.reg .b64 	%rd<295>;


	ld.param.u64 	%rd78, [msm4_sum_param_0];
	ld.param.u64 	%rd83, [msm4_sum_param_1];
	ld.param.u32 	%r12, [msm4_sum_param_2];
	ld.param.u32 	%r13, [msm4_sum_param_3];
	cvta.to.global.u64 	%rd1, %rd83;
	mov.u32 	%r14, %ntid.x;
	mov.u32 	%r15, %ctaid.x;
	mov.u32 	%r16, %tid.x;
	mad.lo.s32 	%r1, %r15, %r14, %r16;
	mul.lo.s32 	%r2, %r1, %r12;
	setp.ge.u32 	%p1, %r2, %r13;
	mov.u64 	%rd287, 0;
	mov.u64 	%rd288, %rd287;
	mov.u64 	%rd289, %rd287;
	mov.u64 	%rd294, %rd287;
	@%p1 bra 	LBB1_42;

	add.s32 	%r17, %r2, %r12;
	min.u32 	%r3, %r17, %r13;
	setp.ge.u32 	%p2, %r2, %r3;
	mov.u64 	%rd288, %rd287;
	mov.u64 	%rd289, %rd287;
	mov.u64 	%rd294, %rd287;
	@%p2 bra 	LBB1_42;

	sub.s32 	%r18, %r3, %r2;
	and.b32  	%r27, %r18, 3;
	setp.eq.s32 	%p3, %r27, 0;
	mov.u64 	%rd287, 0;
	mov.u64 	%rd288, %rd287;
	mov.u64 	%rd289, %rd287;
	mov.u64 	%rd294, %rd287;
	mov.u32 	%r28, %r2;
	@%p3 bra 	LBB1_12;

	mov.u64 	%rd287, 0;
	mov.u64 	%rd288, %rd287;
	mov.u64 	%rd289, %rd287;
	mov.u64 	%rd294, %rd287;
	mov.u32 	%r28, %r2;

LBB1_4:
	.pragma "nounroll";
	mul.wide.u32 	%rd108, %r28, 32;
	add.s64 	%rd109, %rd1, %rd108;
	ld.global.u64 	%rd104, [%rd109];
	ld.global.u64 	%rd105, [%rd109+8];
	ld.global.u64 	%rd106, [%rd109+16];
	ld.global.u64 	%rd107, [%rd109+24];
	// begin inline asm
	add.cc.u64  %rd294, %rd294, %rd104;
	addc.cc.u64 %rd97, %rd289, %rd105;
	addc.cc.u64 %rd98, %rd288, %rd106;
	addc.u64    %rd99, %rd287, %rd107;
	
	// end inline asm
	setp.lt.u64 	%p4, %rd99, 1345280370688173398;
	mov.u64 	%rd287, %rd99;
	mov.u64 	%rd288, %rd98;
	mov.u64 	%rd289, %rd97;
	@%p4 bra 	LBB1_11;

	setp.ne.s64 	%p5, %rd99, 1345280370688173398;
	@%p5 bra 	LBB1_10;

	setp.lt.u64 	%p6, %rd98, 6968279316240510977;
	mov.u64 	%rd287, 1345280370688173398;
	mov.u64 	%rd288, %rd98;
	mov.u64 	%rd289, %rd97;
	@%p6 bra 	LBB1_11;

	setp.ne.s64 	%p7, %rd98, 6968279316240510977;
	@%p7 bra 	LBB1_10;

	setp.lt.u64 	%p8, %rd97, 6461107452199829505;
	mov.u64 	%rd288, 6968279316240510977;
	mov.u64 	%rd289, %rd97;
	@%p8 bra 	LBB1_11;

	setp.eq.s64 	%p9, %rd97, 6461107452199829505;
	mov.u64 	%rd289, 6461107452199829505;
	setp.lt.u64 	%p10, %rd294, 725501752471715841;
	and.pred  	%p11, %p9, %p10;
	@%p11 bra 	LBB1_11;

LBB1_10:
	mov.u64 	%rd124, 725501752471715841;
	mov.u64 	%rd125, 6461107452199829505;
	mov.u64 	%rd126, 6968279316240510977;
	mov.u64 	%rd127, 1345280370688173398;
	// begin inline asm
	sub.cc.u64  %rd294, %rd294, %rd124;
	subc.cc.u64 %rd289, %rd97, %rd125;
	subc.cc.u64 %rd288, %rd98, %rd126;
	subc.u64    %rd287, %rd99, %rd127;
	
	// end inline asm

LBB1_11:
	add.s32 	%r28, %r28, 1;
	add.s32 	%r27, %r27, -1;
	setp.ne.s32 	%p12, %r27, 0;
	@%p12 bra 	LBB1_4;

LBB1_12:
	mov.u32 	%r19, -2;
	sub.s32 	%r20, %r19, %r2;
	not.b32 	%r21, %r3;
	sub.s32 	%r22, %r20, %r21;
	setp.lt.u32 	%p13, %r22, 3;
	@%p13 bra 	LBB1_42;

LBB1_13:
	mul.wide.u32 	%rd140, %r28, 32;
	add.s64 	%rd141, %rd1, %rd140;
	ld.global.u64 	%rd136, [%rd141];
	ld.global.u64 	%rd137, [%rd141+8];
	ld.global.u64 	%rd138, [%rd141+16];
	ld.global.u64 	%rd139, [%rd141+24];
	// begin inline asm
	add.cc.u64  %rd278, %rd294, %rd136;
	addc.cc.u64 %rd129, %rd289, %rd137;
	addc.cc.u64 %rd130, %rd288, %rd138;
	addc.u64    %rd131, %rd287, %rd139;
	
	// end inline asm
	setp.lt.u64 	%p14, %rd131, 1345280370688173398;
	mov.u64 	%rd275, %rd131;
	mov.u64 	%rd276, %rd130;
	mov.u64 	%rd277, %rd129;
	@%p14 bra 	LBB1_20;

	setp.ne.s64 	%p15, %rd131, 1345280370688173398;
	@%p15 bra 	LBB1_19;

	setp.lt.u64 	%p16, %rd130, 6968279316240510977;
	mov.u64 	%rd275, 1345280370688173398;
	mov.u64 	%rd276, %rd130;
	mov.u64 	%rd277, %rd129;
	@%p16 bra 	LBB1_20;

	setp.ne.s64 	%p17, %rd130, 6968279316240510977;
	@%p17 bra 	LBB1_19;

	setp.lt.u64 	%p18, %rd129, 6461107452199829505;
	mov.u64 	%rd276, 6968279316240510977;
	mov.u64 	%rd277, %rd129;
	@%p18 bra 	LBB1_20;

	setp.eq.s64 	%p19, %rd129, 6461107452199829505;
	mov.u64 	%rd277, 6461107452199829505;
	setp.lt.u64 	%p20, %rd278, 725501752471715841;
	and.pred  	%p21, %p19, %p20;
	@%p21 bra 	LBB1_20;

LBB1_19:
	mov.u64 	%rd156, 725501752471715841;
	mov.u64 	%rd157, 6461107452199829505;
	mov.u64 	%rd158, 6968279316240510977;
	mov.u64 	%rd159, 1345280370688173398;
	// begin inline asm
	sub.cc.u64  %rd278, %rd278, %rd156;
	subc.cc.u64 %rd277, %rd129, %rd157;
	subc.cc.u64 %rd276, %rd130, %rd158;
	subc.u64    %rd275, %rd131, %rd159;
	
	// end inline asm

LBB1_20:
	add.s32 	%r23, %r28, 1;
	mul.wide.u32 	%rd172, %r23, 32;
	add.s64 	%rd173, %rd1, %rd172;
	ld.global.u64 	%rd168, [%rd173];
	ld.global.u64 	%rd169, [%rd173+8];
	ld.global.u64 	%rd170, [%rd173+16];
	ld.global.u64 	%rd171, [%rd173+24];
	// begin inline asm
	add.cc.u64  %rd282, %rd278, %rd168;
	addc.cc.u64 %rd161, %rd277, %rd169;
	addc.cc.u64 %rd162, %rd276, %rd170;
	addc.u64    %rd163, %rd275, %rd171;
	
	// end inline asm
	setp.lt.u64 	%p22, %rd163, 1345280370688173398;
	mov.u64 	%rd279, %rd163;
	mov.u64 	%rd280, %rd162;
	mov.u64 	%rd281, %rd161;
	@%p22 bra 	LBB1_27;

	setp.ne.s64 	%p23, %rd163, 1345280370688173398;
	@%p23 bra 	LBB1_26;

	setp.lt.u64 	%p24, %rd162, 6968279316240510977;
	mov.u64 	%rd279, 1345280370688173398;
	mov.u64 	%rd280, %rd162;
	mov.u64 	%rd281, %rd161;
	@%p24 bra 	LBB1_27;

	setp.ne.s64 	%p25, %rd162, 6968279316240510977;
	@%p25 bra 	LBB1_26;

	setp.lt.u64 	%p26, %rd161, 6461107452199829505;
	mov.u64 	%rd280, 6968279316240510977;
	mov.u64 	%rd281, %rd161;
	@%p26 bra 	LBB1_27;

	setp.eq.s64 	%p27, %rd161, 6461107452199829505;
	mov.u64 	%rd281, 6461107452199829505;
	setp.lt.u64 	%p28, %rd282, 725501752471715841;
	and.pred  	%p29, %p27, %p28;
	@%p29 bra 	LBB1_27;

LBB1_26:
	mov.u64 	%rd188, 725501752471715841;
	mov.u64 	%rd189, 6461107452199829505;
	mov.u64 	%rd190, 6968279316240510977;
	mov.u64 	%rd191, 1345280370688173398;
	// begin inline asm
	sub.cc.u64  %rd282, %rd282, %rd188;
	subc.cc.u64 %rd281, %rd161, %rd189;
	subc.cc.u64 %rd280, %rd162, %rd190;
	subc.u64    %rd279, %rd163, %rd191;
	
	// end inline asm

LBB1_27:
	add.s32 	%r24, %r28, 2;
	mul.wide.u32 	%rd204, %r24, 32;
	add.s64 	%rd205, %rd1, %rd204;
	ld.global.u64 	%rd200, [%rd205];
	ld.global.u64 	%rd201, [%rd205+8];
	ld.global.u64 	%rd202, [%rd205+16];
	ld.global.u64 	%rd203, [%rd205+24];
	// begin inline asm
	add.cc.u64  %rd286, %rd282, %rd200;
	addc.cc.u64 %rd193, %rd281, %rd201;
	addc.cc.u64 %rd194, %rd280, %rd202;
	addc.u64    %rd195, %rd279, %rd203;
	
	// end inline asm
	setp.lt.u64 	%p30, %rd195, 1345280370688173398;
	mov.u64 	%rd283, %rd195;
	mov.u64 	%rd284, %rd194;
	mov.u64 	%rd285, %rd193;
	@%p30 bra 	LBB1_34;

	setp.ne.s64 	%p31, %rd195, 1345280370688173398;
	@%p31 bra 	LBB1_33;

	setp.lt.u64 	%p32, %rd194, 6968279316240510977;
	mov.u64 	%rd283, 1345280370688173398;
	mov.u64 	%rd284, %rd194;
	mov.u64 	%rd285, %rd193;
	@%p32 bra 	LBB1_34;

	setp.ne.s64 	%p33, %rd194, 6968279316240510977;
	@%p33 bra 	LBB1_33;

	setp.lt.u64 	%p34, %rd193, 6461107452199829505;
	mov.u64 	%rd284, 6968279316240510977;
	mov.u64 	%rd285, %rd193;
	@%p34 bra 	LBB1_34;

	setp.eq.s64 	%p35, %rd193, 6461107452199829505;
	mov.u64 	%rd285, 6461107452199829505;
	setp.lt.u64 	%p36, %rd286, 725501752471715841;
	and.pred  	%p37, %p35, %p36;
	@%p37 bra 	LBB1_34;

LBB1_33:
	mov.u64 	%rd220, 725501752471715841;
	mov.u64 	%rd221, 6461107452199829505;
	mov.u64 	%rd222, 6968279316240510977;
	mov.u64 	%rd223, 1345280370688173398;
	// begin inline asm
	sub.cc.u64  %rd286, %rd286, %rd220;
	subc.cc.u64 %rd285, %rd193, %rd221;
	subc.cc.u64 %rd284, %rd194, %rd222;
	subc.u64    %rd283, %rd195, %rd223;
	
	// end inline asm

LBB1_34:
	add.s32 	%r25, %r28, 3;
	mul.wide.u32 	%rd236, %r25, 32;
	add.s64 	%rd237, %rd1, %rd236;
	ld.global.u64 	%rd232, [%rd237];
	ld.global.u64 	%rd233, [%rd237+8];
	ld.global.u64 	%rd234, [%rd237+16];
	ld.global.u64 	%rd235, [%rd237+24];
	// begin inline asm
	add.cc.u64  %rd294, %rd286, %rd232;
	addc.cc.u64 %rd225, %rd285, %rd233;
	addc.cc.u64 %rd226, %rd284, %rd234;
	addc.u64    %rd227, %rd283, %rd235;
	
	// end inline asm
	setp.lt.u64 	%p38, %rd227, 1345280370688173398;
	mov.u64 	%rd287, %rd227;
	mov.u64 	%rd288, %rd226;
	mov.u64 	%rd289, %rd225;
	@%p38 bra 	LBB1_41;

	setp.ne.s64 	%p39, %rd227, 1345280370688173398;
	@%p39 bra 	LBB1_40;

	setp.lt.u64 	%p40, %rd226, 6968279316240510977;
	mov.u64 	%rd287, 1345280370688173398;
	mov.u64 	%rd288, %rd226;
	mov.u64 	%rd289, %rd225;
	@%p40 bra 	LBB1_41;

	setp.ne.s64 	%p41, %rd226, 6968279316240510977;
	@%p41 bra 	LBB1_40;

	setp.lt.u64 	%p42, %rd225, 6461107452199829505;
	mov.u64 	%rd288, 6968279316240510977;
	mov.u64 	%rd289, %rd225;
	@%p42 bra 	LBB1_41;

	setp.eq.s64 	%p43, %rd225, 6461107452199829505;
	mov.u64 	%rd289, 6461107452199829505;
	setp.lt.u64 	%p44, %rd294, 725501752471715841;
	and.pred  	%p45, %p43, %p44;
	@%p45 bra 	LBB1_41;

LBB1_40:
	mov.u64 	%rd252, 725501752471715841;
	mov.u64 	%rd253, 6461107452199829505;
	mov.u64 	%rd254, 6968279316240510977;
	mov.u64 	%rd255, 1345280370688173398;
	// begin inline asm
	sub.cc.u64  %rd294, %rd294, %rd252;
	subc.cc.u64 %rd289, %rd225, %rd253;
	subc.cc.u64 %rd288, %rd226, %rd254;
	subc.u64    %rd287, %rd227, %rd255;
	
	// end inline asm

LBB1_41:
	add.s32 	%r28, %r28, 4;
	setp.lt.u32 	%p46, %r28, %r3;
	@%p46 bra 	LBB1_13;

LBB1_42:
	cvta.to.global.u64 	%rd256, %rd78;
	mul.wide.u32 	%rd257, %r1, 32;
	add.s64 	%rd258, %rd256, %rd257;
	st.global.u64 	[%rd258], %rd294;
	st.global.u64 	[%rd258+8], %rd289;
	st.global.u64 	[%rd258+16], %rd288;
	st.global.u64 	[%rd258+24], %rd287;
	ret;

}
	// .globl	msm4_powers_serial
.visible .entry msm4_powers_serial(
	.param .u64 msm4_powers_serial_param_0,
	.param .u64 msm4_powers_serial_param_1,
	.param .u32 msm4_powers_serial_param_2,
	.param .u32 msm4_powers_serial_param_3
)
{
	.reg .pred 	%p<47>;
	.reg .b32 	%r<17>;
	.reg .b64 	%rd<811>;


	ld.param.u64 	%rd182, [msm4_powers_serial_param_1];
	ld.param.u32 	%r6, [msm4_powers_serial_param_2];
	ld.param.u32 	%r7, [msm4_powers_serial_param_3];
	mov.u32 	%r8, %ntid.x;
	mov.u32 	%r9, %ctaid.x;
	mov.u32 	%r10, %tid.x;
	mad.lo.s32 	%r11, %r9, %r8, %r10;
	shl.b32 	%r15, %r11, 3;
	cvt.u64.u32 	%rd774, %r15;
	setp.ge.u32 	%p1, %r15, %r7;
	@%p1 bra 	LBB2_33;

	cvta.to.global.u64 	%rd188, %rd182;
	mul.wide.u32 	%rd189, %r6, 32;
	add.s64 	%rd190, %rd188, %rd189;
	ld.global.u64 	%rd2, [%rd190];
	ld.global.u64 	%rd3, [%rd190+8];
	ld.global.u64 	%rd4, [%rd190+16];
	ld.global.u64 	%rd5, [%rd190+24];
	setp.eq.s32 	%p2, %r15, 0;
	mov.u64 	%rd740, 9015221291577245683;
	mov.u64 	%rd739, 8239323489949974514;
	mov.u64 	%rd738, 1646089257421115374;
	mov.u64 	%rd737, 958099254763297437;
	@%p2 bra 	LBB2_21;

	mov.u64 	%rd740, 9015221291577245683;
	mov.u64 	%rd739, 8239323489949974514;
	mov.u64 	%rd738, 1646089257421115374;
	mov.u64 	%rd737, 958099254763297437;
	mov.pred 	%p4, 0;
	mov.u64 	%rd749, %rd5;
	mov.u64 	%rd750, %rd4;
	mov.u64 	%rd751, %rd3;
	mov.u64 	%rd752, %rd2;

LBB2_3:
	and.b32  	%r12, %r15, 1;
	setp.eq.b32 	%p3, %r12, 1;
	xor.pred  	%p5, %p3, %p4;
	not.pred 	%p6, %p5;
	@%p6 bra 	LBB2_12;

	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 nc;
	.reg .u64 t;
	mad.lo.cc.u64  %rd744, %rd740, %rd752, 0;
	madc.hi.cc.u64  c, %rd740, %rd752, 0;
	madc.lo.cc.u64 %rd743, %rd740, %rd751, c;
	madc.hi.cc.u64  c, %rd740, %rd751, 0;
	madc.lo.cc.u64 %rd742, %rd740, %rd750, c;
	madc.hi.cc.u64  c, %rd740, %rd750, 0;
	madc.lo.cc.u64 %rd741, %rd740, %rd749, c;
	madc.hi.u64    %rd745, %rd740, %rd749, 0;
	mad.lo.cc.u64  %rd743, %rd739, %rd752, %rd743;
	madc.hi.cc.u64  c, %rd739, %rd752, 0;
	addc.cc.u64     t, %rd742, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd742, %rd739, %rd751, t;
	madc.hi.cc.u64  c, %rd739, %rd751, nc;
	addc.cc.u64     t, %rd741, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd741, %rd739, %rd750, t;
	madc.hi.cc.u64  c, %rd739, %rd750, nc;
	addc.cc.u64     t, %rd745, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd745, %rd739, %rd749, t;
	madc.hi.u64    %rd746, %rd739, %rd749, nc;
	mad.lo.cc.u64  %rd742, %rd738, %rd752, %rd742;
	madc.hi.cc.u64  c, %rd738, %rd752, 0;
	addc.cc.u64     t, %rd741, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd741, %rd738, %rd751, t;
	madc.hi.cc.u64  c, %rd738, %rd751, nc;
	addc.cc.u64     t, %rd745, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd745, %rd738, %rd750, t;
	madc.hi.cc.u64  c, %rd738, %rd750, nc;
	addc.cc.u64     t, %rd746, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd746, %rd738, %rd749, t;
	madc.hi.u64    %rd747, %rd738, %rd749, nc;
	mad.lo.cc.u64  %rd741, %rd737, %rd752, %rd741;
	madc.hi.cc.u64  c, %rd737, %rd752, 0;
	addc.cc.u64     t, %rd745, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd745, %rd737, %rd751, t;
	madc.hi.cc.u64  c, %rd737, %rd751, nc;
	addc.cc.u64     t, %rd746, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd746, %rd737, %rd750, t;
	madc.hi.cc.u64  c, %rd737, %rd750, nc;
	addc.cc.u64     t, %rd747, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd747, %rd737, %rd749, t;
	madc.hi.u64    %rd748, %rd737, %rd749, nc;
	}
	// end inline asm
	or.b64  	%rd224, %rd744, %rd743;
	or.b64  	%rd225, %rd224, %rd742;
	or.b64  	%rd226, %rd225, %rd741;
	or.b64  	%rd227, %rd226, %rd745;
	or.b64  	%rd228, %rd227, %rd746;
	or.b64  	%rd229, %rd228, %rd747;
	or.b64  	%rd230, %rd229, %rd748;
	setp.eq.s64 	%p7, %rd230, 0;
	mov.u64 	%rd737, 0;
	mov.u64 	%rd738, %rd737;
	mov.u64 	%rd739, %rd737;
	mov.u64 	%rd740, %rd737;
	@%p7 bra 	LBB2_12;

	mul.lo.s64 	%rd241, %rd744, 725501752471715839;
	mov.u64 	%rd287, 725501752471715841;
	mov.u64 	%rd288, 6461107452199829505;
	mov.u64 	%rd289, 6968279316240510977;
	mov.u64 	%rd290, 1345280370688173398;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd241, %rd287, %rd744;
	madc.hi.cc.u64 c, %rd241, %rd287, 0;
	addc.cc.u64 t, %rd743, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd743, %rd241, %rd288, t;
	madc.hi.cc.u64 c, %rd241, %rd288, nc;
	addc.cc.u64 t, %rd742, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd742, %rd241, %rd289, t;
	madc.hi.cc.u64 c, %rd241, %rd289, nc;
	addc.cc.u64 t, %rd741, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd741, %rd241, %rd290, t;
	madc.hi.cc.u64 c, %rd241, %rd290, nc;
	addc.cc.u64 %rd745, %rd745, c;
	addc.u64 %rd269, 0, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd257, %rd743, 725501752471715839;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd257, %rd287, %rd743;
	madc.hi.cc.u64 c, %rd257, %rd287, 0;
	addc.cc.u64 t, %rd742, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd742, %rd257, %rd288, t;
	madc.hi.cc.u64 c, %rd257, %rd288, nc;
	addc.cc.u64 t, %rd741, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd741, %rd257, %rd289, t;
	madc.hi.cc.u64 c, %rd257, %rd289, nc;
	addc.cc.u64 t, %rd745, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd745, %rd257, %rd290, t;
	madc.hi.cc.u64 c, %rd257, %rd290, nc;
	addc.cc.u64 c, c, %rd269;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd746, %rd746, c;
	addc.u64 %rd269, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd274, %rd742, 725501752471715839;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd274, %rd287, %rd742;
	madc.hi.cc.u64 c, %rd274, %rd287, 0;
	addc.cc.u64 t, %rd741, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd741, %rd274, %rd288, t;
	madc.hi.cc.u64 c, %rd274, %rd288, nc;
	addc.cc.u64 t, %rd745, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd745, %rd274, %rd289, t;
	madc.hi.cc.u64 c, %rd274, %rd289, nc;
	addc.cc.u64 t, %rd746, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd746, %rd274, %rd290, t;
	madc.hi.cc.u64 c, %rd274, %rd290, nc;
	addc.cc.u64 c, c, %rd269;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd747, %rd747, c;
	addc.u64 %rd269, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd291, %rd741, 725501752471715839;
	mov.u64 	%rd285, %rd748;
	mov.u64 	%rd284, %rd747;
	mov.u64 	%rd283, %rd746;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd291, %rd287, %rd741;
	madc.hi.cc.u64 c, %rd291, %rd287, 0;
	addc.cc.u64 t, %rd745, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd745, %rd291, %rd288, t;
	madc.hi.cc.u64 c, %rd291, %rd288, nc;
	addc.cc.u64 t, %rd283, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd283, %rd291, %rd289, t;
	madc.hi.cc.u64 c, %rd291, %rd289, nc;
	addc.cc.u64 t, %rd284, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd284, %rd291, %rd290, t;
	madc.hi.cc.u64 c, %rd291, %rd290, nc;
	addc.cc.u64 c, c, %rd269;
	addc.cc.u64 %rd285, %rd285, c;
	}
	// end inline asm
	setp.lt.u64 	%p8, %rd285, 1345280370688173398;
	mov.u64 	%rd737, %rd285;
	mov.u64 	%rd738, %rd284;
	mov.u64 	%rd739, %rd283;
	mov.u64 	%rd740, %rd745;
	mov.u64 	%rd746, %rd283;
	mov.u64 	%rd747, %rd284;
	mov.u64 	%rd748, %rd285;
	@%p8 bra 	LBB2_12;

	setp.ne.s64 	%p9, %rd285, 1345280370688173398;
	@%p9 bra 	LBB2_11;

	mov.u64 	%rd737, 1345280370688173398;
	setp.lt.u64 	%p10, %rd284, 6968279316240510977;
	mov.u64 	%rd738, %rd284;
	mov.u64 	%rd739, %rd283;
	mov.u64 	%rd740, %rd745;
	mov.u64 	%rd746, %rd283;
	mov.u64 	%rd747, %rd284;
	mov.u64 	%rd748, %rd737;
	@%p10 bra 	LBB2_12;

	setp.ne.s64 	%p11, %rd284, 6968279316240510977;
	@%p11 bra 	LBB2_11;

	mov.u64 	%rd737, 1345280370688173398;
	mov.u64 	%rd738, 6968279316240510977;
	setp.lt.u64 	%p12, %rd283, 6461107452199829505;
	mov.u64 	%rd739, %rd283;
	mov.u64 	%rd740, %rd745;
	mov.u64 	%rd746, %rd283;
	mov.u64 	%rd747, %rd738;
	mov.u64 	%rd748, %rd737;
	@%p12 bra 	LBB2_12;

	mov.u64 	%rd737, 1345280370688173398;
	mov.u64 	%rd738, 6968279316240510977;
	mov.u64 	%rd739, 6461107452199829505;
	setp.eq.s64 	%p13, %rd283, 6461107452199829505;
	setp.lt.u64 	%p14, %rd745, 725501752471715841;
	and.pred  	%p15, %p13, %p14;
	mov.u64 	%rd740, %rd745;
	mov.u64 	%rd746, %rd739;
	mov.u64 	%rd747, %rd738;
	mov.u64 	%rd748, %rd737;
	@%p15 bra 	LBB2_12;

LBB2_11:
	mov.u64 	%rd711, 1345280370688173398;
	mov.u64 	%rd710, 6968279316240510977;
	mov.u64 	%rd701, 6461107452199829505;
	mov.u64 	%rd700, 725501752471715841;
	// begin inline asm
	sub.cc.u64  %rd740, %rd745, %rd700;
	subc.cc.u64 %rd739, %rd283, %rd701;
	subc.cc.u64 %rd738, %rd284, %rd710;
	subc.u64    %rd737, %rd285, %rd711;
	
	// end inline asm
	mov.u64 	%rd746, %rd283;
	mov.u64 	%rd747, %rd284;
	mov.u64 	%rd748, %rd285;

LBB2_12:
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 nc;
	.reg .u64 t;
	mad.lo.cc.u64  %rd744, %rd752, %rd752, 0;
	madc.hi.cc.u64  c, %rd752, %rd752, 0;
	madc.lo.cc.u64 %rd743, %rd752, %rd751, c;
	madc.hi.cc.u64  c, %rd752, %rd751, 0;
	madc.lo.cc.u64 %rd742, %rd752, %rd750, c;
	madc.hi.cc.u64  c, %rd752, %rd750, 0;
	madc.lo.cc.u64 %rd741, %rd752, %rd749, c;
	madc.hi.u64    %rd745, %rd752, %rd749, 0;
	mad.lo.cc.u64  %rd743, %rd751, %rd752, %rd743;
	madc.hi.cc.u64  c, %rd751, %rd752, 0;
	addc.cc.u64     t, %rd742, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd742, %rd751, %rd751, t;
	madc.hi.cc.u64  c, %rd751, %rd751, nc;
	addc.cc.u64     t, %rd741, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd741, %rd751, %rd750, t;
	madc.hi.cc.u64  c, %rd751, %rd750, nc;
	addc.cc.u64     t, %rd745, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd745, %rd751, %rd749, t;
	madc.hi.u64    %rd746, %rd751, %rd749, nc;
	mad.lo.cc.u64  %rd742, %rd750, %rd752, %rd742;
	madc.hi.cc.u64  c, %rd750, %rd752, 0;
	addc.cc.u64     t, %rd741, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd741, %rd750, %rd751, t;
	madc.hi.cc.u64  c, %rd750, %rd751, nc;
	addc.cc.u64     t, %rd745, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd745, %rd750, %rd750, t;
	madc.hi.cc.u64  c, %rd750, %rd750, nc;
	addc.cc.u64     t, %rd746, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd746, %rd750, %rd749, t;
	madc.hi.u64    %rd747, %rd750, %rd749, nc;
	mad.lo.cc.u64  %rd741, %rd749, %rd752, %rd741;
	madc.hi.cc.u64  c, %rd749, %rd752, 0;
	addc.cc.u64     t, %rd745, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd745, %rd749, %rd751, t;
	madc.hi.cc.u64  c, %rd749, %rd751, nc;
	addc.cc.u64     t, %rd746, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd746, %rd749, %rd750, t;
	madc.hi.cc.u64  c, %rd749, %rd750, nc;
	addc.cc.u64     t, %rd747, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd747, %rd749, %rd749, t;
	madc.hi.u64    %rd748, %rd749, %rd749, nc;
	}
	// end inline asm
	or.b64  	%rd349, %rd744, %rd743;
	or.b64  	%rd350, %rd349, %rd742;
	or.b64  	%rd351, %rd350, %rd741;
	or.b64  	%rd352, %rd351, %rd745;
	or.b64  	%rd353, %rd352, %rd746;
	or.b64  	%rd354, %rd353, %rd747;
	or.b64  	%rd355, %rd354, %rd748;
	setp.eq.s64 	%p16, %rd355, 0;
	mov.u64 	%rd749, 0;
	mov.u64 	%rd750, %rd749;
	mov.u64 	%rd751, %rd749;
	mov.u64 	%rd752, %rd749;
	@%p16 bra 	LBB2_20;

	mul.lo.s64 	%rd366, %rd744, 725501752471715839;
	mov.u64 	%rd412, 725501752471715841;
	mov.u64 	%rd413, 6461107452199829505;
	mov.u64 	%rd414, 6968279316240510977;
	mov.u64 	%rd415, 1345280370688173398;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd366, %rd412, %rd744;
	madc.hi.cc.u64 c, %rd366, %rd412, 0;
	addc.cc.u64 t, %rd743, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd743, %rd366, %rd413, t;
	madc.hi.cc.u64 c, %rd366, %rd413, nc;
	addc.cc.u64 t, %rd742, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd742, %rd366, %rd414, t;
	madc.hi.cc.u64 c, %rd366, %rd414, nc;
	addc.cc.u64 t, %rd741, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd741, %rd366, %rd415, t;
	madc.hi.cc.u64 c, %rd366, %rd415, nc;
	addc.cc.u64 %rd745, %rd745, c;
	addc.u64 %rd394, 0, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd382, %rd743, 725501752471715839;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd382, %rd412, %rd743;
	madc.hi.cc.u64 c, %rd382, %rd412, 0;
	addc.cc.u64 t, %rd742, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd742, %rd382, %rd413, t;
	madc.hi.cc.u64 c, %rd382, %rd413, nc;
	addc.cc.u64 t, %rd741, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd741, %rd382, %rd414, t;
	madc.hi.cc.u64 c, %rd382, %rd414, nc;
	addc.cc.u64 t, %rd745, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd745, %rd382, %rd415, t;
	madc.hi.cc.u64 c, %rd382, %rd415, nc;
	addc.cc.u64 c, c, %rd394;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd746, %rd746, c;
	addc.u64 %rd394, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd399, %rd742, 725501752471715839;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd399, %rd412, %rd742;
	madc.hi.cc.u64 c, %rd399, %rd412, 0;
	addc.cc.u64 t, %rd741, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd741, %rd399, %rd413, t;
	madc.hi.cc.u64 c, %rd399, %rd413, nc;
	addc.cc.u64 t, %rd745, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd745, %rd399, %rd414, t;
	madc.hi.cc.u64 c, %rd399, %rd414, nc;
	addc.cc.u64 t, %rd746, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd746, %rd399, %rd415, t;
	madc.hi.cc.u64 c, %rd399, %rd415, nc;
	addc.cc.u64 c, c, %rd394;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd747, %rd747, c;
	addc.u64 %rd394, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd416, %rd741, 725501752471715839;
	mov.u64 	%rd408, %rd746;
	mov.u64 	%rd410, %rd748;
	mov.u64 	%rd409, %rd747;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd416, %rd412, %rd741;
	madc.hi.cc.u64 c, %rd416, %rd412, 0;
	addc.cc.u64 t, %rd745, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd745, %rd416, %rd413, t;
	madc.hi.cc.u64 c, %rd416, %rd413, nc;
	addc.cc.u64 t, %rd408, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd408, %rd416, %rd414, t;
	madc.hi.cc.u64 c, %rd416, %rd414, nc;
	addc.cc.u64 t, %rd409, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd409, %rd416, %rd415, t;
	madc.hi.cc.u64 c, %rd416, %rd415, nc;
	addc.cc.u64 c, c, %rd394;
	addc.cc.u64 %rd410, %rd410, c;
	}
	// end inline asm
	setp.lt.u64 	%p17, %rd410, 1345280370688173398;
	mov.u64 	%rd749, %rd410;
	mov.u64 	%rd750, %rd409;
	mov.u64 	%rd751, %rd408;
	mov.u64 	%rd752, %rd745;
	mov.u64 	%rd746, %rd408;
	mov.u64 	%rd747, %rd409;
	mov.u64 	%rd748, %rd410;
	@%p17 bra 	LBB2_20;

	setp.ne.s64 	%p18, %rd410, 1345280370688173398;
	@%p18 bra 	LBB2_19;

	mov.u64 	%rd749, 1345280370688173398;
	setp.lt.u64 	%p19, %rd409, 6968279316240510977;
	mov.u64 	%rd750, %rd409;
	mov.u64 	%rd751, %rd408;
	mov.u64 	%rd752, %rd745;
	mov.u64 	%rd746, %rd408;
	mov.u64 	%rd747, %rd409;
	mov.u64 	%rd748, %rd749;
	@%p19 bra 	LBB2_20;

	setp.ne.s64 	%p20, %rd409, 6968279316240510977;
	@%p20 bra 	LBB2_19;

	mov.u64 	%rd749, 1345280370688173398;
	mov.u64 	%rd750, 6968279316240510977;
	setp.lt.u64 	%p21, %rd408, 6461107452199829505;
	mov.u64 	%rd751, %rd408;
	mov.u64 	%rd752, %rd745;
	mov.u64 	%rd746, %rd408;
	mov.u64 	%rd747, %rd750;
	mov.u64 	%rd748, %rd749;
	@%p21 bra 	LBB2_20;

	mov.u64 	%rd749, 1345280370688173398;
	mov.u64 	%rd750, 6968279316240510977;
	mov.u64 	%rd751, 6461107452199829505;
	setp.eq.s64 	%p22, %rd408, 6461107452199829505;
	setp.lt.u64 	%p23, %rd745, 725501752471715841;
	and.pred  	%p24, %p22, %p23;
	mov.u64 	%rd752, %rd745;
	mov.u64 	%rd746, %rd751;
	mov.u64 	%rd747, %rd750;
	mov.u64 	%rd748, %rd749;
	@%p24 bra 	LBB2_20;

LBB2_19:
	mov.u64 	%rd717, 1345280370688173398;
	mov.u64 	%rd706, 6968279316240510977;
	mov.u64 	%rd705, 6461107452199829505;
	mov.u64 	%rd704, 725501752471715841;
	// begin inline asm
	sub.cc.u64  %rd752, %rd745, %rd704;
	subc.cc.u64 %rd751, %rd408, %rd705;
	subc.cc.u64 %rd750, %rd409, %rd706;
	subc.u64    %rd749, %rd410, %rd717;
	
	// end inline asm
	mov.u64 	%rd746, %rd408;
	mov.u64 	%rd747, %rd409;
	mov.u64 	%rd748, %rd410;

LBB2_20:
	shr.u32 	%r15, %r15, 1;
	setp.ne.s32 	%p25, %r15, 0;
	@%p25 bra 	LBB2_3;

LBB2_21:
	ld.param.u32 	%r14, [msm4_powers_serial_param_3];
	ld.param.u64 	%rd703, [msm4_powers_serial_param_0];
	cvta.to.global.u64 	%rd446, %rd703;
	shl.b64 	%rd447, %rd774, 5;
	add.s64 	%rd448, %rd446, %rd447;
	st.global.u64 	[%rd448], %rd740;
	st.global.u64 	[%rd448+8], %rd739;
	st.global.u64 	[%rd448+16], %rd738;
	st.global.u64 	[%rd448+24], %rd737;
	cvt.u64.u32 	%rd98, %r14;
	add.s64 	%rd773, %rd448, 48;
	mov.u32 	%r16, 2;
	bra.uni 	LBB2_22;

LBB2_42:
	st.global.u64 	[%rd773+16], %rd740;
	st.global.u64 	[%rd773+24], %rd739;
	st.global.u64 	[%rd773+32], %rd738;
	st.global.u64 	[%rd773+40], %rd737;
	add.s32 	%r16, %r16, 2;
	add.s64 	%rd773, %rd773, 64;

LBB2_22:
	add.s64 	%rd449, %rd774, 1;
	setp.ge.u64 	%p26, %rd449, %rd98;
	@%p26 bra 	LBB2_33;

	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 nc;
	.reg .u64 t;
	mad.lo.cc.u64  %rd744, %rd740, %rd2, 0;
	madc.hi.cc.u64  c, %rd740, %rd2, 0;
	madc.lo.cc.u64 %rd743, %rd740, %rd3, c;
	madc.hi.cc.u64  c, %rd740, %rd3, 0;
	madc.lo.cc.u64 %rd742, %rd740, %rd4, c;
	madc.hi.cc.u64  c, %rd740, %rd4, 0;
	madc.lo.cc.u64 %rd741, %rd740, %rd5, c;
	madc.hi.u64    %rd745, %rd740, %rd5, 0;
	mad.lo.cc.u64  %rd743, %rd739, %rd2, %rd743;
	madc.hi.cc.u64  c, %rd739, %rd2, 0;
	addc.cc.u64     t, %rd742, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd742, %rd739, %rd3, t;
	madc.hi.cc.u64  c, %rd739, %rd3, nc;
	addc.cc.u64     t, %rd741, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd741, %rd739, %rd4, t;
	madc.hi.cc.u64  c, %rd739, %rd4, nc;
	addc.cc.u64     t, %rd745, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd745, %rd739, %rd5, t;
	madc.hi.u64    %rd746, %rd739, %rd5, nc;
	mad.lo.cc.u64  %rd742, %rd738, %rd2, %rd742;
	madc.hi.cc.u64  c, %rd738, %rd2, 0;
	addc.cc.u64     t, %rd741, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd741, %rd738, %rd3, t;
	madc.hi.cc.u64  c, %rd738, %rd3, nc;
	addc.cc.u64     t, %rd745, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd745, %rd738, %rd4, t;
	madc.hi.cc.u64  c, %rd738, %rd4, nc;
	addc.cc.u64     t, %rd746, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd746, %rd738, %rd5, t;
	madc.hi.u64    %rd747, %rd738, %rd5, nc;
	mad.lo.cc.u64  %rd741, %rd737, %rd2, %rd741;
	madc.hi.cc.u64  c, %rd737, %rd2, 0;
	addc.cc.u64     t, %rd745, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd745, %rd737, %rd3, t;
	madc.hi.cc.u64  c, %rd737, %rd3, nc;
	addc.cc.u64     t, %rd746, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd746, %rd737, %rd4, t;
	madc.hi.cc.u64  c, %rd737, %rd4, nc;
	addc.cc.u64     t, %rd747, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd747, %rd737, %rd5, t;
	madc.hi.u64    %rd748, %rd737, %rd5, nc;
	}
	// end inline asm
	or.b64  	%rd478, %rd744, %rd743;
	or.b64  	%rd479, %rd478, %rd742;
	or.b64  	%rd480, %rd479, %rd741;
	or.b64  	%rd481, %rd480, %rd745;
	or.b64  	%rd482, %rd481, %rd746;
	or.b64  	%rd483, %rd482, %rd747;
	or.b64  	%rd484, %rd483, %rd748;
	setp.eq.s64 	%p27, %rd484, 0;
	mov.u64 	%rd787, 0;
	mov.u64 	%rd788, %rd787;
	mov.u64 	%rd789, %rd787;
	mov.u64 	%rd790, %rd787;
	@%p27 bra 	LBB2_31;

	mul.lo.s64 	%rd495, %rd744, 725501752471715839;
	mov.u64 	%rd541, 725501752471715841;
	mov.u64 	%rd542, 6461107452199829505;
	mov.u64 	%rd543, 6968279316240510977;
	mov.u64 	%rd544, 1345280370688173398;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd495, %rd541, %rd744;
	madc.hi.cc.u64 c, %rd495, %rd541, 0;
	addc.cc.u64 t, %rd743, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd743, %rd495, %rd542, t;
	madc.hi.cc.u64 c, %rd495, %rd542, nc;
	addc.cc.u64 t, %rd742, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd742, %rd495, %rd543, t;
	madc.hi.cc.u64 c, %rd495, %rd543, nc;
	addc.cc.u64 t, %rd741, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd741, %rd495, %rd544, t;
	madc.hi.cc.u64 c, %rd495, %rd544, nc;
	addc.cc.u64 %rd745, %rd745, c;
	addc.u64 %rd523, 0, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd511, %rd743, 725501752471715839;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd511, %rd541, %rd743;
	madc.hi.cc.u64 c, %rd511, %rd541, 0;
	addc.cc.u64 t, %rd742, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd742, %rd511, %rd542, t;
	madc.hi.cc.u64 c, %rd511, %rd542, nc;
	addc.cc.u64 t, %rd741, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd741, %rd511, %rd543, t;
	madc.hi.cc.u64 c, %rd511, %rd543, nc;
	addc.cc.u64 t, %rd745, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd745, %rd511, %rd544, t;
	madc.hi.cc.u64 c, %rd511, %rd544, nc;
	addc.cc.u64 c, c, %rd523;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd746, %rd746, c;
	addc.u64 %rd523, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd528, %rd742, 725501752471715839;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd528, %rd541, %rd742;
	madc.hi.cc.u64 c, %rd528, %rd541, 0;
	addc.cc.u64 t, %rd741, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd741, %rd528, %rd542, t;
	madc.hi.cc.u64 c, %rd528, %rd542, nc;
	addc.cc.u64 t, %rd745, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd745, %rd528, %rd543, t;
	madc.hi.cc.u64 c, %rd528, %rd543, nc;
	addc.cc.u64 t, %rd746, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd746, %rd528, %rd544, t;
	madc.hi.cc.u64 c, %rd528, %rd544, nc;
	addc.cc.u64 c, c, %rd523;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd747, %rd747, c;
	addc.u64 %rd523, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd545, %rd741, 725501752471715839;
	mov.u64 	%rd539, %rd748;
	mov.u64 	%rd538, %rd747;
	mov.u64 	%rd537, %rd746;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd545, %rd541, %rd741;
	madc.hi.cc.u64 c, %rd545, %rd541, 0;
	addc.cc.u64 t, %rd745, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd745, %rd545, %rd542, t;
	madc.hi.cc.u64 c, %rd545, %rd542, nc;
	addc.cc.u64 t, %rd537, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd537, %rd545, %rd543, t;
	madc.hi.cc.u64 c, %rd545, %rd543, nc;
	addc.cc.u64 t, %rd538, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd538, %rd545, %rd544, t;
	madc.hi.cc.u64 c, %rd545, %rd544, nc;
	addc.cc.u64 c, c, %rd523;
	addc.cc.u64 %rd539, %rd539, c;
	}
	// end inline asm
	setp.lt.u64 	%p28, %rd539, 1345280370688173398;
	mov.u64 	%rd787, %rd539;
	mov.u64 	%rd788, %rd538;
	mov.u64 	%rd789, %rd537;
	mov.u64 	%rd790, %rd745;
	mov.u64 	%rd746, %rd537;
	mov.u64 	%rd747, %rd538;
	mov.u64 	%rd748, %rd539;
	@%p28 bra 	LBB2_31;

	setp.ne.s64 	%p29, %rd539, 1345280370688173398;
	@%p29 bra 	LBB2_30;

	setp.lt.u64 	%p30, %rd538, 6968279316240510977;
	mov.u64 	%rd787, %rd544;
	mov.u64 	%rd788, %rd538;
	mov.u64 	%rd789, %rd537;
	mov.u64 	%rd790, %rd745;
	mov.u64 	%rd746, %rd537;
	mov.u64 	%rd747, %rd538;
	mov.u64 	%rd748, %rd544;
	@%p30 bra 	LBB2_31;

	setp.ne.s64 	%p31, %rd538, 6968279316240510977;
	@%p31 bra 	LBB2_30;

	setp.lt.u64 	%p32, %rd537, 6461107452199829505;
	mov.u64 	%rd787, %rd544;
	mov.u64 	%rd788, %rd543;
	mov.u64 	%rd789, %rd537;
	mov.u64 	%rd790, %rd745;
	mov.u64 	%rd746, %rd537;
	mov.u64 	%rd747, %rd543;
	mov.u64 	%rd748, %rd544;
	@%p32 bra 	LBB2_31;

	setp.eq.s64 	%p33, %rd537, 6461107452199829505;
	setp.lt.u64 	%p34, %rd745, 725501752471715841;
	and.pred  	%p35, %p33, %p34;
	mov.u64 	%rd787, %rd544;
	mov.u64 	%rd788, %rd543;
	mov.u64 	%rd789, %rd542;
	mov.u64 	%rd790, %rd745;
	mov.u64 	%rd746, %rd542;
	mov.u64 	%rd747, %rd543;
	mov.u64 	%rd748, %rd544;
	@%p35 bra 	LBB2_31;

LBB2_30:
	// begin inline asm
	sub.cc.u64  %rd790, %rd745, %rd541;
	subc.cc.u64 %rd789, %rd537, %rd542;
	subc.cc.u64 %rd788, %rd538, %rd543;
	subc.u64    %rd787, %rd539, %rd544;
	
	// end inline asm
	mov.u64 	%rd746, %rd537;
	mov.u64 	%rd747, %rd538;
	mov.u64 	%rd748, %rd539;

LBB2_31:
	st.global.u64 	[%rd773+-16], %rd790;
	st.global.u64 	[%rd773+-8], %rd789;
	st.global.u64 	[%rd773], %rd788;
	st.global.u64 	[%rd773+8], %rd787;
	setp.gt.u32 	%p36, %r16, 7;
	@%p36 bra 	LBB2_33;

	add.s64 	%rd774, %rd774, 2;
	setp.lt.u64 	%p37, %rd774, %rd98;
	@%p37 bra 	LBB2_34;
	bra.uni 	LBB2_33;

LBB2_34:
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 nc;
	.reg .u64 t;
	mad.lo.cc.u64  %rd744, %rd790, %rd2, 0;
	madc.hi.cc.u64  c, %rd790, %rd2, 0;
	madc.lo.cc.u64 %rd743, %rd790, %rd3, c;
	madc.hi.cc.u64  c, %rd790, %rd3, 0;
	madc.lo.cc.u64 %rd742, %rd790, %rd4, c;
	madc.hi.cc.u64  c, %rd790, %rd4, 0;
	madc.lo.cc.u64 %rd741, %rd790, %rd5, c;
	madc.hi.u64    %rd745, %rd790, %rd5, 0;
	mad.lo.cc.u64  %rd743, %rd789, %rd2, %rd743;
	madc.hi.cc.u64  c, %rd789, %rd2, 0;
	addc.cc.u64     t, %rd742, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd742, %rd789, %rd3, t;
	madc.hi.cc.u64  c, %rd789, %rd3, nc;
	addc.cc.u64     t, %rd741, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd741, %rd789, %rd4, t;
	madc.hi.cc.u64  c, %rd789, %rd4, nc;
	addc.cc.u64     t, %rd745, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd745, %rd789, %rd5, t;
	madc.hi.u64    %rd746, %rd789, %rd5, nc;
	mad.lo.cc.u64  %rd742, %rd788, %rd2, %rd742;
	madc.hi.cc.u64  c, %rd788, %rd2, 0;
	addc.cc.u64     t, %rd741, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd741, %rd788, %rd3, t;
	madc.hi.cc.u64  c, %rd788, %rd3, nc;
	addc.cc.u64     t, %rd745, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd745, %rd788, %rd4, t;
	madc.hi.cc.u64  c, %rd788, %rd4, nc;
	addc.cc.u64     t, %rd746, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd746, %rd788, %rd5, t;
	madc.hi.u64    %rd747, %rd788, %rd5, nc;
	mad.lo.cc.u64  %rd741, %rd787, %rd2, %rd741;
	madc.hi.cc.u64  c, %rd787, %rd2, 0;
	addc.cc.u64     t, %rd745, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd745, %rd787, %rd3, t;
	madc.hi.cc.u64  c, %rd787, %rd3, nc;
	addc.cc.u64     t, %rd746, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd746, %rd787, %rd4, t;
	madc.hi.cc.u64  c, %rd787, %rd4, nc;
	addc.cc.u64     t, %rd747, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd747, %rd787, %rd5, t;
	madc.hi.u64    %rd748, %rd787, %rd5, nc;
	}
	// end inline asm
	or.b64  	%rd603, %rd744, %rd743;
	or.b64  	%rd604, %rd603, %rd742;
	or.b64  	%rd605, %rd604, %rd741;
	or.b64  	%rd606, %rd605, %rd745;
	or.b64  	%rd607, %rd606, %rd746;
	or.b64  	%rd608, %rd607, %rd747;
	or.b64  	%rd609, %rd608, %rd748;
	setp.eq.s64 	%p38, %rd609, 0;
	mov.u64 	%rd737, 0;
	mov.u64 	%rd738, %rd737;
	mov.u64 	%rd739, %rd737;
	mov.u64 	%rd740, %rd737;
	@%p38 bra 	LBB2_42;

	mul.lo.s64 	%rd620, %rd744, 725501752471715839;
	mov.u64 	%rd666, 725501752471715841;
	mov.u64 	%rd667, 6461107452199829505;
	mov.u64 	%rd668, 6968279316240510977;
	mov.u64 	%rd669, 1345280370688173398;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd620, %rd666, %rd744;
	madc.hi.cc.u64 c, %rd620, %rd666, 0;
	addc.cc.u64 t, %rd743, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd743, %rd620, %rd667, t;
	madc.hi.cc.u64 c, %rd620, %rd667, nc;
	addc.cc.u64 t, %rd742, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd742, %rd620, %rd668, t;
	madc.hi.cc.u64 c, %rd620, %rd668, nc;
	addc.cc.u64 t, %rd741, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd741, %rd620, %rd669, t;
	madc.hi.cc.u64 c, %rd620, %rd669, nc;
	addc.cc.u64 %rd745, %rd745, c;
	addc.u64 %rd648, 0, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd636, %rd743, 725501752471715839;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd636, %rd666, %rd743;
	madc.hi.cc.u64 c, %rd636, %rd666, 0;
	addc.cc.u64 t, %rd742, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd742, %rd636, %rd667, t;
	madc.hi.cc.u64 c, %rd636, %rd667, nc;
	addc.cc.u64 t, %rd741, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd741, %rd636, %rd668, t;
	madc.hi.cc.u64 c, %rd636, %rd668, nc;
	addc.cc.u64 t, %rd745, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd745, %rd636, %rd669, t;
	madc.hi.cc.u64 c, %rd636, %rd669, nc;
	addc.cc.u64 c, c, %rd648;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd746, %rd746, c;
	addc.u64 %rd648, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd653, %rd742, 725501752471715839;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd653, %rd666, %rd742;
	madc.hi.cc.u64 c, %rd653, %rd666, 0;
	addc.cc.u64 t, %rd741, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd741, %rd653, %rd667, t;
	madc.hi.cc.u64 c, %rd653, %rd667, nc;
	addc.cc.u64 t, %rd745, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd745, %rd653, %rd668, t;
	madc.hi.cc.u64 c, %rd653, %rd668, nc;
	addc.cc.u64 t, %rd746, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd746, %rd653, %rd669, t;
	madc.hi.cc.u64 c, %rd653, %rd669, nc;
	addc.cc.u64 c, c, %rd648;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd747, %rd747, c;
	addc.u64 %rd648, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd670, %rd741, 725501752471715839;
	mov.u64 	%rd662, %rd746;
	mov.u64 	%rd664, %rd748;
	mov.u64 	%rd663, %rd747;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd670, %rd666, %rd741;
	madc.hi.cc.u64 c, %rd670, %rd666, 0;
	addc.cc.u64 t, %rd745, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd745, %rd670, %rd667, t;
	madc.hi.cc.u64 c, %rd670, %rd667, nc;
	addc.cc.u64 t, %rd662, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd662, %rd670, %rd668, t;
	madc.hi.cc.u64 c, %rd670, %rd668, nc;
	addc.cc.u64 t, %rd663, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd663, %rd670, %rd669, t;
	madc.hi.cc.u64 c, %rd670, %rd669, nc;
	addc.cc.u64 c, c, %rd648;
	addc.cc.u64 %rd664, %rd664, c;
	}
	// end inline asm
	setp.lt.u64 	%p39, %rd664, 1345280370688173398;
	mov.u64 	%rd737, %rd664;
	mov.u64 	%rd738, %rd663;
	mov.u64 	%rd739, %rd662;
	mov.u64 	%rd740, %rd745;
	mov.u64 	%rd746, %rd662;
	mov.u64 	%rd747, %rd663;
	mov.u64 	%rd748, %rd664;
	@%p39 bra 	LBB2_42;

	setp.ne.s64 	%p40, %rd664, 1345280370688173398;
	@%p40 bra 	LBB2_41;

	setp.lt.u64 	%p41, %rd663, 6968279316240510977;
	mov.u64 	%rd737, %rd669;
	mov.u64 	%rd738, %rd663;
	mov.u64 	%rd739, %rd662;
	mov.u64 	%rd740, %rd745;
	mov.u64 	%rd746, %rd662;
	mov.u64 	%rd747, %rd663;
	mov.u64 	%rd748, %rd669;
	@%p41 bra 	LBB2_42;

	setp.ne.s64 	%p42, %rd663, 6968279316240510977;
	@%p42 bra 	LBB2_41;

	setp.lt.u64 	%p43, %rd662, 6461107452199829505;
	mov.u64 	%rd737, %rd669;
	mov.u64 	%rd738, %rd668;
	mov.u64 	%rd739, %rd662;
	mov.u64 	%rd740, %rd745;
	mov.u64 	%rd746, %rd662;
	mov.u64 	%rd747, %rd668;
	mov.u64 	%rd748, %rd669;
	@%p43 bra 	LBB2_42;

	setp.eq.s64 	%p44, %rd662, 6461107452199829505;
	setp.lt.u64 	%p45, %rd745, 725501752471715841;
	and.pred  	%p46, %p44, %p45;
	mov.u64 	%rd737, %rd669;
	mov.u64 	%rd738, %rd668;
	mov.u64 	%rd739, %rd667;
	mov.u64 	%rd740, %rd745;
	mov.u64 	%rd746, %rd667;
	mov.u64 	%rd747, %rd668;
	mov.u64 	%rd748, %rd669;
	@%p46 bra 	LBB2_42;

LBB2_41:
	// begin inline asm
	sub.cc.u64  %rd740, %rd745, %rd666;
	subc.cc.u64 %rd739, %rd662, %rd667;
	subc.cc.u64 %rd738, %rd663, %rd668;
	subc.u64    %rd737, %rd664, %rd669;
	
	// end inline asm
	mov.u64 	%rd746, %rd662;
	mov.u64 	%rd747, %rd663;
	mov.u64 	%rd748, %rd664;
	bra.uni 	LBB2_42;

LBB2_33:
	ret;

}
	// .globl	msm4_io_helper
.visible .entry msm4_io_helper(
	.param .u64 msm4_io_helper_param_0,
	.param .u64 msm4_io_helper_param_1,
	.param .u32 msm4_io_helper_param_2,
	.param .u32 msm4_io_helper_param_3,
	.param .u32 msm4_io_helper_param_4,
	.param .u32 msm4_io_helper_param_5
)
{
	.reg .pred 	%p<29>;
	.reg .b32 	%r<33>;
	.reg .b64 	%rd<287>;


	ld.param.u64 	%rd69, [msm4_io_helper_param_0];
	ld.param.u64 	%rd70, [msm4_io_helper_param_1];
	ld.param.u32 	%r9, [msm4_io_helper_param_3];
	ld.param.u32 	%r11, [msm4_io_helper_param_5];
	mov.u32 	%r12, %ntid.x;
	mov.u32 	%r13, %ctaid.x;
	mul.lo.s32 	%r1, %r13, %r12;
	mov.u32 	%r2, %tid.x;
	add.s32 	%r14, %r1, %r2;
	shl.b32 	%r15, %r14, 3;
	cvt.u64.u32 	%rd273, %r15;
	setp.ge.u32 	%p1, %r15, %r11;
	@%p1 bra 	LBB3_30;

	cvta.to.global.u64 	%rd2, %rd69;
	add.s64 	%rd72, %rd273, 8;
	cvt.u64.u32 	%rd73, %r11;
	min.u64 	%rd3, %rd72, %rd73;
	cvt.u64.u32 	%rd4, %r9;
	shl.b32 	%r16, %r2, 3;
	shl.b32 	%r17, %r1, 3;
	add.s32 	%r32, %r17, %r16;
	cvta.to.global.u64 	%rd5, %rd70;
	bra.uni 	LBB3_2;

LBB3_8:
	setp.gt.u64 	%p6, %rd25, %rd21;
	@%p6 bra 	LBB3_11;

	setp.lt.u64 	%p7, %rd24, %rd20;
	@%p7 bra 	LBB3_12;

	setp.le.u64 	%p8, %rd24, %rd20;
	setp.lt.u64 	%p9, %rd23, %rd19;
	and.pred  	%p10, %p8, %p9;
	@%p10 bra 	LBB3_12;
	bra.uni 	LBB3_11;

LBB3_2:
	and.b64  	%rd74, %rd273, -4294967296;
	setp.eq.s64 	%p2, %rd74, 0;
	@%p2 bra 	LBB3_4;

	div.u64 	%rd274, %rd273, %rd4;
	bra.uni 	LBB3_5;

LBB3_4:
	cvt.u32.u64 	%r18, %rd4;
	cvt.u32.u64 	%r19, %rd273;
	div.u32 	%r20, %r19, %r18;
	cvt.u64.u32 	%rd274, %r20;

LBB3_5:
	ld.param.u32 	%r29, [msm4_io_helper_param_4];
	ld.param.u32 	%r28, [msm4_io_helper_param_2];
	ld.param.u32 	%r27, [msm4_io_helper_param_3];
	add.s32 	%r26, %r27, -1;
	cvt.u32.u64 	%r21, %rd274;
	and.b32  	%r22, %r26, %r32;
	mad.lo.s32 	%r23, %r22, %r28, %r21;
	mul.wide.u32 	%rd75, %r23, 32;
	add.s64 	%rd18, %rd2, %rd75;
	ld.global.u64 	%rd19, [%rd18];
	ld.global.u64 	%rd20, [%rd18+8];
	ld.global.u64 	%rd21, [%rd18+16];
	add.s32 	%r24, %r23, %r29;
	mul.wide.u32 	%rd76, %r24, 32;
	add.s64 	%rd22, %rd2, %rd76;
	ld.global.u64 	%rd23, [%rd22];
	ld.global.u64 	%rd24, [%rd22+8];
	ld.global.u64 	%rd25, [%rd22+16];
	ld.global.u64 	%rd26, [%rd22+24];
	ld.global.u64 	%rd27, [%rd18+24];
	setp.lt.u64 	%p3, %rd26, %rd27;
	@%p3 bra 	LBB3_12;

	setp.gt.u64 	%p4, %rd26, %rd27;
	@%p4 bra 	LBB3_11;
	bra.uni 	LBB3_7;

LBB3_11:
	mov.u64 	%rd85, 725501752471715841;
	mov.u64 	%rd86, 6461107452199829505;
	mov.u64 	%rd87, 6968279316240510977;
	mov.u64 	%rd88, 1345280370688173398;
	// begin inline asm
	add.cc.u64  %rd77, %rd19, %rd85;
	addc.cc.u64 %rd78, %rd20, %rd86;
	addc.cc.u64 %rd79, %rd21, %rd87;
	addc.u64    %rd80, %rd27, %rd88;
	
	// end inline asm
	// begin inline asm
	sub.cc.u64  %rd278, %rd77, %rd23;
	subc.cc.u64 %rd277, %rd78, %rd24;
	subc.cc.u64 %rd276, %rd79, %rd25;
	subc.u64    %rd275, %rd80, %rd26;
	
	// end inline asm
	bra.uni 	LBB3_13;

LBB3_7:
	setp.lt.u64 	%p5, %rd25, %rd21;
	@%p5 bra 	LBB3_12;
	bra.uni 	LBB3_8;

LBB3_12:
	// begin inline asm
	sub.cc.u64  %rd278, %rd19, %rd23;
	subc.cc.u64 %rd277, %rd20, %rd24;
	subc.cc.u64 %rd276, %rd21, %rd25;
	subc.u64    %rd275, %rd27, %rd26;
	
	// end inline asm

LBB3_13:
	// begin inline asm
	add.cc.u64  %rd113, %rd19, %rd23;
	addc.cc.u64 %rd114, %rd20, %rd24;
	addc.cc.u64 %rd115, %rd21, %rd25;
	addc.u64    %rd116, %rd27, %rd26;
	
	// end inline asm
	st.global.u64 	[%rd18], %rd113;
	st.global.u64 	[%rd18+8], %rd114;
	st.global.u64 	[%rd18+16], %rd115;
	st.global.u64 	[%rd18+24], %rd116;
	setp.lt.u64 	%p11, %rd116, 1345280370688173398;
	@%p11 bra 	LBB3_20;

	setp.ne.s64 	%p12, %rd116, 1345280370688173398;
	@%p12 bra 	LBB3_19;

	setp.lt.u64 	%p13, %rd115, 6968279316240510977;
	@%p13 bra 	LBB3_20;

	setp.ne.s64 	%p14, %rd115, 6968279316240510977;
	@%p14 bra 	LBB3_19;

	setp.lt.u64 	%p15, %rd114, 6461107452199829505;
	@%p15 bra 	LBB3_20;

	setp.eq.s64 	%p16, %rd114, 6461107452199829505;
	setp.lt.u64 	%p17, %rd113, 725501752471715841;
	and.pred  	%p18, %p16, %p17;
	@%p18 bra 	LBB3_20;

LBB3_19:
	mov.u64 	%rd133, 725501752471715841;
	mov.u64 	%rd134, 6461107452199829505;
	mov.u64 	%rd135, 6968279316240510977;
	mov.u64 	%rd136, 1345280370688173398;
	// begin inline asm
	sub.cc.u64  %rd125, %rd113, %rd133;
	subc.cc.u64 %rd126, %rd114, %rd134;
	subc.cc.u64 %rd127, %rd115, %rd135;
	subc.u64    %rd128, %rd116, %rd136;
	
	// end inline asm
	st.global.u64 	[%rd18], %rd125;
	st.global.u64 	[%rd18+8], %rd126;
	st.global.u64 	[%rd18+16], %rd127;
	st.global.u64 	[%rd18+24], %rd128;

LBB3_20:
	ld.param.u32 	%r31, [msm4_io_helper_param_3];
	neg.s32 	%r30, %r31;
	and.b32  	%r25, %r32, %r30;
	mul.wide.u32 	%rd161, %r25, 32;
	add.s64 	%rd162, %rd5, %rd161;
	ld.global.u64 	%rd149, [%rd162];
	ld.global.u64 	%rd150, [%rd162+8];
	ld.global.u64 	%rd151, [%rd162+16];
	ld.global.u64 	%rd152, [%rd162+24];
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 nc;
	.reg .u64 t;
	mad.lo.cc.u64  %rd282, %rd278, %rd149, 0;
	madc.hi.cc.u64  c, %rd278, %rd149, 0;
	madc.lo.cc.u64 %rd281, %rd278, %rd150, c;
	madc.hi.cc.u64  c, %rd278, %rd150, 0;
	madc.lo.cc.u64 %rd280, %rd278, %rd151, c;
	madc.hi.cc.u64  c, %rd278, %rd151, 0;
	madc.lo.cc.u64 %rd279, %rd278, %rd152, c;
	madc.hi.u64    %rd283, %rd278, %rd152, 0;
	mad.lo.cc.u64  %rd281, %rd277, %rd149, %rd281;
	madc.hi.cc.u64  c, %rd277, %rd149, 0;
	addc.cc.u64     t, %rd280, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd280, %rd277, %rd150, t;
	madc.hi.cc.u64  c, %rd277, %rd150, nc;
	addc.cc.u64     t, %rd279, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd279, %rd277, %rd151, t;
	madc.hi.cc.u64  c, %rd277, %rd151, nc;
	addc.cc.u64     t, %rd283, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd283, %rd277, %rd152, t;
	madc.hi.u64    %rd284, %rd277, %rd152, nc;
	mad.lo.cc.u64  %rd280, %rd276, %rd149, %rd280;
	madc.hi.cc.u64  c, %rd276, %rd149, 0;
	addc.cc.u64     t, %rd279, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd279, %rd276, %rd150, t;
	madc.hi.cc.u64  c, %rd276, %rd150, nc;
	addc.cc.u64     t, %rd283, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd283, %rd276, %rd151, t;
	madc.hi.cc.u64  c, %rd276, %rd151, nc;
	addc.cc.u64     t, %rd284, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd284, %rd276, %rd152, t;
	madc.hi.u64    %rd285, %rd276, %rd152, nc;
	mad.lo.cc.u64  %rd279, %rd275, %rd149, %rd279;
	madc.hi.cc.u64  c, %rd275, %rd149, 0;
	addc.cc.u64     t, %rd283, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd283, %rd275, %rd150, t;
	madc.hi.cc.u64  c, %rd275, %rd150, nc;
	addc.cc.u64     t, %rd284, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd284, %rd275, %rd151, t;
	madc.hi.cc.u64  c, %rd275, %rd151, nc;
	addc.cc.u64     t, %rd285, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd285, %rd275, %rd152, t;
	madc.hi.u64    %rd286, %rd275, %rd152, nc;
	}
	// end inline asm
	or.b64  	%rd163, %rd282, %rd281;
	or.b64  	%rd164, %rd163, %rd280;
	or.b64  	%rd165, %rd164, %rd279;
	or.b64  	%rd166, %rd165, %rd283;
	or.b64  	%rd167, %rd166, %rd284;
	or.b64  	%rd168, %rd167, %rd285;
	or.b64  	%rd169, %rd168, %rd286;
	setp.eq.s64 	%p19, %rd169, 0;
	@%p19 bra 	LBB3_28;

	mul.lo.s64 	%rd180, %rd282, 725501752471715839;
	mov.u64 	%rd226, 725501752471715841;
	mov.u64 	%rd227, 6461107452199829505;
	mov.u64 	%rd228, 6968279316240510977;
	mov.u64 	%rd229, 1345280370688173398;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd180, %rd226, %rd282;
	madc.hi.cc.u64 c, %rd180, %rd226, 0;
	addc.cc.u64 t, %rd281, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd281, %rd180, %rd227, t;
	madc.hi.cc.u64 c, %rd180, %rd227, nc;
	addc.cc.u64 t, %rd280, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd280, %rd180, %rd228, t;
	madc.hi.cc.u64 c, %rd180, %rd228, nc;
	addc.cc.u64 t, %rd279, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd279, %rd180, %rd229, t;
	madc.hi.cc.u64 c, %rd180, %rd229, nc;
	addc.cc.u64 %rd283, %rd283, c;
	addc.u64 %rd208, 0, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd196, %rd281, 725501752471715839;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd196, %rd226, %rd281;
	madc.hi.cc.u64 c, %rd196, %rd226, 0;
	addc.cc.u64 t, %rd280, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd280, %rd196, %rd227, t;
	madc.hi.cc.u64 c, %rd196, %rd227, nc;
	addc.cc.u64 t, %rd279, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd279, %rd196, %rd228, t;
	madc.hi.cc.u64 c, %rd196, %rd228, nc;
	addc.cc.u64 t, %rd283, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd283, %rd196, %rd229, t;
	madc.hi.cc.u64 c, %rd196, %rd229, nc;
	addc.cc.u64 c, c, %rd208;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd284, %rd284, c;
	addc.u64 %rd208, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd213, %rd280, 725501752471715839;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd213, %rd226, %rd280;
	madc.hi.cc.u64 c, %rd213, %rd226, 0;
	addc.cc.u64 t, %rd279, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd279, %rd213, %rd227, t;
	madc.hi.cc.u64 c, %rd213, %rd227, nc;
	addc.cc.u64 t, %rd283, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd283, %rd213, %rd228, t;
	madc.hi.cc.u64 c, %rd213, %rd228, nc;
	addc.cc.u64 t, %rd284, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd284, %rd213, %rd229, t;
	madc.hi.cc.u64 c, %rd213, %rd229, nc;
	addc.cc.u64 c, c, %rd208;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd285, %rd285, c;
	addc.u64 %rd208, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd230, %rd279, 725501752471715839;
	mov.u64 	%rd223, %rd285;
	mov.u64 	%rd222, %rd284;
	mov.u64 	%rd224, %rd286;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd230, %rd226, %rd279;
	madc.hi.cc.u64 c, %rd230, %rd226, 0;
	addc.cc.u64 t, %rd283, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd283, %rd230, %rd227, t;
	madc.hi.cc.u64 c, %rd230, %rd227, nc;
	addc.cc.u64 t, %rd222, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd222, %rd230, %rd228, t;
	madc.hi.cc.u64 c, %rd230, %rd228, nc;
	addc.cc.u64 t, %rd223, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd223, %rd230, %rd229, t;
	madc.hi.cc.u64 c, %rd230, %rd229, nc;
	addc.cc.u64 c, c, %rd208;
	addc.cc.u64 %rd224, %rd224, c;
	}
	// end inline asm
	st.global.u64 	[%rd22], %rd283;
	st.global.u64 	[%rd22+8], %rd222;
	st.global.u64 	[%rd22+16], %rd223;
	st.global.u64 	[%rd22+24], %rd224;
	setp.lt.u64 	%p20, %rd224, 1345280370688173398;
	mov.u64 	%rd284, %rd222;
	mov.u64 	%rd285, %rd223;
	mov.u64 	%rd286, %rd224;
	@%p20 bra 	LBB3_29;

	setp.ne.s64 	%p21, %rd224, 1345280370688173398;
	@%p21 bra 	LBB3_27;

	mov.u64 	%rd286, 1345280370688173398;
	setp.lt.u64 	%p22, %rd223, 6968279316240510977;
	mov.u64 	%rd284, %rd222;
	mov.u64 	%rd285, %rd223;
	@%p22 bra 	LBB3_29;

	setp.ne.s64 	%p23, %rd223, 6968279316240510977;
	@%p23 bra 	LBB3_27;

	mov.u64 	%rd286, 1345280370688173398;
	mov.u64 	%rd285, 6968279316240510977;
	setp.lt.u64 	%p24, %rd222, 6461107452199829505;
	mov.u64 	%rd284, %rd222;
	@%p24 bra 	LBB3_29;

	mov.u64 	%rd286, 1345280370688173398;
	mov.u64 	%rd285, 6968279316240510977;
	mov.u64 	%rd284, 6461107452199829505;
	setp.eq.s64 	%p25, %rd222, 6461107452199829505;
	setp.lt.u64 	%p26, %rd283, 725501752471715841;
	and.pred  	%p27, %p25, %p26;
	@%p27 bra 	LBB3_29;

LBB3_27:
	mov.u64 	%rd258, 1345280370688173398;
	mov.u64 	%rd257, 6968279316240510977;
	mov.u64 	%rd256, 6461107452199829505;
	mov.u64 	%rd255, 725501752471715841;
	// begin inline asm
	sub.cc.u64  %rd242, %rd283, %rd255;
	subc.cc.u64 %rd243, %rd222, %rd256;
	subc.cc.u64 %rd244, %rd223, %rd257;
	subc.u64    %rd245, %rd224, %rd258;
	
	// end inline asm
	st.global.u64 	[%rd22], %rd242;
	st.global.u64 	[%rd22+8], %rd243;
	st.global.u64 	[%rd22+16], %rd244;
	st.global.u64 	[%rd22+24], %rd245;
	mov.u64 	%rd284, %rd222;
	mov.u64 	%rd285, %rd223;
	mov.u64 	%rd286, %rd224;
	bra.uni 	LBB3_29;

LBB3_28:
	mov.u64 	%rd254, 0;
	st.global.u64 	[%rd22], %rd254;
	st.global.u64 	[%rd22+8], %rd254;
	st.global.u64 	[%rd22+16], %rd254;
	st.global.u64 	[%rd22+24], %rd254;

LBB3_29:
	add.s32 	%r32, %r32, 1;
	add.s64 	%rd273, %rd273, 1;
	setp.lt.u64 	%p28, %rd273, %rd3;
	@%p28 bra 	LBB3_2;

LBB3_30:
	ret;

}
	// .globl	msm4_oi_helper
.visible .entry msm4_oi_helper(
	.param .u64 msm4_oi_helper_param_0,
	.param .u64 msm4_oi_helper_param_1,
	.param .u32 msm4_oi_helper_param_2,
	.param .u32 msm4_oi_helper_param_3,
	.param .u32 msm4_oi_helper_param_4,
	.param .u32 msm4_oi_helper_param_5
)
{
	.reg .pred 	%p<29>;
	.reg .b32 	%r<40>;
	.reg .b64 	%rd<310>;


	ld.param.u64 	%rd74, [msm4_oi_helper_param_1];
	ld.param.u32 	%r9, [msm4_oi_helper_param_3];
	ld.param.u32 	%r11, [msm4_oi_helper_param_5];
	mov.u32 	%r12, %ntid.x;
	mov.u32 	%r13, %ctaid.x;
	mul.lo.s32 	%r1, %r13, %r12;
	mov.u32 	%r2, %tid.x;
	add.s32 	%r14, %r1, %r2;
	shl.b32 	%r15, %r14, 3;
	cvt.u64.u32 	%rd292, %r15;
	setp.ge.u32 	%p1, %r15, %r11;
	@%p1 bra 	LBB4_29;

	add.s64 	%rd76, %rd292, 8;
	cvt.u64.u32 	%rd77, %r11;
	min.u64 	%rd3, %rd76, %rd77;
	cvt.u64.u32 	%rd4, %r9;
	shl.b32 	%r16, %r2, 3;
	shl.b32 	%r17, %r1, 3;
	add.s32 	%r39, %r17, %r16;
	cvta.to.global.u64 	%rd5, %rd74;
	bra.uni 	LBB4_2;

LBB4_16:
	setp.gt.u64 	%p15, %rd295, %rd21;
	@%p15 bra 	LBB4_19;

	setp.lt.u64 	%p16, %rd296, %rd20;
	@%p16 bra 	LBB4_20;

	setp.le.u64 	%p17, %rd296, %rd20;
	setp.lt.u64 	%p18, %rd297, %rd19;
	and.pred  	%p19, %p17, %p18;
	@%p19 bra 	LBB4_20;
	bra.uni 	LBB4_19;

LBB4_2:
	and.b64  	%rd78, %rd292, -4294967296;
	setp.eq.s64 	%p2, %rd78, 0;
	@%p2 bra 	LBB4_4;

	div.u64 	%rd293, %rd292, %rd4;
	bra.uni 	LBB4_5;

LBB4_4:
	cvt.u32.u64 	%r18, %rd4;
	cvt.u32.u64 	%r19, %rd292;
	div.u32 	%r20, %r19, %r18;
	cvt.u64.u32 	%rd293, %r20;

LBB4_5:
	ld.param.u32 	%r38, [msm4_oi_helper_param_3];
	add.s32 	%r37, %r38, -1;
	ld.param.u32 	%r36, [msm4_oi_helper_param_4];
	ld.param.u32 	%r35, [msm4_oi_helper_param_2];
	ld.param.u64 	%rd279, [msm4_oi_helper_param_0];
	cvta.to.global.u64 	%rd278, %rd279;
	neg.s32 	%r34, %r38;
	cvt.u32.u64 	%r21, %rd293;
	and.b32  	%r22, %r37, %r39;
	mad.lo.s32 	%r23, %r22, %r35, %r21;
	mul.wide.u32 	%rd107, %r23, 32;
	add.s64 	%rd18, %rd278, %rd107;
	ld.global.u64 	%rd19, [%rd18];
	mov.u64 	%rd294, 0;
	ld.global.u64 	%rd20, [%rd18+8];
	ld.global.u64 	%rd21, [%rd18+16];
	ld.global.u64 	%rd22, [%rd18+24];
	add.s32 	%r24, %r23, %r36;
	mul.wide.u32 	%rd108, %r24, 32;
	add.s64 	%rd23, %rd278, %rd108;
	ld.global.u64 	%rd87, [%rd23];
	ld.global.u64 	%rd88, [%rd23+8];
	ld.global.u64 	%rd89, [%rd23+16];
	ld.global.u64 	%rd90, [%rd23+24];
	and.b32  	%r25, %r39, %r34;
	mul.wide.u32 	%rd109, %r25, 32;
	add.s64 	%rd110, %rd5, %rd109;
	ld.global.u64 	%rd91, [%rd110];
	ld.global.u64 	%rd92, [%rd110+8];
	ld.global.u64 	%rd93, [%rd110+16];
	ld.global.u64 	%rd94, [%rd110+24];
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 nc;
	.reg .u64 t;
	mad.lo.cc.u64  %rd305, %rd87, %rd91, 0;
	madc.hi.cc.u64  c, %rd87, %rd91, 0;
	madc.lo.cc.u64 %rd304, %rd87, %rd92, c;
	madc.hi.cc.u64  c, %rd87, %rd92, 0;
	madc.lo.cc.u64 %rd303, %rd87, %rd93, c;
	madc.hi.cc.u64  c, %rd87, %rd93, 0;
	madc.lo.cc.u64 %rd302, %rd87, %rd94, c;
	madc.hi.u64    %rd301, %rd87, %rd94, 0;
	mad.lo.cc.u64  %rd304, %rd88, %rd91, %rd304;
	madc.hi.cc.u64  c, %rd88, %rd91, 0;
	addc.cc.u64     t, %rd303, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd303, %rd88, %rd92, t;
	madc.hi.cc.u64  c, %rd88, %rd92, nc;
	addc.cc.u64     t, %rd302, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd302, %rd88, %rd93, t;
	madc.hi.cc.u64  c, %rd88, %rd93, nc;
	addc.cc.u64     t, %rd301, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd301, %rd88, %rd94, t;
	madc.hi.u64    %rd300, %rd88, %rd94, nc;
	mad.lo.cc.u64  %rd303, %rd89, %rd91, %rd303;
	madc.hi.cc.u64  c, %rd89, %rd91, 0;
	addc.cc.u64     t, %rd302, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd302, %rd89, %rd92, t;
	madc.hi.cc.u64  c, %rd89, %rd92, nc;
	addc.cc.u64     t, %rd301, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd301, %rd89, %rd93, t;
	madc.hi.cc.u64  c, %rd89, %rd93, nc;
	addc.cc.u64     t, %rd300, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd300, %rd89, %rd94, t;
	madc.hi.u64    %rd299, %rd89, %rd94, nc;
	mad.lo.cc.u64  %rd302, %rd90, %rd91, %rd302;
	madc.hi.cc.u64  c, %rd90, %rd91, 0;
	addc.cc.u64     t, %rd301, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd301, %rd90, %rd92, t;
	madc.hi.cc.u64  c, %rd90, %rd92, nc;
	addc.cc.u64     t, %rd300, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd300, %rd90, %rd93, t;
	madc.hi.cc.u64  c, %rd90, %rd93, nc;
	addc.cc.u64     t, %rd299, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd299, %rd90, %rd94, t;
	madc.hi.u64    %rd298, %rd90, %rd94, nc;
	}
	// end inline asm
	or.b64  	%rd111, %rd305, %rd304;
	or.b64  	%rd112, %rd111, %rd303;
	or.b64  	%rd113, %rd112, %rd302;
	or.b64  	%rd114, %rd113, %rd301;
	or.b64  	%rd115, %rd114, %rd300;
	or.b64  	%rd116, %rd115, %rd299;
	or.b64  	%rd117, %rd116, %rd298;
	setp.eq.s64 	%p3, %rd117, 0;
	mov.u64 	%rd295, %rd294;
	mov.u64 	%rd296, %rd294;
	mov.u64 	%rd297, %rd294;
	@%p3 bra 	LBB4_13;

	mul.lo.s64 	%rd128, %rd305, 725501752471715839;
	mov.u64 	%rd174, 725501752471715841;
	mov.u64 	%rd175, 6461107452199829505;
	mov.u64 	%rd176, 6968279316240510977;
	mov.u64 	%rd177, 1345280370688173398;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd128, %rd174, %rd305;
	madc.hi.cc.u64 c, %rd128, %rd174, 0;
	addc.cc.u64 t, %rd304, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd304, %rd128, %rd175, t;
	madc.hi.cc.u64 c, %rd128, %rd175, nc;
	addc.cc.u64 t, %rd303, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd303, %rd128, %rd176, t;
	madc.hi.cc.u64 c, %rd128, %rd176, nc;
	addc.cc.u64 t, %rd302, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd302, %rd128, %rd177, t;
	madc.hi.cc.u64 c, %rd128, %rd177, nc;
	addc.cc.u64 %rd301, %rd301, c;
	addc.u64 %rd156, 0, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd144, %rd304, 725501752471715839;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd144, %rd174, %rd304;
	madc.hi.cc.u64 c, %rd144, %rd174, 0;
	addc.cc.u64 t, %rd303, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd303, %rd144, %rd175, t;
	madc.hi.cc.u64 c, %rd144, %rd175, nc;
	addc.cc.u64 t, %rd302, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd302, %rd144, %rd176, t;
	madc.hi.cc.u64 c, %rd144, %rd176, nc;
	addc.cc.u64 t, %rd301, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd301, %rd144, %rd177, t;
	madc.hi.cc.u64 c, %rd144, %rd177, nc;
	addc.cc.u64 c, c, %rd156;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd300, %rd300, c;
	addc.u64 %rd156, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd161, %rd303, 725501752471715839;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd161, %rd174, %rd303;
	madc.hi.cc.u64 c, %rd161, %rd174, 0;
	addc.cc.u64 t, %rd302, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd302, %rd161, %rd175, t;
	madc.hi.cc.u64 c, %rd161, %rd175, nc;
	addc.cc.u64 t, %rd301, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd301, %rd161, %rd176, t;
	madc.hi.cc.u64 c, %rd161, %rd176, nc;
	addc.cc.u64 t, %rd300, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd300, %rd161, %rd177, t;
	madc.hi.cc.u64 c, %rd161, %rd177, nc;
	addc.cc.u64 c, c, %rd156;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd299, %rd299, c;
	addc.u64 %rd156, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd178, %rd302, 725501752471715839;
	mov.u64 	%rd171, %rd299;
	mov.u64 	%rd170, %rd300;
	mov.u64 	%rd172, %rd298;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd178, %rd174, %rd302;
	madc.hi.cc.u64 c, %rd178, %rd174, 0;
	addc.cc.u64 t, %rd301, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd301, %rd178, %rd175, t;
	madc.hi.cc.u64 c, %rd178, %rd175, nc;
	addc.cc.u64 t, %rd170, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd170, %rd178, %rd176, t;
	madc.hi.cc.u64 c, %rd178, %rd176, nc;
	addc.cc.u64 t, %rd171, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd171, %rd178, %rd177, t;
	madc.hi.cc.u64 c, %rd178, %rd177, nc;
	addc.cc.u64 c, c, %rd156;
	addc.cc.u64 %rd172, %rd172, c;
	}
	// end inline asm
	setp.lt.u64 	%p4, %rd172, 1345280370688173398;
	mov.u64 	%rd294, %rd172;
	mov.u64 	%rd295, %rd171;
	mov.u64 	%rd296, %rd170;
	mov.u64 	%rd297, %rd301;
	mov.u64 	%rd298, %rd172;
	mov.u64 	%rd299, %rd171;
	mov.u64 	%rd300, %rd170;
	@%p4 bra 	LBB4_13;

	setp.ne.s64 	%p5, %rd172, 1345280370688173398;
	@%p5 bra 	LBB4_12;

	mov.u64 	%rd294, 1345280370688173398;
	setp.lt.u64 	%p6, %rd171, 6968279316240510977;
	mov.u64 	%rd295, %rd171;
	mov.u64 	%rd296, %rd170;
	mov.u64 	%rd297, %rd301;
	mov.u64 	%rd298, %rd294;
	mov.u64 	%rd299, %rd171;
	mov.u64 	%rd300, %rd170;
	@%p6 bra 	LBB4_13;

	setp.ne.s64 	%p7, %rd171, 6968279316240510977;
	@%p7 bra 	LBB4_12;

	mov.u64 	%rd294, 1345280370688173398;
	mov.u64 	%rd295, 6968279316240510977;
	setp.lt.u64 	%p8, %rd170, 6461107452199829505;
	mov.u64 	%rd296, %rd170;
	mov.u64 	%rd297, %rd301;
	mov.u64 	%rd298, %rd294;
	mov.u64 	%rd299, %rd295;
	mov.u64 	%rd300, %rd170;
	@%p8 bra 	LBB4_13;

	mov.u64 	%rd294, 1345280370688173398;
	mov.u64 	%rd295, 6968279316240510977;
	mov.u64 	%rd296, 6461107452199829505;
	setp.eq.s64 	%p9, %rd170, 6461107452199829505;
	setp.lt.u64 	%p10, %rd301, 725501752471715841;
	and.pred  	%p11, %p9, %p10;
	mov.u64 	%rd297, %rd301;
	mov.u64 	%rd298, %rd294;
	mov.u64 	%rd299, %rd295;
	mov.u64 	%rd300, %rd296;
	@%p11 bra 	LBB4_13;

LBB4_12:
	mov.u64 	%rd280, 1345280370688173398;
	mov.u64 	%rd270, 6968279316240510977;
	mov.u64 	%rd269, 6461107452199829505;
	mov.u64 	%rd268, 725501752471715841;
	// begin inline asm
	sub.cc.u64  %rd297, %rd301, %rd268;
	subc.cc.u64 %rd296, %rd170, %rd269;
	subc.cc.u64 %rd295, %rd171, %rd270;
	subc.u64    %rd294, %rd172, %rd280;
	
	// end inline asm
	mov.u64 	%rd298, %rd172;
	mov.u64 	%rd299, %rd171;
	mov.u64 	%rd300, %rd170;

LBB4_13:
	setp.lt.u64 	%p12, %rd294, %rd22;
	@%p12 bra 	LBB4_20;

	setp.gt.u64 	%p13, %rd294, %rd22;
	@%p13 bra 	LBB4_19;
	bra.uni 	LBB4_15;

LBB4_19:
	mov.u64 	%rd216, 725501752471715841;
	mov.u64 	%rd217, 6461107452199829505;
	mov.u64 	%rd218, 6968279316240510977;
	mov.u64 	%rd219, 1345280370688173398;
	// begin inline asm
	add.cc.u64  %rd208, %rd19, %rd216;
	addc.cc.u64 %rd209, %rd20, %rd217;
	addc.cc.u64 %rd210, %rd21, %rd218;
	addc.u64    %rd211, %rd22, %rd219;
	
	// end inline asm
	// begin inline asm
	sub.cc.u64  %rd309, %rd208, %rd297;
	subc.cc.u64 %rd308, %rd209, %rd296;
	subc.cc.u64 %rd307, %rd210, %rd295;
	subc.u64    %rd306, %rd211, %rd294;
	
	// end inline asm
	bra.uni 	LBB4_21;

LBB4_15:
	setp.lt.u64 	%p14, %rd295, %rd21;
	@%p14 bra 	LBB4_20;
	bra.uni 	LBB4_16;

LBB4_20:
	// begin inline asm
	sub.cc.u64  %rd309, %rd19, %rd297;
	subc.cc.u64 %rd308, %rd20, %rd296;
	subc.cc.u64 %rd307, %rd21, %rd295;
	subc.u64    %rd306, %rd22, %rd294;
	
	// end inline asm

LBB4_21:
	// begin inline asm
	add.cc.u64  %rd244, %rd19, %rd297;
	addc.cc.u64 %rd245, %rd20, %rd296;
	addc.cc.u64 %rd246, %rd21, %rd295;
	addc.u64    %rd247, %rd22, %rd294;
	
	// end inline asm
	st.global.u64 	[%rd18], %rd244;
	st.global.u64 	[%rd18+8], %rd245;
	st.global.u64 	[%rd18+16], %rd246;
	st.global.u64 	[%rd18+24], %rd247;
	setp.lt.u64 	%p20, %rd247, 1345280370688173398;
	@%p20 bra 	LBB4_28;

	setp.ne.s64 	%p21, %rd247, 1345280370688173398;
	@%p21 bra 	LBB4_27;

	setp.lt.u64 	%p22, %rd246, 6968279316240510977;
	@%p22 bra 	LBB4_28;

	setp.ne.s64 	%p23, %rd246, 6968279316240510977;
	@%p23 bra 	LBB4_27;

	setp.lt.u64 	%p24, %rd245, 6461107452199829505;
	@%p24 bra 	LBB4_28;

	setp.eq.s64 	%p25, %rd245, 6461107452199829505;
	setp.lt.u64 	%p26, %rd244, 725501752471715841;
	and.pred  	%p27, %p25, %p26;
	@%p27 bra 	LBB4_28;

LBB4_27:
	mov.u64 	%rd264, 725501752471715841;
	mov.u64 	%rd265, 6461107452199829505;
	mov.u64 	%rd266, 6968279316240510977;
	mov.u64 	%rd267, 1345280370688173398;
	// begin inline asm
	sub.cc.u64  %rd256, %rd244, %rd264;
	subc.cc.u64 %rd257, %rd245, %rd265;
	subc.cc.u64 %rd258, %rd246, %rd266;
	subc.u64    %rd259, %rd247, %rd267;
	
	// end inline asm
	st.global.u64 	[%rd18], %rd256;
	st.global.u64 	[%rd18+8], %rd257;
	st.global.u64 	[%rd18+16], %rd258;
	st.global.u64 	[%rd18+24], %rd259;

LBB4_28:
	ld.param.u64 	%rd277, [msm4_oi_helper_param_0];
	ld.param.u32 	%r33, [msm4_oi_helper_param_3];
	add.s32 	%r32, %r33, -1;
	cvt.u32.u64 	%r31, %rd293;
	ld.param.u32 	%r30, [msm4_oi_helper_param_2];
	and.b32  	%r29, %r32, %r39;
	ld.param.u32 	%r28, [msm4_oi_helper_param_4];
	mad.lo.s32 	%r27, %r29, %r30, %r31;
	add.s32 	%r26, %r27, %r28;
	mul.wide.u32 	%rd276, %r26, 32;
	cvta.to.global.u64 	%rd275, %rd277;
	add.s64 	%rd274, %rd275, %rd276;
	st.global.u64 	[%rd274], %rd309;
	st.global.u64 	[%rd274+8], %rd308;
	st.global.u64 	[%rd274+16], %rd307;
	st.global.u64 	[%rd274+24], %rd306;
	add.s32 	%r39, %r39, 1;
	add.s64 	%rd292, %rd292, 1;
	setp.lt.u64 	%p28, %rd292, %rd3;
	@%p28 bra 	LBB4_2;

LBB4_29:
	ret;

}
	// .globl	msm4_mul_assign
.visible .entry msm4_mul_assign(
	.param .u64 msm4_mul_assign_param_0,
	.param .u64 msm4_mul_assign_param_1,
	.param .u32 msm4_mul_assign_param_2
)
{
	.reg .pred 	%p<12>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<193>;


	ld.param.u64 	%rd41, [msm4_mul_assign_param_0];
	ld.param.u64 	%rd42, [msm4_mul_assign_param_1];
	ld.param.u32 	%r1, [msm4_mul_assign_param_2];
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %tid.x;
	mad.lo.s32 	%r5, %r3, %r2, %r4;
	shl.b32 	%r6, %r5, 3;
	cvt.u64.u32 	%rd184, %r6;
	setp.ge.u32 	%p1, %r6, %r1;
	@%p1 bra 	LBB5_12;

	add.s64 	%rd44, %rd184, 8;
	cvt.u64.u32 	%rd45, %r1;
	min.u64 	%rd2, %rd44, %rd45;
	cvta.to.global.u64 	%rd46, %rd41;
	shl.b64 	%rd47, %rd184, 5;
	add.s64 	%rd48, %rd46, %rd47;
	add.s64 	%rd175, %rd48, 16;
	cvta.to.global.u64 	%rd4, %rd42;

LBB5_2:
	ld.global.u64 	%rd57, [%rd175+-16];
	ld.global.u64 	%rd58, [%rd175+-8];
	ld.global.u64 	%rd59, [%rd175];
	ld.global.u64 	%rd60, [%rd175+8];
	ld.global.u64 	%rd61, [%rd4];
	ld.global.u64 	%rd62, [%rd4+8];
	ld.global.u64 	%rd63, [%rd4+16];
	ld.global.u64 	%rd64, [%rd4+24];
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 nc;
	.reg .u64 t;
	mad.lo.cc.u64  %rd192, %rd57, %rd61, 0;
	madc.hi.cc.u64  c, %rd57, %rd61, 0;
	madc.lo.cc.u64 %rd191, %rd57, %rd62, c;
	madc.hi.cc.u64  c, %rd57, %rd62, 0;
	madc.lo.cc.u64 %rd190, %rd57, %rd63, c;
	madc.hi.cc.u64  c, %rd57, %rd63, 0;
	madc.lo.cc.u64 %rd189, %rd57, %rd64, c;
	madc.hi.u64    %rd188, %rd57, %rd64, 0;
	mad.lo.cc.u64  %rd191, %rd58, %rd61, %rd191;
	madc.hi.cc.u64  c, %rd58, %rd61, 0;
	addc.cc.u64     t, %rd190, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd190, %rd58, %rd62, t;
	madc.hi.cc.u64  c, %rd58, %rd62, nc;
	addc.cc.u64     t, %rd189, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd189, %rd58, %rd63, t;
	madc.hi.cc.u64  c, %rd58, %rd63, nc;
	addc.cc.u64     t, %rd188, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd188, %rd58, %rd64, t;
	madc.hi.u64    %rd187, %rd58, %rd64, nc;
	mad.lo.cc.u64  %rd190, %rd59, %rd61, %rd190;
	madc.hi.cc.u64  c, %rd59, %rd61, 0;
	addc.cc.u64     t, %rd189, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd189, %rd59, %rd62, t;
	madc.hi.cc.u64  c, %rd59, %rd62, nc;
	addc.cc.u64     t, %rd188, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd188, %rd59, %rd63, t;
	madc.hi.cc.u64  c, %rd59, %rd63, nc;
	addc.cc.u64     t, %rd187, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd187, %rd59, %rd64, t;
	madc.hi.u64    %rd186, %rd59, %rd64, nc;
	mad.lo.cc.u64  %rd189, %rd60, %rd61, %rd189;
	madc.hi.cc.u64  c, %rd60, %rd61, 0;
	addc.cc.u64     t, %rd188, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd188, %rd60, %rd62, t;
	madc.hi.cc.u64  c, %rd60, %rd62, nc;
	addc.cc.u64     t, %rd187, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd187, %rd60, %rd63, t;
	madc.hi.cc.u64  c, %rd60, %rd63, nc;
	addc.cc.u64     t, %rd186, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd186, %rd60, %rd64, t;
	madc.hi.u64    %rd185, %rd60, %rd64, nc;
	}
	// end inline asm
	or.b64  	%rd73, %rd192, %rd191;
	or.b64  	%rd74, %rd73, %rd190;
	or.b64  	%rd75, %rd74, %rd189;
	or.b64  	%rd76, %rd75, %rd188;
	or.b64  	%rd77, %rd76, %rd187;
	or.b64  	%rd78, %rd77, %rd186;
	or.b64  	%rd79, %rd78, %rd185;
	setp.eq.s64 	%p2, %rd79, 0;
	@%p2 bra 	LBB5_10;

	mul.lo.s64 	%rd90, %rd192, 725501752471715839;
	mov.u64 	%rd136, 725501752471715841;
	mov.u64 	%rd137, 6461107452199829505;
	mov.u64 	%rd138, 6968279316240510977;
	mov.u64 	%rd139, 1345280370688173398;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd90, %rd136, %rd192;
	madc.hi.cc.u64 c, %rd90, %rd136, 0;
	addc.cc.u64 t, %rd191, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd191, %rd90, %rd137, t;
	madc.hi.cc.u64 c, %rd90, %rd137, nc;
	addc.cc.u64 t, %rd190, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd190, %rd90, %rd138, t;
	madc.hi.cc.u64 c, %rd90, %rd138, nc;
	addc.cc.u64 t, %rd189, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd189, %rd90, %rd139, t;
	madc.hi.cc.u64 c, %rd90, %rd139, nc;
	addc.cc.u64 %rd188, %rd188, c;
	addc.u64 %rd118, 0, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd106, %rd191, 725501752471715839;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd106, %rd136, %rd191;
	madc.hi.cc.u64 c, %rd106, %rd136, 0;
	addc.cc.u64 t, %rd190, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd190, %rd106, %rd137, t;
	madc.hi.cc.u64 c, %rd106, %rd137, nc;
	addc.cc.u64 t, %rd189, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd189, %rd106, %rd138, t;
	madc.hi.cc.u64 c, %rd106, %rd138, nc;
	addc.cc.u64 t, %rd188, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd188, %rd106, %rd139, t;
	madc.hi.cc.u64 c, %rd106, %rd139, nc;
	addc.cc.u64 c, c, %rd118;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd187, %rd187, c;
	addc.u64 %rd118, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd123, %rd190, 725501752471715839;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd123, %rd136, %rd190;
	madc.hi.cc.u64 c, %rd123, %rd136, 0;
	addc.cc.u64 t, %rd189, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd189, %rd123, %rd137, t;
	madc.hi.cc.u64 c, %rd123, %rd137, nc;
	addc.cc.u64 t, %rd188, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd188, %rd123, %rd138, t;
	madc.hi.cc.u64 c, %rd123, %rd138, nc;
	addc.cc.u64 t, %rd187, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd187, %rd123, %rd139, t;
	madc.hi.cc.u64 c, %rd123, %rd139, nc;
	addc.cc.u64 c, c, %rd118;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd186, %rd186, c;
	addc.u64 %rd118, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd140, %rd189, 725501752471715839;
	mov.u64 	%rd132, %rd187;
	mov.u64 	%rd133, %rd186;
	mov.u64 	%rd134, %rd185;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd140, %rd136, %rd189;
	madc.hi.cc.u64 c, %rd140, %rd136, 0;
	addc.cc.u64 t, %rd188, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd188, %rd140, %rd137, t;
	madc.hi.cc.u64 c, %rd140, %rd137, nc;
	addc.cc.u64 t, %rd132, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd132, %rd140, %rd138, t;
	madc.hi.cc.u64 c, %rd140, %rd138, nc;
	addc.cc.u64 t, %rd133, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd133, %rd140, %rd139, t;
	madc.hi.cc.u64 c, %rd140, %rd139, nc;
	addc.cc.u64 c, c, %rd118;
	addc.cc.u64 %rd134, %rd134, c;
	}
	// end inline asm
	st.global.u64 	[%rd175+-16], %rd188;
	st.global.u64 	[%rd175+-8], %rd132;
	st.global.u64 	[%rd175], %rd133;
	st.global.u64 	[%rd175+8], %rd134;
	setp.lt.u64 	%p3, %rd134, 1345280370688173398;
	mov.u64 	%rd185, %rd134;
	mov.u64 	%rd186, %rd133;
	mov.u64 	%rd187, %rd132;
	@%p3 bra 	LBB5_11;

	setp.ne.s64 	%p4, %rd134, 1345280370688173398;
	@%p4 bra 	LBB5_9;

	mov.u64 	%rd185, 1345280370688173398;
	setp.lt.u64 	%p5, %rd133, 6968279316240510977;
	mov.u64 	%rd186, %rd133;
	mov.u64 	%rd187, %rd132;
	@%p5 bra 	LBB5_11;

	setp.ne.s64 	%p6, %rd133, 6968279316240510977;
	@%p6 bra 	LBB5_9;

	mov.u64 	%rd185, 1345280370688173398;
	mov.u64 	%rd186, 6968279316240510977;
	setp.lt.u64 	%p7, %rd132, 6461107452199829505;
	mov.u64 	%rd187, %rd132;
	@%p7 bra 	LBB5_11;

	mov.u64 	%rd185, 1345280370688173398;
	mov.u64 	%rd186, 6968279316240510977;
	mov.u64 	%rd187, 6461107452199829505;
	setp.eq.s64 	%p8, %rd132, 6461107452199829505;
	setp.lt.u64 	%p9, %rd188, 725501752471715841;
	and.pred  	%p10, %p8, %p9;
	@%p10 bra 	LBB5_11;

LBB5_9:
	mov.u64 	%rd171, 1345280370688173398;
	mov.u64 	%rd167, 6968279316240510977;
	mov.u64 	%rd166, 6461107452199829505;
	mov.u64 	%rd165, 725501752471715841;
	// begin inline asm
	sub.cc.u64  %rd152, %rd188, %rd165;
	subc.cc.u64 %rd153, %rd132, %rd166;
	subc.cc.u64 %rd154, %rd133, %rd167;
	subc.u64    %rd155, %rd134, %rd171;
	
	// end inline asm
	st.global.u64 	[%rd175+-16], %rd152;
	st.global.u64 	[%rd175+-8], %rd153;
	st.global.u64 	[%rd175], %rd154;
	st.global.u64 	[%rd175+8], %rd155;
	mov.u64 	%rd185, %rd134;
	mov.u64 	%rd186, %rd133;
	mov.u64 	%rd187, %rd132;
	bra.uni 	LBB5_11;

LBB5_10:
	mov.u64 	%rd164, 0;
	st.global.u64 	[%rd175+-16], %rd164;
	st.global.u64 	[%rd175+-8], %rd164;
	st.global.u64 	[%rd175], %rd164;
	st.global.u64 	[%rd175+8], %rd164;

LBB5_11:
	add.s64 	%rd175, %rd175, 32;
	add.s64 	%rd184, %rd184, 1;
	setp.lt.u64 	%p11, %rd184, %rd2;
	@%p11 bra 	LBB5_2;

LBB5_12:
	ret;

}
	// .globl	msm4_mul2_assign
.visible .entry msm4_mul2_assign(
	.param .u64 msm4_mul2_assign_param_0,
	.param .u64 msm4_mul2_assign_param_1,
	.param .u32 msm4_mul2_assign_param_2
)
{
	.reg .pred 	%p<12>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<198>;


	ld.param.u64 	%rd43, [msm4_mul2_assign_param_0];
	ld.param.u64 	%rd44, [msm4_mul2_assign_param_1];
	ld.param.u32 	%r1, [msm4_mul2_assign_param_2];
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %tid.x;
	mad.lo.s32 	%r5, %r3, %r2, %r4;
	shl.b32 	%r6, %r5, 3;
	cvt.u64.u32 	%rd189, %r6;
	setp.ge.u32 	%p1, %r6, %r1;
	@%p1 bra 	LBB6_12;

	add.s64 	%rd46, %rd189, 8;
	cvt.u64.u32 	%rd47, %r1;
	min.u64 	%rd2, %rd46, %rd47;
	cvta.to.global.u64 	%rd48, %rd44;
	shl.b64 	%rd49, %rd189, 5;
	add.s64 	%rd50, %rd48, %rd49;
	add.s64 	%rd180, %rd50, 16;
	cvta.to.global.u64 	%rd51, %rd43;
	add.s64 	%rd52, %rd51, %rd49;
	add.s64 	%rd179, %rd52, 16;

LBB6_2:
	ld.global.u64 	%rd61, [%rd179+-16];
	ld.global.u64 	%rd62, [%rd179+-8];
	ld.global.u64 	%rd63, [%rd179];
	ld.global.u64 	%rd64, [%rd179+8];
	ld.global.u64 	%rd65, [%rd180+-16];
	ld.global.u64 	%rd66, [%rd180+-8];
	ld.global.u64 	%rd67, [%rd180];
	ld.global.u64 	%rd68, [%rd180+8];
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 nc;
	.reg .u64 t;
	mad.lo.cc.u64  %rd197, %rd61, %rd65, 0;
	madc.hi.cc.u64  c, %rd61, %rd65, 0;
	madc.lo.cc.u64 %rd196, %rd61, %rd66, c;
	madc.hi.cc.u64  c, %rd61, %rd66, 0;
	madc.lo.cc.u64 %rd195, %rd61, %rd67, c;
	madc.hi.cc.u64  c, %rd61, %rd67, 0;
	madc.lo.cc.u64 %rd194, %rd61, %rd68, c;
	madc.hi.u64    %rd193, %rd61, %rd68, 0;
	mad.lo.cc.u64  %rd196, %rd62, %rd65, %rd196;
	madc.hi.cc.u64  c, %rd62, %rd65, 0;
	addc.cc.u64     t, %rd195, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd195, %rd62, %rd66, t;
	madc.hi.cc.u64  c, %rd62, %rd66, nc;
	addc.cc.u64     t, %rd194, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd194, %rd62, %rd67, t;
	madc.hi.cc.u64  c, %rd62, %rd67, nc;
	addc.cc.u64     t, %rd193, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd193, %rd62, %rd68, t;
	madc.hi.u64    %rd192, %rd62, %rd68, nc;
	mad.lo.cc.u64  %rd195, %rd63, %rd65, %rd195;
	madc.hi.cc.u64  c, %rd63, %rd65, 0;
	addc.cc.u64     t, %rd194, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd194, %rd63, %rd66, t;
	madc.hi.cc.u64  c, %rd63, %rd66, nc;
	addc.cc.u64     t, %rd193, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd193, %rd63, %rd67, t;
	madc.hi.cc.u64  c, %rd63, %rd67, nc;
	addc.cc.u64     t, %rd192, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd192, %rd63, %rd68, t;
	madc.hi.u64    %rd191, %rd63, %rd68, nc;
	mad.lo.cc.u64  %rd194, %rd64, %rd65, %rd194;
	madc.hi.cc.u64  c, %rd64, %rd65, 0;
	addc.cc.u64     t, %rd193, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd193, %rd64, %rd66, t;
	madc.hi.cc.u64  c, %rd64, %rd66, nc;
	addc.cc.u64     t, %rd192, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd192, %rd64, %rd67, t;
	madc.hi.cc.u64  c, %rd64, %rd67, nc;
	addc.cc.u64     t, %rd191, c;
	addc.u64       nc,  0, 0;
	mad.lo.cc.u64  %rd191, %rd64, %rd68, t;
	madc.hi.u64    %rd190, %rd64, %rd68, nc;
	}
	// end inline asm
	or.b64  	%rd77, %rd197, %rd196;
	or.b64  	%rd78, %rd77, %rd195;
	or.b64  	%rd79, %rd78, %rd194;
	or.b64  	%rd80, %rd79, %rd193;
	or.b64  	%rd81, %rd80, %rd192;
	or.b64  	%rd82, %rd81, %rd191;
	or.b64  	%rd83, %rd82, %rd190;
	setp.eq.s64 	%p2, %rd83, 0;
	@%p2 bra 	LBB6_10;

	mul.lo.s64 	%rd94, %rd197, 725501752471715839;
	mov.u64 	%rd140, 725501752471715841;
	mov.u64 	%rd141, 6461107452199829505;
	mov.u64 	%rd142, 6968279316240510977;
	mov.u64 	%rd143, 1345280370688173398;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd94, %rd140, %rd197;
	madc.hi.cc.u64 c, %rd94, %rd140, 0;
	addc.cc.u64 t, %rd196, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd196, %rd94, %rd141, t;
	madc.hi.cc.u64 c, %rd94, %rd141, nc;
	addc.cc.u64 t, %rd195, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd195, %rd94, %rd142, t;
	madc.hi.cc.u64 c, %rd94, %rd142, nc;
	addc.cc.u64 t, %rd194, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd194, %rd94, %rd143, t;
	madc.hi.cc.u64 c, %rd94, %rd143, nc;
	addc.cc.u64 %rd193, %rd193, c;
	addc.u64 %rd122, 0, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd110, %rd196, 725501752471715839;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd110, %rd140, %rd196;
	madc.hi.cc.u64 c, %rd110, %rd140, 0;
	addc.cc.u64 t, %rd195, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd195, %rd110, %rd141, t;
	madc.hi.cc.u64 c, %rd110, %rd141, nc;
	addc.cc.u64 t, %rd194, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd194, %rd110, %rd142, t;
	madc.hi.cc.u64 c, %rd110, %rd142, nc;
	addc.cc.u64 t, %rd193, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd193, %rd110, %rd143, t;
	madc.hi.cc.u64 c, %rd110, %rd143, nc;
	addc.cc.u64 c, c, %rd122;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd192, %rd192, c;
	addc.u64 %rd122, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd127, %rd195, 725501752471715839;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd127, %rd140, %rd195;
	madc.hi.cc.u64 c, %rd127, %rd140, 0;
	addc.cc.u64 t, %rd194, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd194, %rd127, %rd141, t;
	madc.hi.cc.u64 c, %rd127, %rd141, nc;
	addc.cc.u64 t, %rd193, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd193, %rd127, %rd142, t;
	madc.hi.cc.u64 c, %rd127, %rd142, nc;
	addc.cc.u64 t, %rd192, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd192, %rd127, %rd143, t;
	madc.hi.cc.u64 c, %rd127, %rd143, nc;
	addc.cc.u64 c, c, %rd122;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd191, %rd191, c;
	addc.u64 %rd122, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd144, %rd194, 725501752471715839;
	mov.u64 	%rd137, %rd191;
	mov.u64 	%rd138, %rd190;
	mov.u64 	%rd136, %rd192;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd144, %rd140, %rd194;
	madc.hi.cc.u64 c, %rd144, %rd140, 0;
	addc.cc.u64 t, %rd193, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd193, %rd144, %rd141, t;
	madc.hi.cc.u64 c, %rd144, %rd141, nc;
	addc.cc.u64 t, %rd136, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd136, %rd144, %rd142, t;
	madc.hi.cc.u64 c, %rd144, %rd142, nc;
	addc.cc.u64 t, %rd137, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd137, %rd144, %rd143, t;
	madc.hi.cc.u64 c, %rd144, %rd143, nc;
	addc.cc.u64 c, c, %rd122;
	addc.cc.u64 %rd138, %rd138, c;
	}
	// end inline asm
	st.global.u64 	[%rd179+-16], %rd193;
	st.global.u64 	[%rd179+-8], %rd136;
	st.global.u64 	[%rd179], %rd137;
	st.global.u64 	[%rd179+8], %rd138;
	setp.lt.u64 	%p3, %rd138, 1345280370688173398;
	mov.u64 	%rd190, %rd138;
	mov.u64 	%rd191, %rd137;
	mov.u64 	%rd192, %rd136;
	@%p3 bra 	LBB6_11;

	setp.ne.s64 	%p4, %rd138, 1345280370688173398;
	@%p4 bra 	LBB6_9;

	mov.u64 	%rd190, 1345280370688173398;
	setp.lt.u64 	%p5, %rd137, 6968279316240510977;
	mov.u64 	%rd191, %rd137;
	mov.u64 	%rd192, %rd136;
	@%p5 bra 	LBB6_11;

	setp.ne.s64 	%p6, %rd137, 6968279316240510977;
	@%p6 bra 	LBB6_9;

	mov.u64 	%rd190, 1345280370688173398;
	mov.u64 	%rd191, 6968279316240510977;
	setp.lt.u64 	%p7, %rd136, 6461107452199829505;
	mov.u64 	%rd192, %rd136;
	@%p7 bra 	LBB6_11;

	mov.u64 	%rd190, 1345280370688173398;
	mov.u64 	%rd191, 6968279316240510977;
	mov.u64 	%rd192, 6461107452199829505;
	setp.eq.s64 	%p8, %rd136, 6461107452199829505;
	setp.lt.u64 	%p9, %rd193, 725501752471715841;
	and.pred  	%p10, %p8, %p9;
	@%p10 bra 	LBB6_11;

LBB6_9:
	mov.u64 	%rd175, 1345280370688173398;
	mov.u64 	%rd171, 6968279316240510977;
	mov.u64 	%rd170, 6461107452199829505;
	mov.u64 	%rd169, 725501752471715841;
	// begin inline asm
	sub.cc.u64  %rd156, %rd193, %rd169;
	subc.cc.u64 %rd157, %rd136, %rd170;
	subc.cc.u64 %rd158, %rd137, %rd171;
	subc.u64    %rd159, %rd138, %rd175;
	
	// end inline asm
	st.global.u64 	[%rd179+-16], %rd156;
	st.global.u64 	[%rd179+-8], %rd157;
	st.global.u64 	[%rd179], %rd158;
	st.global.u64 	[%rd179+8], %rd159;
	mov.u64 	%rd190, %rd138;
	mov.u64 	%rd191, %rd137;
	mov.u64 	%rd192, %rd136;
	bra.uni 	LBB6_11;

LBB6_10:
	mov.u64 	%rd168, 0;
	st.global.u64 	[%rd179+-16], %rd168;
	st.global.u64 	[%rd179+-8], %rd168;
	st.global.u64 	[%rd179], %rd168;
	st.global.u64 	[%rd179+8], %rd168;

LBB6_11:
	add.s64 	%rd180, %rd180, 32;
	add.s64 	%rd179, %rd179, 32;
	add.s64 	%rd189, %rd189, 1;
	setp.lt.u64 	%p11, %rd189, %rd2;
	@%p11 bra 	LBB6_2;

LBB6_12:
	ret;

}
	// .globl	msm6_pixel
.visible .entry msm6_pixel(
	.param .u64 msm6_pixel_param_0,
	.param .u64 msm6_pixel_param_1,
	.param .u64 msm6_pixel_param_2,
	.param .u32 msm6_pixel_param_3,
	.param .u32 msm6_pixel_param_4
)
{
	.local .align 8 .b8 	__local_depot7[2504];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<41>;
	.reg .b32 	%r<149>;
	.reg .b64 	%rd<450>;
	// demoted variable
	.shared .align 8 .b8 _ZZ10msm6_pixelE11scalarCache[16192];

	mov.u64 	%SPL, __local_depot7;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd25, [msm6_pixel_param_1];
	ld.param.u64 	%rd26, [msm6_pixel_param_2];
	ld.param.u32 	%r61, [msm6_pixel_param_3];
	ld.param.u32 	%r60, [msm6_pixel_param_4];
	cvta.to.global.u64 	%rd1, %rd25;
	add.u64 	%rd27, %SP, 0;
	add.u64 	%rd4, %SPL, 0;
	add.u64 	%rd2, %SPL, 144;
	mov.u32 	%r1, %tid.x;
	shr.u32 	%r2, %r1, 6;
	cvt.u64.u32 	%rd29, %r1;
	and.b32  	%r62, %r1, -64;
	cvt.u64.u32 	%rd30, %r62;
	sub.s64 	%rd31, %rd29, %rd30;
	cvt.u32.u64 	%r63, %rd31;
	mov.u64 	%rd32, 1;
	shl.b64 	%rd3, %rd32, %r63;
	ld.global.u64 	%rd33, [BLS12_377_ZERO_PROJECTIVE];
	st.local.u64 	[%rd4], %rd33;
	ld.global.u64 	%rd34, [BLS12_377_ZERO_PROJECTIVE+8];
	st.local.u64 	[%rd4+8], %rd34;
	ld.global.u64 	%rd35, [BLS12_377_ZERO_PROJECTIVE+16];
	st.local.u64 	[%rd4+16], %rd35;
	ld.global.u64 	%rd36, [BLS12_377_ZERO_PROJECTIVE+24];
	st.local.u64 	[%rd4+24], %rd36;
	ld.global.u64 	%rd37, [BLS12_377_ZERO_PROJECTIVE+32];
	st.local.u64 	[%rd4+32], %rd37;
	ld.global.u64 	%rd38, [BLS12_377_ZERO_PROJECTIVE+40];
	st.local.u64 	[%rd4+40], %rd38;
	ld.global.u64 	%rd39, [BLS12_377_ZERO_PROJECTIVE+48];
	st.local.u64 	[%rd4+48], %rd39;
	ld.global.u64 	%rd40, [BLS12_377_ZERO_PROJECTIVE+56];
	st.local.u64 	[%rd4+56], %rd40;
	ld.global.u64 	%rd41, [BLS12_377_ZERO_PROJECTIVE+64];
	st.local.u64 	[%rd4+64], %rd41;
	ld.global.u64 	%rd42, [BLS12_377_ZERO_PROJECTIVE+72];
	st.local.u64 	[%rd4+72], %rd42;
	ld.global.u64 	%rd43, [BLS12_377_ZERO_PROJECTIVE+80];
	st.local.u64 	[%rd4+80], %rd43;
	ld.global.u64 	%rd44, [BLS12_377_ZERO_PROJECTIVE+88];
	st.local.u64 	[%rd4+88], %rd44;
	ld.global.u64 	%rd45, [BLS12_377_ZERO_PROJECTIVE+96];
	st.local.u64 	[%rd4+96], %rd45;
	ld.global.u64 	%rd46, [BLS12_377_ZERO_PROJECTIVE+104];
	st.local.u64 	[%rd4+104], %rd46;
	ld.global.u64 	%rd47, [BLS12_377_ZERO_PROJECTIVE+112];
	st.local.u64 	[%rd4+112], %rd47;
	ld.global.u64 	%rd48, [BLS12_377_ZERO_PROJECTIVE+120];
	st.local.u64 	[%rd4+120], %rd48;
	ld.global.u64 	%rd49, [BLS12_377_ZERO_PROJECTIVE+128];
	st.local.u64 	[%rd4+128], %rd49;
	ld.global.u64 	%rd50, [BLS12_377_ZERO_PROJECTIVE+136];
	st.local.u64 	[%rd4+136], %rd50;
	mov.u32 	%r3, %ctaid.x;
	mul.lo.s32 	%r4, %r3, 506;
	add.s32 	%r64, %r60, -1;
	setp.eq.s32 	%p1, %r3, %r64;
	selp.b32 	%r5, %r61, 506, %p1;
	shl.b32 	%r6, %r1, 1;
	setp.ge.u32 	%p2, %r6, %r5;
	add.s32 	%r65, %r4, %r6;
	cvta.to.global.u64 	%rd51, %rd26;
	mul.wide.u32 	%rd52, %r65, 32;
	add.s64 	%rd5, %rd51, %rd52;
	shl.b32 	%r66, %r1, 6;
	mov.u32 	%r67, _ZZ10msm6_pixelE11scalarCache;
	add.s32 	%r7, %r67, %r66;
	@%p2 bra 	LBB7_10;

	ld.global.u64 	%rd56, [%rd5];
	ld.global.u64 	%rd72, [%rd5+8];
	or.b64  	%rd53, %rd72, %rd56;
	ld.global.u64 	%rd73, [%rd5+16];
	or.b64  	%rd54, %rd53, %rd73;
	ld.global.u64 	%rd74, [%rd5+24];
	or.b64  	%rd55, %rd54, %rd74;
	setp.eq.s64 	%p3, %rd55, 0;
	@%p3 bra 	LBB7_9;

	mul.lo.s64 	%rd66, %rd56, 725501752471715839;
	mov.u64 	%rd112, 725501752471715841;
	mov.u64 	%rd113, 6461107452199829505;
	mov.u64 	%rd114, 6968279316240510977;
	mov.u64 	%rd115, 1345280370688173398;
	mov.u64 	%rd110, 0;
	mov.u64 	%rd75, %rd110;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd66, %rd112, %rd56;
	madc.hi.cc.u64 c, %rd66, %rd112, 0;
	addc.cc.u64 t, %rd72, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd72, %rd66, %rd113, t;
	madc.hi.cc.u64 c, %rd66, %rd113, nc;
	addc.cc.u64 t, %rd73, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd73, %rd66, %rd114, t;
	madc.hi.cc.u64 c, %rd66, %rd114, nc;
	addc.cc.u64 t, %rd74, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd74, %rd66, %rd115, t;
	madc.hi.cc.u64 c, %rd66, %rd115, nc;
	addc.cc.u64 %rd75, %rd75, c;
	addc.u64 %rd94, 0, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd82, %rd72, 725501752471715839;
	mov.u64 	%rd92, %rd110;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd82, %rd112, %rd72;
	madc.hi.cc.u64 c, %rd82, %rd112, 0;
	addc.cc.u64 t, %rd73, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd73, %rd82, %rd113, t;
	madc.hi.cc.u64 c, %rd82, %rd113, nc;
	addc.cc.u64 t, %rd74, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd74, %rd82, %rd114, t;
	madc.hi.cc.u64 c, %rd82, %rd114, nc;
	addc.cc.u64 t, %rd75, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd75, %rd82, %rd115, t;
	madc.hi.cc.u64 c, %rd82, %rd115, nc;
	addc.cc.u64 c, c, %rd94;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd92, %rd92, c;
	addc.u64 %rd94, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd99, %rd73, 725501752471715839;
	mov.u64 	%rd109, %rd110;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd99, %rd112, %rd73;
	madc.hi.cc.u64 c, %rd99, %rd112, 0;
	addc.cc.u64 t, %rd74, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd74, %rd99, %rd113, t;
	madc.hi.cc.u64 c, %rd99, %rd113, nc;
	addc.cc.u64 t, %rd75, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd75, %rd99, %rd114, t;
	madc.hi.cc.u64 c, %rd99, %rd114, nc;
	addc.cc.u64 t, %rd92, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd92, %rd99, %rd115, t;
	madc.hi.cc.u64 c, %rd99, %rd115, nc;
	addc.cc.u64 c, c, %rd94;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd109, %rd109, c;
	addc.u64 %rd94, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd116, %rd74, 725501752471715839;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd116, %rd112, %rd74;
	madc.hi.cc.u64 c, %rd116, %rd112, 0;
	addc.cc.u64 t, %rd75, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd75, %rd116, %rd113, t;
	madc.hi.cc.u64 c, %rd116, %rd113, nc;
	addc.cc.u64 t, %rd92, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd92, %rd116, %rd114, t;
	madc.hi.cc.u64 c, %rd116, %rd114, nc;
	addc.cc.u64 t, %rd109, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd109, %rd116, %rd115, t;
	madc.hi.cc.u64 c, %rd116, %rd115, nc;
	addc.cc.u64 c, c, %rd94;
	addc.cc.u64 %rd110, %rd110, c;
	}
	// end inline asm
	st.shared.u64 	[%r7], %rd75;
	st.shared.u64 	[%r7+8], %rd92;
	st.shared.u64 	[%r7+16], %rd109;
	st.shared.u64 	[%r7+24], %rd110;
	setp.lt.u64 	%p4, %rd110, 1345280370688173398;
	@%p4 bra 	LBB7_10;

	setp.ne.s64 	%p5, %rd110, 1345280370688173398;
	@%p5 bra 	LBB7_8;

	setp.lt.u64 	%p6, %rd109, 6968279316240510977;
	@%p6 bra 	LBB7_10;

	setp.ne.s64 	%p7, %rd109, 6968279316240510977;
	@%p7 bra 	LBB7_8;

	setp.lt.u64 	%p8, %rd92, 6461107452199829505;
	@%p8 bra 	LBB7_10;

	setp.eq.s64 	%p9, %rd92, 6461107452199829505;
	setp.lt.u64 	%p10, %rd75, 725501752471715841;
	and.pred  	%p11, %p9, %p10;
	@%p11 bra 	LBB7_10;

LBB7_8:
	mov.u64 	%rd443, 1345280370688173398;
	mov.u64 	%rd442, 6968279316240510977;
	mov.u64 	%rd441, 6461107452199829505;
	mov.u64 	%rd440, 725501752471715841;
	// begin inline asm
	sub.cc.u64  %rd122, %rd75, %rd440;
	subc.cc.u64 %rd123, %rd92, %rd441;
	subc.cc.u64 %rd124, %rd109, %rd442;
	subc.u64    %rd125, %rd110, %rd443;
	
	// end inline asm
	st.shared.u64 	[%r7], %rd122;
	st.shared.u64 	[%r7+8], %rd123;
	st.shared.u64 	[%r7+16], %rd124;
	st.shared.u64 	[%r7+24], %rd125;
	bra.uni 	LBB7_10;

LBB7_9:
	mov.u64 	%rd134, 0;
	st.shared.u64 	[%r7], %rd134;
	st.shared.u64 	[%r7+8], %rd134;
	st.shared.u64 	[%r7+16], %rd134;
	st.shared.u64 	[%r7+24], %rd134;

LBB7_10:
	mov.u32 	%r118, %tid.x;
	shl.b32 	%r117, %r118, 1;
	add.s32 	%r68, %r117, 1;
	setp.ge.u32 	%p12, %r68, %r5;
	@%p12 bra 	LBB7_20;

	ld.global.u64 	%rd154, [%rd5+40];
	ld.global.u64 	%rd138, [%rd5+32];
	or.b64  	%rd135, %rd154, %rd138;
	ld.global.u64 	%rd155, [%rd5+48];
	or.b64  	%rd136, %rd135, %rd155;
	ld.global.u64 	%rd156, [%rd5+56];
	or.b64  	%rd137, %rd136, %rd156;
	setp.eq.s64 	%p13, %rd137, 0;
	@%p13 bra 	LBB7_19;

	mul.lo.s64 	%rd148, %rd138, 725501752471715839;
	mov.u64 	%rd194, 725501752471715841;
	mov.u64 	%rd195, 6461107452199829505;
	mov.u64 	%rd196, 6968279316240510977;
	mov.u64 	%rd197, 1345280370688173398;
	mov.u64 	%rd192, 0;
	mov.u64 	%rd157, %rd192;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd148, %rd194, %rd138;
	madc.hi.cc.u64 c, %rd148, %rd194, 0;
	addc.cc.u64 t, %rd154, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd154, %rd148, %rd195, t;
	madc.hi.cc.u64 c, %rd148, %rd195, nc;
	addc.cc.u64 t, %rd155, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd155, %rd148, %rd196, t;
	madc.hi.cc.u64 c, %rd148, %rd196, nc;
	addc.cc.u64 t, %rd156, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd156, %rd148, %rd197, t;
	madc.hi.cc.u64 c, %rd148, %rd197, nc;
	addc.cc.u64 %rd157, %rd157, c;
	addc.u64 %rd176, 0, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd164, %rd154, 725501752471715839;
	mov.u64 	%rd174, %rd192;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd164, %rd194, %rd154;
	madc.hi.cc.u64 c, %rd164, %rd194, 0;
	addc.cc.u64 t, %rd155, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd155, %rd164, %rd195, t;
	madc.hi.cc.u64 c, %rd164, %rd195, nc;
	addc.cc.u64 t, %rd156, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd156, %rd164, %rd196, t;
	madc.hi.cc.u64 c, %rd164, %rd196, nc;
	addc.cc.u64 t, %rd157, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd157, %rd164, %rd197, t;
	madc.hi.cc.u64 c, %rd164, %rd197, nc;
	addc.cc.u64 c, c, %rd176;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd174, %rd174, c;
	addc.u64 %rd176, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd181, %rd155, 725501752471715839;
	mov.u64 	%rd191, %rd192;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd181, %rd194, %rd155;
	madc.hi.cc.u64 c, %rd181, %rd194, 0;
	addc.cc.u64 t, %rd156, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd156, %rd181, %rd195, t;
	madc.hi.cc.u64 c, %rd181, %rd195, nc;
	addc.cc.u64 t, %rd157, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd157, %rd181, %rd196, t;
	madc.hi.cc.u64 c, %rd181, %rd196, nc;
	addc.cc.u64 t, %rd174, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd174, %rd181, %rd197, t;
	madc.hi.cc.u64 c, %rd181, %rd197, nc;
	addc.cc.u64 c, c, %rd176;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd191, %rd191, c;
	addc.u64 %rd176, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd198, %rd156, 725501752471715839;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd198, %rd194, %rd156;
	madc.hi.cc.u64 c, %rd198, %rd194, 0;
	addc.cc.u64 t, %rd157, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd157, %rd198, %rd195, t;
	madc.hi.cc.u64 c, %rd198, %rd195, nc;
	addc.cc.u64 t, %rd174, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd174, %rd198, %rd196, t;
	madc.hi.cc.u64 c, %rd198, %rd196, nc;
	addc.cc.u64 t, %rd191, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd191, %rd198, %rd197, t;
	madc.hi.cc.u64 c, %rd198, %rd197, nc;
	addc.cc.u64 c, c, %rd176;
	addc.cc.u64 %rd192, %rd192, c;
	}
	// end inline asm
	st.shared.u64 	[%r7+32], %rd157;
	st.shared.u64 	[%r7+40], %rd174;
	st.shared.u64 	[%r7+48], %rd191;
	st.shared.u64 	[%r7+56], %rd192;
	setp.lt.u64 	%p14, %rd192, 1345280370688173398;
	@%p14 bra 	LBB7_20;

	setp.ne.s64 	%p15, %rd192, 1345280370688173398;
	@%p15 bra 	LBB7_18;

	setp.lt.u64 	%p16, %rd191, 6968279316240510977;
	@%p16 bra 	LBB7_20;

	setp.ne.s64 	%p17, %rd191, 6968279316240510977;
	@%p17 bra 	LBB7_18;

	setp.lt.u64 	%p18, %rd174, 6461107452199829505;
	@%p18 bra 	LBB7_20;

	setp.eq.s64 	%p19, %rd174, 6461107452199829505;
	setp.lt.u64 	%p20, %rd157, 725501752471715841;
	and.pred  	%p21, %p19, %p20;
	@%p21 bra 	LBB7_20;

LBB7_18:
	mov.u32 	%r123, %tid.x;
	shl.b32 	%r122, %r123, 6;
	mov.u32 	%r121, _ZZ10msm6_pixelE11scalarCache;
	add.s32 	%r120, %r121, %r122;
	mov.u64 	%rd448, 1345280370688173398;
	mov.u64 	%rd447, 6968279316240510977;
	mov.u64 	%rd446, 6461107452199829505;
	mov.u64 	%rd445, 725501752471715841;
	// begin inline asm
	sub.cc.u64  %rd204, %rd157, %rd445;
	subc.cc.u64 %rd205, %rd174, %rd446;
	subc.cc.u64 %rd206, %rd191, %rd447;
	subc.u64    %rd207, %rd192, %rd448;
	
	// end inline asm
	st.shared.u64 	[%r120+32], %rd204;
	st.shared.u64 	[%r120+40], %rd205;
	st.shared.u64 	[%r120+48], %rd206;
	st.shared.u64 	[%r120+56], %rd207;
	bra.uni 	LBB7_20;

LBB7_19:
	mov.u64 	%rd216, 0;
	st.shared.u64 	[%r7+32], %rd216;
	st.shared.u64 	[%r7+40], %rd216;
	st.shared.u64 	[%r7+48], %rd216;
	st.shared.u64 	[%r7+56], %rd216;

LBB7_20:
	bar.sync 	0;
	setp.eq.s32 	%p22, %r5, 0;
	mov.u32 	%r142, 0;
	mov.u32 	%r127, %r142;
	@%p22 bra 	LBB7_37;

	add.s32 	%r73, %r5, -1;
	and.b32  	%r137, %r5, 3;
	setp.lt.u32 	%p23, %r73, 3;
	mov.u32 	%r132, 0;
	mov.u32 	%r127, %r132;
	@%p23 bra 	LBB7_32;

	sub.s32 	%r126, %r5, %r137;
	mov.u32 	%r132, 0;
	mov.u32 	%r127, %r132;

LBB7_23:
	shl.b32 	%r76, %r132, 5;
	add.s32 	%r78, %r67, %r76;
	shl.b32 	%r79, %r2, 3;
	add.s32 	%r14, %r78, %r79;
	ld.shared.u64 	%rd217, [%r14];
	and.b64  	%rd218, %rd217, %rd3;
	setp.eq.s64 	%p24, %rd218, 0;
	@%p24 bra 	LBB7_25;

	add.s32 	%r80, %r132, %r4;
	add.s32 	%r15, %r127, 1;
	mul.wide.u32 	%rd219, %r127, 4;
	add.s64 	%rd220, %rd2, %rd219;
	st.local.u32 	[%rd220], %r80;
	mov.u32 	%r127, %r15;

LBB7_25:
	ld.shared.u64 	%rd221, [%r14+32];
	and.b64  	%rd222, %rd221, %rd3;
	setp.eq.s64 	%p25, %rd222, 0;
	@%p25 bra 	LBB7_27;

	add.s32 	%r81, %r132, %r4;
	add.s32 	%r82, %r81, 1;
	add.s32 	%r17, %r127, 1;
	mul.wide.u32 	%rd223, %r127, 4;
	add.s64 	%rd224, %rd2, %rd223;
	st.local.u32 	[%rd224], %r82;
	mov.u32 	%r127, %r17;

LBB7_27:
	ld.shared.u64 	%rd225, [%r14+64];
	and.b64  	%rd226, %rd225, %rd3;
	setp.eq.s64 	%p26, %rd226, 0;
	@%p26 bra 	LBB7_29;

	add.s32 	%r83, %r132, %r4;
	add.s32 	%r84, %r83, 2;
	add.s32 	%r19, %r127, 1;
	mul.wide.u32 	%rd227, %r127, 4;
	add.s64 	%rd228, %rd2, %rd227;
	st.local.u32 	[%rd228], %r84;
	mov.u32 	%r127, %r19;

LBB7_29:
	ld.shared.u64 	%rd229, [%r14+96];
	and.b64  	%rd230, %rd229, %rd3;
	setp.eq.s64 	%p27, %rd230, 0;
	@%p27 bra 	LBB7_31;

	add.s32 	%r85, %r132, %r4;
	add.s32 	%r86, %r85, 3;
	add.s32 	%r21, %r127, 1;
	mul.wide.u32 	%rd231, %r127, 4;
	add.s64 	%rd232, %rd2, %rd231;
	st.local.u32 	[%rd232], %r86;
	mov.u32 	%r127, %r21;

LBB7_31:
	add.s32 	%r132, %r132, 4;
	add.s32 	%r126, %r126, -4;
	setp.ne.s32 	%p28, %r126, 0;
	@%p28 bra 	LBB7_23;

LBB7_32:
	setp.eq.s32 	%p29, %r137, 0;
	@%p29 bra 	LBB7_37;

	add.s32 	%r135, %r132, %r4;
	shl.b32 	%r87, %r132, 5;
	add.s32 	%r89, %r67, %r87;
	shl.b32 	%r90, %r2, 3;
	add.s32 	%r134, %r89, %r90;

LBB7_34:
	.pragma "nounroll";
	ld.shared.u64 	%rd233, [%r134];
	and.b64  	%rd234, %rd233, %rd3;
	setp.eq.s64 	%p30, %rd234, 0;
	@%p30 bra 	LBB7_36;

	add.s32 	%r34, %r127, 1;
	mul.wide.u32 	%rd235, %r127, 4;
	add.s64 	%rd236, %rd2, %rd235;
	st.local.u32 	[%rd236], %r135;
	mov.u32 	%r127, %r34;

LBB7_36:
	add.s32 	%r135, %r135, 1;
	add.s32 	%r134, %r134, 32;
	add.s32 	%r137, %r137, -1;
	setp.ne.s32 	%p31, %r137, 0;
	@%p31 bra 	LBB7_34;

LBB7_37:
	and.b32  	%r40, %r127, -2;
	setp.eq.s32 	%p32, %r40, 0;
	add.u64 	%rd237, %SP, 2312;
	add.u64 	%rd22, %SPL, 2312;
	@%p32 bra 	LBB7_43;

	add.s32 	%r94, %r40, -1;
	shr.u32 	%r95, %r94, 1;
	add.s32 	%r41, %r95, 1;
	and.b32  	%r42, %r41, 1;
	setp.eq.s32 	%p33, %r95, 0;
	mov.u32 	%r142, 0;
	add.u64 	%rd238, %SP, 2408;
	add.u64 	%rd23, %SPL, 2408;
	@%p33 bra 	LBB7_41;

	sub.s32 	%r141, %r41, %r42;
	mov.u32 	%r142, 0;
	add.u64 	%rd269, %SP, 2168;

LBB7_40:
	mul.wide.u32 	%rd239, %r142, 4;
	add.s64 	%rd240, %rd2, %rd239;
	ld.local.u32 	%r97, [%rd240];
	mul.wide.u32 	%rd241, %r97, 104;
	add.s64 	%rd242, %rd1, %rd241;
	ld.global.u64 	%rd243, [%rd242];
	st.local.u64 	[%rd22], %rd243;
	ld.global.u64 	%rd244, [%rd242+8];
	st.local.u64 	[%rd22+8], %rd244;
	ld.global.u64 	%rd245, [%rd242+16];
	st.local.u64 	[%rd22+16], %rd245;
	ld.global.u64 	%rd246, [%rd242+24];
	st.local.u64 	[%rd22+24], %rd246;
	ld.global.u64 	%rd247, [%rd242+32];
	st.local.u64 	[%rd22+32], %rd247;
	ld.global.u64 	%rd248, [%rd242+40];
	st.local.u64 	[%rd22+40], %rd248;
	ld.global.u64 	%rd249, [%rd242+48];
	st.local.u64 	[%rd22+48], %rd249;
	ld.global.u64 	%rd250, [%rd242+56];
	st.local.u64 	[%rd22+56], %rd250;
	ld.global.u64 	%rd251, [%rd242+64];
	st.local.u64 	[%rd22+64], %rd251;
	ld.global.u64 	%rd252, [%rd242+72];
	st.local.u64 	[%rd22+72], %rd252;
	ld.global.u64 	%rd253, [%rd242+80];
	st.local.u64 	[%rd22+80], %rd253;
	ld.global.u64 	%rd254, [%rd242+88];
	st.local.u64 	[%rd22+88], %rd254;
	ld.local.u32 	%r98, [%rd240+4];
	mul.wide.u32 	%rd255, %r98, 104;
	add.s64 	%rd256, %rd1, %rd255;
	ld.global.u64 	%rd257, [%rd256];
	st.local.u64 	[%rd23], %rd257;
	ld.global.u64 	%rd258, [%rd256+8];
	st.local.u64 	[%rd23+8], %rd258;
	ld.global.u64 	%rd259, [%rd256+16];
	st.local.u64 	[%rd23+16], %rd259;
	ld.global.u64 	%rd260, [%rd256+24];
	st.local.u64 	[%rd23+24], %rd260;
	ld.global.u64 	%rd261, [%rd256+32];
	st.local.u64 	[%rd23+32], %rd261;
	ld.global.u64 	%rd262, [%rd256+40];
	st.local.u64 	[%rd23+40], %rd262;
	ld.global.u64 	%rd263, [%rd256+48];
	st.local.u64 	[%rd23+48], %rd263;
	ld.global.u64 	%rd264, [%rd256+56];
	st.local.u64 	[%rd23+56], %rd264;
	ld.global.u64 	%rd265, [%rd256+64];
	st.local.u64 	[%rd23+64], %rd265;
	ld.global.u64 	%rd266, [%rd256+72];
	st.local.u64 	[%rd23+72], %rd266;
	ld.global.u64 	%rd267, [%rd256+80];
	st.local.u64 	[%rd23+80], %rd267;
	ld.global.u64 	%rd268, [%rd256+88];
	st.local.u64 	[%rd23+88], %rd268;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd269;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd237;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd238;
	call.uni 
	_Z35blst_p1_add_affines_into_projectiveP7blst_p1PK14blst_p1_affineS3_, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 0
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd27;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd27;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd269;
	call.uni 
	_Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2_, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 1
	ld.local.u32 	%r99, [%rd240+8];
	mul.wide.u32 	%rd273, %r99, 104;
	add.s64 	%rd274, %rd1, %rd273;
	ld.global.u64 	%rd275, [%rd274];
	st.local.u64 	[%rd22], %rd275;
	ld.global.u64 	%rd276, [%rd274+8];
	st.local.u64 	[%rd22+8], %rd276;
	ld.global.u64 	%rd277, [%rd274+16];
	st.local.u64 	[%rd22+16], %rd277;
	ld.global.u64 	%rd278, [%rd274+24];
	st.local.u64 	[%rd22+24], %rd278;
	ld.global.u64 	%rd279, [%rd274+32];
	st.local.u64 	[%rd22+32], %rd279;
	ld.global.u64 	%rd280, [%rd274+40];
	st.local.u64 	[%rd22+40], %rd280;
	ld.global.u64 	%rd281, [%rd274+48];
	st.local.u64 	[%rd22+48], %rd281;
	ld.global.u64 	%rd282, [%rd274+56];
	st.local.u64 	[%rd22+56], %rd282;
	ld.global.u64 	%rd283, [%rd274+64];
	st.local.u64 	[%rd22+64], %rd283;
	ld.global.u64 	%rd284, [%rd274+72];
	st.local.u64 	[%rd22+72], %rd284;
	ld.global.u64 	%rd285, [%rd274+80];
	st.local.u64 	[%rd22+80], %rd285;
	ld.global.u64 	%rd286, [%rd274+88];
	st.local.u64 	[%rd22+88], %rd286;
	ld.local.u32 	%r100, [%rd240+12];
	mul.wide.u32 	%rd287, %r100, 104;
	add.s64 	%rd288, %rd1, %rd287;
	ld.global.u64 	%rd289, [%rd288];
	st.local.u64 	[%rd23], %rd289;
	ld.global.u64 	%rd290, [%rd288+8];
	st.local.u64 	[%rd23+8], %rd290;
	ld.global.u64 	%rd291, [%rd288+16];
	st.local.u64 	[%rd23+16], %rd291;
	ld.global.u64 	%rd292, [%rd288+24];
	st.local.u64 	[%rd23+24], %rd292;
	ld.global.u64 	%rd293, [%rd288+32];
	st.local.u64 	[%rd23+32], %rd293;
	ld.global.u64 	%rd294, [%rd288+40];
	st.local.u64 	[%rd23+40], %rd294;
	ld.global.u64 	%rd295, [%rd288+48];
	st.local.u64 	[%rd23+48], %rd295;
	ld.global.u64 	%rd296, [%rd288+56];
	st.local.u64 	[%rd23+56], %rd296;
	ld.global.u64 	%rd297, [%rd288+64];
	st.local.u64 	[%rd23+64], %rd297;
	ld.global.u64 	%rd298, [%rd288+72];
	st.local.u64 	[%rd23+72], %rd298;
	ld.global.u64 	%rd299, [%rd288+80];
	st.local.u64 	[%rd23+80], %rd299;
	ld.global.u64 	%rd300, [%rd288+88];
	st.local.u64 	[%rd23+88], %rd300;
	{ // callseq 2, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd269;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd237;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd238;
	call.uni 
	_Z35blst_p1_add_affines_into_projectiveP7blst_p1PK14blst_p1_affineS3_, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 2
	{ // callseq 3, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd27;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd27;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd269;
	call.uni 
	_Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2_, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 3
	add.s32 	%r142, %r142, 4;
	add.s32 	%r141, %r141, -2;
	setp.ne.s32 	%p34, %r141, 0;
	@%p34 bra 	LBB7_40;

LBB7_41:
	setp.eq.s32 	%p35, %r42, 0;
	@%p35 bra 	LBB7_43;

	mul.wide.u32 	%rd301, %r142, 4;
	add.s64 	%rd302, %rd2, %rd301;
	ld.local.u32 	%r101, [%rd302];
	mul.wide.u32 	%rd303, %r101, 104;
	add.s64 	%rd304, %rd1, %rd303;
	ld.global.u64 	%rd305, [%rd304];
	st.local.u64 	[%rd22], %rd305;
	ld.global.u64 	%rd306, [%rd304+8];
	st.local.u64 	[%rd22+8], %rd306;
	ld.global.u64 	%rd307, [%rd304+16];
	st.local.u64 	[%rd22+16], %rd307;
	ld.global.u64 	%rd308, [%rd304+24];
	st.local.u64 	[%rd22+24], %rd308;
	ld.global.u64 	%rd309, [%rd304+32];
	st.local.u64 	[%rd22+32], %rd309;
	ld.global.u64 	%rd310, [%rd304+40];
	st.local.u64 	[%rd22+40], %rd310;
	ld.global.u64 	%rd311, [%rd304+48];
	st.local.u64 	[%rd22+48], %rd311;
	ld.global.u64 	%rd312, [%rd304+56];
	st.local.u64 	[%rd22+56], %rd312;
	ld.global.u64 	%rd313, [%rd304+64];
	st.local.u64 	[%rd22+64], %rd313;
	ld.global.u64 	%rd314, [%rd304+72];
	st.local.u64 	[%rd22+72], %rd314;
	ld.global.u64 	%rd315, [%rd304+80];
	st.local.u64 	[%rd22+80], %rd315;
	ld.global.u64 	%rd316, [%rd304+88];
	st.local.u64 	[%rd22+88], %rd316;
	ld.local.u32 	%r102, [%rd302+4];
	mul.wide.u32 	%rd317, %r102, 104;
	add.s64 	%rd318, %rd1, %rd317;
	ld.global.u64 	%rd319, [%rd318];
	st.local.u64 	[%rd23], %rd319;
	ld.global.u64 	%rd320, [%rd318+8];
	st.local.u64 	[%rd23+8], %rd320;
	ld.global.u64 	%rd321, [%rd318+16];
	st.local.u64 	[%rd23+16], %rd321;
	ld.global.u64 	%rd322, [%rd318+24];
	st.local.u64 	[%rd23+24], %rd322;
	ld.global.u64 	%rd323, [%rd318+32];
	st.local.u64 	[%rd23+32], %rd323;
	ld.global.u64 	%rd324, [%rd318+40];
	st.local.u64 	[%rd23+40], %rd324;
	ld.global.u64 	%rd325, [%rd318+48];
	st.local.u64 	[%rd23+48], %rd325;
	ld.global.u64 	%rd326, [%rd318+56];
	st.local.u64 	[%rd23+56], %rd326;
	ld.global.u64 	%rd327, [%rd318+64];
	st.local.u64 	[%rd23+64], %rd327;
	ld.global.u64 	%rd328, [%rd318+72];
	st.local.u64 	[%rd23+72], %rd328;
	ld.global.u64 	%rd329, [%rd318+80];
	st.local.u64 	[%rd23+80], %rd329;
	ld.global.u64 	%rd330, [%rd318+88];
	st.local.u64 	[%rd23+88], %rd330;
	add.u64 	%rd331, %SP, 2168;
	{ // callseq 4, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd331;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd237;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd238;
	call.uni 
	_Z35blst_p1_add_affines_into_projectiveP7blst_p1PK14blst_p1_affineS3_, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 4
	{ // callseq 5, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd27;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd27;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd331;
	call.uni 
	_Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2_, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 5
	add.s32 	%r142, %r142, 2;

LBB7_43:
	setp.le.u32 	%p36, %r127, %r142;
	@%p36 bra 	LBB7_49;

	sub.s32 	%r103, %r127, %r142;
	and.b32  	%r146, %r103, 3;
	setp.eq.s32 	%p37, %r146, 0;
	mov.u32 	%r147, %r142;
	@%p37 bra 	LBB7_47;

	mov.u32 	%r147, %r142;

LBB7_46:
	.pragma "nounroll";
	mul.wide.u32 	%rd335, %r147, 4;
	add.s64 	%rd336, %rd2, %rd335;
	ld.local.u32 	%r104, [%rd336];
	mul.wide.u32 	%rd337, %r104, 104;
	add.s64 	%rd338, %rd1, %rd337;
	ld.global.u64 	%rd339, [%rd338];
	st.local.u64 	[%rd22], %rd339;
	ld.global.u64 	%rd340, [%rd338+8];
	st.local.u64 	[%rd22+8], %rd340;
	ld.global.u64 	%rd341, [%rd338+16];
	st.local.u64 	[%rd22+16], %rd341;
	ld.global.u64 	%rd342, [%rd338+24];
	st.local.u64 	[%rd22+24], %rd342;
	ld.global.u64 	%rd343, [%rd338+32];
	st.local.u64 	[%rd22+32], %rd343;
	ld.global.u64 	%rd344, [%rd338+40];
	st.local.u64 	[%rd22+40], %rd344;
	ld.global.u64 	%rd345, [%rd338+48];
	st.local.u64 	[%rd22+48], %rd345;
	ld.global.u64 	%rd346, [%rd338+56];
	st.local.u64 	[%rd22+56], %rd346;
	ld.global.u64 	%rd347, [%rd338+64];
	st.local.u64 	[%rd22+64], %rd347;
	ld.global.u64 	%rd348, [%rd338+72];
	st.local.u64 	[%rd22+72], %rd348;
	ld.global.u64 	%rd349, [%rd338+80];
	st.local.u64 	[%rd22+80], %rd349;
	ld.global.u64 	%rd350, [%rd338+88];
	st.local.u64 	[%rd22+88], %rd350;
	{ // callseq 6, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd27;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd27;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd237;
	call.uni 
	_Z32blst_p1_add_affine_to_projectiveP7blst_p1PKS_PK14blst_p1_affine, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 6
	add.s32 	%r147, %r147, 1;
	add.s32 	%r146, %r146, -1;
	setp.ne.s32 	%p38, %r146, 0;
	@%p38 bra 	LBB7_46;

LBB7_47:
	not.b32 	%r105, %r142;
	add.s32 	%r106, %r127, %r105;
	setp.lt.u32 	%p39, %r106, 3;
	@%p39 bra 	LBB7_49;

LBB7_48:
	mul.wide.u32 	%rd353, %r147, 4;
	add.s64 	%rd354, %rd2, %rd353;
	ld.local.u32 	%r107, [%rd354];
	mul.wide.u32 	%rd355, %r107, 104;
	add.s64 	%rd356, %rd1, %rd355;
	ld.global.u64 	%rd357, [%rd356];
	st.local.u64 	[%rd22], %rd357;
	ld.global.u64 	%rd358, [%rd356+8];
	st.local.u64 	[%rd22+8], %rd358;
	ld.global.u64 	%rd359, [%rd356+16];
	st.local.u64 	[%rd22+16], %rd359;
	ld.global.u64 	%rd360, [%rd356+24];
	st.local.u64 	[%rd22+24], %rd360;
	ld.global.u64 	%rd361, [%rd356+32];
	st.local.u64 	[%rd22+32], %rd361;
	ld.global.u64 	%rd362, [%rd356+40];
	st.local.u64 	[%rd22+40], %rd362;
	ld.global.u64 	%rd363, [%rd356+48];
	st.local.u64 	[%rd22+48], %rd363;
	ld.global.u64 	%rd364, [%rd356+56];
	st.local.u64 	[%rd22+56], %rd364;
	ld.global.u64 	%rd365, [%rd356+64];
	st.local.u64 	[%rd22+64], %rd365;
	ld.global.u64 	%rd366, [%rd356+72];
	st.local.u64 	[%rd22+72], %rd366;
	ld.global.u64 	%rd367, [%rd356+80];
	st.local.u64 	[%rd22+80], %rd367;
	ld.global.u64 	%rd368, [%rd356+88];
	st.local.u64 	[%rd22+88], %rd368;
	{ // callseq 7, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd27;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd27;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd237;
	call.uni 
	_Z32blst_p1_add_affine_to_projectiveP7blst_p1PKS_PK14blst_p1_affine, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 7
	add.s32 	%r108, %r147, 1;
	mul.wide.u32 	%rd371, %r108, 4;
	add.s64 	%rd372, %rd2, %rd371;
	ld.local.u32 	%r109, [%rd372];
	mul.wide.u32 	%rd373, %r109, 104;
	add.s64 	%rd374, %rd1, %rd373;
	ld.global.u64 	%rd375, [%rd374];
	st.local.u64 	[%rd22], %rd375;
	ld.global.u64 	%rd376, [%rd374+8];
	st.local.u64 	[%rd22+8], %rd376;
	ld.global.u64 	%rd377, [%rd374+16];
	st.local.u64 	[%rd22+16], %rd377;
	ld.global.u64 	%rd378, [%rd374+24];
	st.local.u64 	[%rd22+24], %rd378;
	ld.global.u64 	%rd379, [%rd374+32];
	st.local.u64 	[%rd22+32], %rd379;
	ld.global.u64 	%rd380, [%rd374+40];
	st.local.u64 	[%rd22+40], %rd380;
	ld.global.u64 	%rd381, [%rd374+48];
	st.local.u64 	[%rd22+48], %rd381;
	ld.global.u64 	%rd382, [%rd374+56];
	st.local.u64 	[%rd22+56], %rd382;
	ld.global.u64 	%rd383, [%rd374+64];
	st.local.u64 	[%rd22+64], %rd383;
	ld.global.u64 	%rd384, [%rd374+72];
	st.local.u64 	[%rd22+72], %rd384;
	ld.global.u64 	%rd385, [%rd374+80];
	st.local.u64 	[%rd22+80], %rd385;
	ld.global.u64 	%rd386, [%rd374+88];
	st.local.u64 	[%rd22+88], %rd386;
	{ // callseq 8, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd27;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd27;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd237;
	call.uni 
	_Z32blst_p1_add_affine_to_projectiveP7blst_p1PKS_PK14blst_p1_affine, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 8
	add.s32 	%r110, %r147, 2;
	mul.wide.u32 	%rd387, %r110, 4;
	add.s64 	%rd388, %rd2, %rd387;
	ld.local.u32 	%r111, [%rd388];
	mul.wide.u32 	%rd389, %r111, 104;
	add.s64 	%rd390, %rd1, %rd389;
	ld.global.u64 	%rd391, [%rd390];
	st.local.u64 	[%rd22], %rd391;
	ld.global.u64 	%rd392, [%rd390+8];
	st.local.u64 	[%rd22+8], %rd392;
	ld.global.u64 	%rd393, [%rd390+16];
	st.local.u64 	[%rd22+16], %rd393;
	ld.global.u64 	%rd394, [%rd390+24];
	st.local.u64 	[%rd22+24], %rd394;
	ld.global.u64 	%rd395, [%rd390+32];
	st.local.u64 	[%rd22+32], %rd395;
	ld.global.u64 	%rd396, [%rd390+40];
	st.local.u64 	[%rd22+40], %rd396;
	ld.global.u64 	%rd397, [%rd390+48];
	st.local.u64 	[%rd22+48], %rd397;
	ld.global.u64 	%rd398, [%rd390+56];
	st.local.u64 	[%rd22+56], %rd398;
	ld.global.u64 	%rd399, [%rd390+64];
	st.local.u64 	[%rd22+64], %rd399;
	ld.global.u64 	%rd400, [%rd390+72];
	st.local.u64 	[%rd22+72], %rd400;
	ld.global.u64 	%rd401, [%rd390+80];
	st.local.u64 	[%rd22+80], %rd401;
	ld.global.u64 	%rd402, [%rd390+88];
	st.local.u64 	[%rd22+88], %rd402;
	{ // callseq 9, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd27;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd27;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd237;
	call.uni 
	_Z32blst_p1_add_affine_to_projectiveP7blst_p1PKS_PK14blst_p1_affine, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 9
	add.s32 	%r112, %r147, 3;
	mul.wide.u32 	%rd403, %r112, 4;
	add.s64 	%rd404, %rd2, %rd403;
	ld.local.u32 	%r113, [%rd404];
	mul.wide.u32 	%rd405, %r113, 104;
	add.s64 	%rd406, %rd1, %rd405;
	ld.global.u64 	%rd407, [%rd406];
	st.local.u64 	[%rd22], %rd407;
	ld.global.u64 	%rd408, [%rd406+8];
	st.local.u64 	[%rd22+8], %rd408;
	ld.global.u64 	%rd409, [%rd406+16];
	st.local.u64 	[%rd22+16], %rd409;
	ld.global.u64 	%rd410, [%rd406+24];
	st.local.u64 	[%rd22+24], %rd410;
	ld.global.u64 	%rd411, [%rd406+32];
	st.local.u64 	[%rd22+32], %rd411;
	ld.global.u64 	%rd412, [%rd406+40];
	st.local.u64 	[%rd22+40], %rd412;
	ld.global.u64 	%rd413, [%rd406+48];
	st.local.u64 	[%rd22+48], %rd413;
	ld.global.u64 	%rd414, [%rd406+56];
	st.local.u64 	[%rd22+56], %rd414;
	ld.global.u64 	%rd415, [%rd406+64];
	st.local.u64 	[%rd22+64], %rd415;
	ld.global.u64 	%rd416, [%rd406+72];
	st.local.u64 	[%rd22+72], %rd416;
	ld.global.u64 	%rd417, [%rd406+80];
	st.local.u64 	[%rd22+80], %rd417;
	ld.global.u64 	%rd418, [%rd406+88];
	st.local.u64 	[%rd22+88], %rd418;
	{ // callseq 10, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd27;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd27;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd237;
	call.uni 
	_Z32blst_p1_add_affine_to_projectiveP7blst_p1PKS_PK14blst_p1_affine, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 10
	add.s32 	%r147, %r147, 4;
	setp.lt.u32 	%p40, %r147, %r127;
	@%p40 bra 	LBB7_48;

LBB7_49:
	ld.param.u64 	%rd449, [msm6_pixel_param_0];
	mov.u32 	%r119, %ctaid.x;
	ld.param.u32 	%r116, [msm6_pixel_param_4];
	mov.u32 	%r115, %tid.x;
	cvta.to.local.u64 	%rd444, %rd27;
	ld.local.u64 	%rd419, [%rd444];
	mad.lo.s32 	%r114, %r115, %r116, %r119;
	cvta.to.global.u64 	%rd420, %rd449;
	mul.wide.u32 	%rd421, %r114, 144;
	add.s64 	%rd422, %rd420, %rd421;
	st.global.u64 	[%rd422], %rd419;
	ld.local.u64 	%rd423, [%rd444+8];
	st.global.u64 	[%rd422+8], %rd423;
	ld.local.u64 	%rd424, [%rd444+16];
	st.global.u64 	[%rd422+16], %rd424;
	ld.local.u64 	%rd425, [%rd444+24];
	st.global.u64 	[%rd422+24], %rd425;
	ld.local.u64 	%rd426, [%rd444+32];
	st.global.u64 	[%rd422+32], %rd426;
	ld.local.u64 	%rd427, [%rd444+40];
	st.global.u64 	[%rd422+40], %rd427;
	ld.local.u64 	%rd428, [%rd444+48];
	st.global.u64 	[%rd422+48], %rd428;
	ld.local.u64 	%rd429, [%rd444+56];
	st.global.u64 	[%rd422+56], %rd429;
	ld.local.u64 	%rd430, [%rd444+64];
	st.global.u64 	[%rd422+64], %rd430;
	ld.local.u64 	%rd431, [%rd444+72];
	st.global.u64 	[%rd422+72], %rd431;
	ld.local.u64 	%rd432, [%rd444+80];
	st.global.u64 	[%rd422+80], %rd432;
	ld.local.u64 	%rd433, [%rd444+88];
	st.global.u64 	[%rd422+88], %rd433;
	ld.local.u64 	%rd434, [%rd444+96];
	st.global.u64 	[%rd422+96], %rd434;
	ld.local.u64 	%rd435, [%rd444+104];
	st.global.u64 	[%rd422+104], %rd435;
	ld.local.u64 	%rd436, [%rd444+112];
	st.global.u64 	[%rd422+112], %rd436;
	ld.local.u64 	%rd437, [%rd444+120];
	st.global.u64 	[%rd422+120], %rd437;
	ld.local.u64 	%rd438, [%rd444+128];
	st.global.u64 	[%rd422+128], %rd438;
	ld.local.u64 	%rd439, [%rd444+136];
	st.global.u64 	[%rd422+136], %rd439;
	ret;

}
	// .globl	msm6_collapse_rows
.visible .entry msm6_collapse_rows(
	.param .u64 msm6_collapse_rows_param_0,
	.param .u64 msm6_collapse_rows_param_1,
	.param .u32 msm6_collapse_rows_param_2
)
{
	.local .align 8 .b8 	__local_depot8[144];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<6>;
	.reg .b32 	%r<23>;
	.reg .b64 	%rd<59>;


	mov.u64 	%SPL, __local_depot8;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd2, [msm6_collapse_rows_param_0];
	ld.param.u64 	%rd3, [msm6_collapse_rows_param_1];
	ld.param.u32 	%r12, [msm6_collapse_rows_param_2];
	add.u64 	%rd4, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r1, %tid.x;
	mul.lo.s32 	%r13, %r1, %r12;
	add.s32 	%r2, %r13, %r12;
	cvta.to.global.u64 	%rd5, %rd3;
	mul.wide.u32 	%rd6, %r13, 144;
	add.s64 	%rd7, %rd5, %rd6;
	ld.global.u64 	%rd8, [%rd7];
	st.local.u64 	[%rd1], %rd8;
	ld.global.u64 	%rd9, [%rd7+8];
	st.local.u64 	[%rd1+8], %rd9;
	ld.global.u64 	%rd10, [%rd7+16];
	st.local.u64 	[%rd1+16], %rd10;
	ld.global.u64 	%rd11, [%rd7+24];
	st.local.u64 	[%rd1+24], %rd11;
	ld.global.u64 	%rd12, [%rd7+32];
	st.local.u64 	[%rd1+32], %rd12;
	ld.global.u64 	%rd13, [%rd7+40];
	st.local.u64 	[%rd1+40], %rd13;
	ld.global.u64 	%rd14, [%rd7+48];
	st.local.u64 	[%rd1+48], %rd14;
	ld.global.u64 	%rd15, [%rd7+56];
	st.local.u64 	[%rd1+56], %rd15;
	ld.global.u64 	%rd16, [%rd7+64];
	st.local.u64 	[%rd1+64], %rd16;
	ld.global.u64 	%rd17, [%rd7+72];
	st.local.u64 	[%rd1+72], %rd17;
	ld.global.u64 	%rd18, [%rd7+80];
	st.local.u64 	[%rd1+80], %rd18;
	ld.global.u64 	%rd19, [%rd7+88];
	st.local.u64 	[%rd1+88], %rd19;
	ld.global.u64 	%rd20, [%rd7+96];
	st.local.u64 	[%rd1+96], %rd20;
	ld.global.u64 	%rd21, [%rd7+104];
	st.local.u64 	[%rd1+104], %rd21;
	ld.global.u64 	%rd22, [%rd7+112];
	st.local.u64 	[%rd1+112], %rd22;
	ld.global.u64 	%rd23, [%rd7+120];
	st.local.u64 	[%rd1+120], %rd23;
	ld.global.u64 	%rd24, [%rd7+128];
	st.local.u64 	[%rd1+128], %rd24;
	ld.global.u64 	%rd25, [%rd7+136];
	st.local.u64 	[%rd1+136], %rd25;
	add.s32 	%r21, %r13, 1;
	setp.ge.u32 	%p1, %r21, %r2;
	@%p1 bra 	LBB8_5;

	add.s32 	%r14, %r12, -1;
	and.b32  	%r20, %r14, 3;
	setp.eq.s32 	%p2, %r20, 0;
	@%p2 bra 	LBB8_3;

LBB8_2:
	.pragma "nounroll";
	mul.wide.u32 	%rd26, %r21, 144;
	add.s64 	%rd27, %rd3, %rd26;
	{ // callseq 11, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd4;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd4;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd27;
	call.uni 
	_Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2_, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 11
	add.s32 	%r21, %r21, 1;
	add.s32 	%r20, %r20, -1;
	setp.ne.s32 	%p3, %r20, 0;
	@%p3 bra 	LBB8_2;

LBB8_3:
	add.s32 	%r15, %r12, -2;
	setp.lt.u32 	%p4, %r15, 3;
	@%p4 bra 	LBB8_5;

LBB8_4:
	mul.wide.u32 	%rd29, %r21, 144;
	add.s64 	%rd30, %rd3, %rd29;
	{ // callseq 12, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd4;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd4;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd30;
	call.uni 
	_Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2_, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 12
	add.s32 	%r16, %r21, 1;
	mul.wide.u32 	%rd32, %r16, 144;
	add.s64 	%rd33, %rd3, %rd32;
	{ // callseq 13, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd4;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd4;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd33;
	call.uni 
	_Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2_, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 13
	add.s32 	%r17, %r21, 2;
	mul.wide.u32 	%rd34, %r17, 144;
	add.s64 	%rd35, %rd3, %rd34;
	{ // callseq 14, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd4;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd4;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd35;
	call.uni 
	_Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2_, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 14
	add.s32 	%r18, %r21, 3;
	mul.wide.u32 	%rd36, %r18, 144;
	add.s64 	%rd37, %rd3, %rd36;
	{ // callseq 15, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd4;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd4;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd37;
	call.uni 
	_Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2_, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 15
	add.s32 	%r21, %r21, 4;
	setp.lt.u32 	%p5, %r21, %r2;
	@%p5 bra 	LBB8_4;

LBB8_5:
	ld.local.u64 	%rd38, [%rd1];
	cvta.to.global.u64 	%rd39, %rd2;
	mul.wide.u32 	%rd40, %r1, 144;
	add.s64 	%rd41, %rd39, %rd40;
	st.global.u64 	[%rd41], %rd38;
	ld.local.u64 	%rd42, [%rd1+8];
	st.global.u64 	[%rd41+8], %rd42;
	ld.local.u64 	%rd43, [%rd1+16];
	st.global.u64 	[%rd41+16], %rd43;
	ld.local.u64 	%rd44, [%rd1+24];
	st.global.u64 	[%rd41+24], %rd44;
	ld.local.u64 	%rd45, [%rd1+32];
	st.global.u64 	[%rd41+32], %rd45;
	ld.local.u64 	%rd46, [%rd1+40];
	st.global.u64 	[%rd41+40], %rd46;
	ld.local.u64 	%rd47, [%rd1+48];
	st.global.u64 	[%rd41+48], %rd47;
	ld.local.u64 	%rd48, [%rd1+56];
	st.global.u64 	[%rd41+56], %rd48;
	ld.local.u64 	%rd49, [%rd1+64];
	st.global.u64 	[%rd41+64], %rd49;
	ld.local.u64 	%rd50, [%rd1+72];
	st.global.u64 	[%rd41+72], %rd50;
	ld.local.u64 	%rd51, [%rd1+80];
	st.global.u64 	[%rd41+80], %rd51;
	ld.local.u64 	%rd52, [%rd1+88];
	st.global.u64 	[%rd41+88], %rd52;
	ld.local.u64 	%rd53, [%rd1+96];
	st.global.u64 	[%rd41+96], %rd53;
	ld.local.u64 	%rd54, [%rd1+104];
	st.global.u64 	[%rd41+104], %rd54;
	ld.local.u64 	%rd55, [%rd1+112];
	st.global.u64 	[%rd41+112], %rd55;
	ld.local.u64 	%rd56, [%rd1+120];
	st.global.u64 	[%rd41+120], %rd56;
	ld.local.u64 	%rd57, [%rd1+128];
	st.global.u64 	[%rd41+128], %rd57;
	ld.local.u64 	%rd58, [%rd1+136];
	st.global.u64 	[%rd41+136], %rd58;
	ret;

}
	// .globl	msm6_collapse_rows_128
.visible .entry msm6_collapse_rows_128(
	.param .u64 msm6_collapse_rows_128_param_0,
	.param .u64 msm6_collapse_rows_128_param_1,
	.param .u32 msm6_collapse_rows_128_param_2
)
{
	.reg .pred 	%p<6>;
	.reg .b32 	%r<17>;
	.reg .b64 	%rd<39>;


	ld.param.u64 	%rd2, [msm6_collapse_rows_128_param_0];
	ld.param.u64 	%rd3, [msm6_collapse_rows_128_param_1];
	cvta.to.global.u64 	%rd4, %rd3;
	mov.u32 	%r1, %ctaid.x;
	shl.b32 	%r4, %r1, 7;
	mov.u32 	%r2, %tid.x;
	shl.b32 	%r5, %r2, 2;
	add.s32 	%r6, %r4, %r5;
	mul.wide.u32 	%rd5, %r6, 144;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.u64 	%rd7, [%rd6];
	mov.u32 	%r7, sdata;
	mad.lo.s32 	%r3, %r2, 144, %r7;
	st.shared.u64 	[%r3], %rd7;
	ld.global.u64 	%rd8, [%rd6+8];
	st.shared.u64 	[%r3+8], %rd8;
	ld.global.u64 	%rd9, [%rd6+16];
	st.shared.u64 	[%r3+16], %rd9;
	ld.global.u64 	%rd10, [%rd6+24];
	st.shared.u64 	[%r3+24], %rd10;
	ld.global.u64 	%rd11, [%rd6+32];
	st.shared.u64 	[%r3+32], %rd11;
	ld.global.u64 	%rd12, [%rd6+40];
	st.shared.u64 	[%r3+40], %rd12;
	ld.global.u64 	%rd13, [%rd6+48];
	st.shared.u64 	[%r3+48], %rd13;
	ld.global.u64 	%rd14, [%rd6+56];
	st.shared.u64 	[%r3+56], %rd14;
	ld.global.u64 	%rd15, [%rd6+64];
	st.shared.u64 	[%r3+64], %rd15;
	ld.global.u64 	%rd16, [%rd6+72];
	st.shared.u64 	[%r3+72], %rd16;
	ld.global.u64 	%rd17, [%rd6+80];
	st.shared.u64 	[%r3+80], %rd17;
	ld.global.u64 	%rd18, [%rd6+88];
	st.shared.u64 	[%r3+88], %rd18;
	ld.global.u64 	%rd19, [%rd6+96];
	st.shared.u64 	[%r3+96], %rd19;
	ld.global.u64 	%rd20, [%rd6+104];
	st.shared.u64 	[%r3+104], %rd20;
	ld.global.u64 	%rd21, [%rd6+112];
	st.shared.u64 	[%r3+112], %rd21;
	ld.global.u64 	%rd22, [%rd6+120];
	st.shared.u64 	[%r3+120], %rd22;
	ld.global.u64 	%rd23, [%rd6+128];
	st.shared.u64 	[%r3+128], %rd23;
	ld.global.u64 	%rd24, [%rd6+136];
	st.shared.u64 	[%r3+136], %rd24;
	{ .reg .b64 %tmp;
	  cvt.u64.u32 	%tmp, %r3;
	  cvta.shared.u64 	%rd1, %tmp; }
	or.b32  	%r8, %r6, 1;
	mul.wide.u32 	%rd25, %r8, 144;
	add.s64 	%rd26, %rd3, %rd25;
	{ // callseq 16, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd1;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd26;
	call.uni 
	_Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2_, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 16
	or.b32  	%r9, %r6, 2;
	mul.wide.u32 	%rd27, %r9, 144;
	add.s64 	%rd28, %rd3, %rd27;
	{ // callseq 17, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd1;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd28;
	call.uni 
	_Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2_, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 17
	or.b32  	%r10, %r6, 3;
	mul.wide.u32 	%rd29, %r10, 144;
	add.s64 	%rd30, %rd3, %rd29;
	{ // callseq 18, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd1;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd30;
	call.uni 
	_Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2_, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 18
	setp.gt.u32 	%p1, %r2, 15;
	@%p1 bra 	LBB9_6;

	add.s32 	%r11, %r3, 2304;
	{ .reg .b64 %tmp;
	  cvt.u64.u32 	%tmp, %r11;
	  cvta.shared.u64 	%rd31, %tmp; }
	{ // callseq 19, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd1;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd31;
	call.uni 
	_Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2_, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 19
	setp.gt.u32 	%p2, %r2, 7;
	@%p2 bra 	LBB9_6;

	add.s32 	%r12, %r3, 1152;
	{ .reg .b64 %tmp;
	  cvt.u64.u32 	%tmp, %r12;
	  cvta.shared.u64 	%rd32, %tmp; }
	{ // callseq 20, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd1;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd32;
	call.uni 
	_Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2_, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 20
	setp.gt.u32 	%p3, %r2, 3;
	@%p3 bra 	LBB9_6;

	add.s32 	%r13, %r3, 576;
	{ .reg .b64 %tmp;
	  cvt.u64.u32 	%tmp, %r13;
	  cvta.shared.u64 	%rd33, %tmp; }
	{ // callseq 21, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd1;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd33;
	call.uni 
	_Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2_, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 21
	setp.gt.u32 	%p4, %r2, 1;
	@%p4 bra 	LBB9_6;

	add.s32 	%r14, %r3, 288;
	{ .reg .b64 %tmp;
	  cvt.u64.u32 	%tmp, %r14;
	  cvta.shared.u64 	%rd34, %tmp; }
	{ // callseq 22, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd1;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd1;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd34;
	call.uni 
	_Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2_, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 22
	setp.ne.s32 	%p5, %r2, 0;
	@%p5 bra 	LBB9_6;

	mul.wide.u32 	%rd35, %r1, 144;
	add.s64 	%rd36, %rd2, %rd35;
	{ .reg .b64 %tmp;
	  cvt.u64.u32 	%tmp, %r7;
	  cvta.shared.u64 	%rd37, %tmp; }
	add.s32 	%r16, %r7, 144;
	{ .reg .b64 %tmp;
	  cvt.u64.u32 	%tmp, %r16;
	  cvta.shared.u64 	%rd38, %tmp; }
	{ // callseq 23, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd36;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd37;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd38;
	call.uni 
	_Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2_, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 23

LBB9_6:
	ret;

}

