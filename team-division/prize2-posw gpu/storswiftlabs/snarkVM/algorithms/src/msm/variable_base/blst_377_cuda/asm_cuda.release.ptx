//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-29373293
// Cuda compilation tools, release 11.2, V11.2.67
// Based on NVVM 7.0.1
//

.version 7.2
.target sm_52
.address_size 64

	// .globl	_Z12mul_mont_384PyPKyS1_S1_y
.global .align 8 .b8 __nv_static_57__44_tmpxft_00002238_00000000_11_asm_cuda_cpp1_ii_715ad8cf_BLS12_377_P[48] = {1, 0, 0, 0, 0, 192, 8, 133, 0, 0, 0, 48, 68, 93, 11, 23, 0, 72, 9, 186, 47, 98, 243, 30, 143, 19, 245, 0, 243, 217, 34, 26, 59, 73, 161, 108, 192, 5, 59, 198, 234, 16, 197, 23, 70, 58, 174, 1};
.global .align 8 .b8 __nv_static_57__44_tmpxft_00002238_00000000_11_asm_cuda_cpp1_ii_715ad8cf_BLS12_377_ZERO[48];
.global .align 8 .b8 __nv_static_57__44_tmpxft_00002238_00000000_11_asm_cuda_cpp1_ii_715ad8cf_BLS12_377_ONE[48] = {104, 255, 255, 255, 255, 255, 205, 2, 177, 255, 255, 127, 131, 159, 64, 81, 242, 63, 125, 138, 169, 179, 125, 159, 5, 99, 124, 110, 183, 151, 78, 123, 232, 132, 60, 128, 191, 149, 244, 76, 154, 244, 253, 226, 97, 102, 141, 0};
.global .align 8 .b8 __nv_static_57__44_tmpxft_00002238_00000000_11_asm_cuda_cpp1_ii_715ad8cf_BLS12_377_R2[48] = {34, 205, 0, 148, 108, 104, 134, 183, 177, 49, 4, 176, 170, 252, 41, 3, 109, 180, 214, 98, 17, 241, 165, 34, 172, 195, 125, 130, 3, 125, 223, 191, 249, 11, 121, 65, 240, 146, 126, 131, 136, 75, 145, 30, 203, 252, 109, 0};
.global .align 8 .u64 __nv_static_57__44_tmpxft_00002238_00000000_11_asm_cuda_cpp1_ii_715ad8cf_BLS12_377_p0 = -8860621160618917889;

.visible .func _Z12mul_mont_384PyPKyS1_S1_y(
	.param .b64 _Z12mul_mont_384PyPKyS1_S1_y_param_0,
	.param .b64 _Z12mul_mont_384PyPKyS1_S1_y_param_1,
	.param .b64 _Z12mul_mont_384PyPKyS1_S1_y_param_2,
	.param .b64 _Z12mul_mont_384PyPKyS1_S1_y_param_3,
	.param .b64 _Z12mul_mont_384PyPKyS1_S1_y_param_4
)
{
	.reg .pred 	%p<12>;
	.reg .b64 	%rd<221>;


	ld.param.u64 	%rd12, [_Z12mul_mont_384PyPKyS1_S1_y_param_0];
	ld.param.u64 	%rd186, [_Z12mul_mont_384PyPKyS1_S1_y_param_1];
	ld.param.u64 	%rd187, [_Z12mul_mont_384PyPKyS1_S1_y_param_2];
	ld.param.u64 	%rd13, [_Z12mul_mont_384PyPKyS1_S1_y_param_3];
	ld.param.u64 	%rd188, [_Z12mul_mont_384PyPKyS1_S1_y_param_4];
	ld.u64 	%rd26, [%rd186];
	ld.u64 	%rd27, [%rd186+8];
	ld.u64 	%rd28, [%rd186+16];
	ld.u64 	%rd29, [%rd186+24];
	ld.u64 	%rd30, [%rd186+32];
	ld.u64 	%rd31, [%rd186+40];
	ld.u64 	%rd32, [%rd187];
	ld.u64 	%rd33, [%rd187+8];
	ld.u64 	%rd34, [%rd187+16];
	ld.u64 	%rd35, [%rd187+24];
	ld.u64 	%rd36, [%rd187+32];
	ld.u64 	%rd37, [%rd187+40];
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 nc;
	.reg .u64 t;
	mad.lo.cc.u64 %rd50, %rd26, %rd32, 0;
	madc.hi.cc.u64 c, %rd26, %rd32, 0;
	madc.lo.cc.u64 %rd72, %rd26, %rd33, c;
	madc.hi.cc.u64 c, %rd26, %rd33, 0;
	madc.lo.cc.u64 %rd73, %rd26, %rd34, c;
	madc.hi.cc.u64 c, %rd26, %rd34, 0;
	madc.lo.cc.u64 %rd74, %rd26, %rd35, c;
	madc.hi.cc.u64 c, %rd26, %rd35, 0;
	madc.lo.cc.u64 %rd75, %rd26, %rd36, c;
	madc.hi.cc.u64 c, %rd26, %rd36, 0;
	madc.lo.cc.u64 %rd76, %rd26, %rd37, c;
	madc.hi.u64 %rd77, %rd26, %rd37, 0;
	mad.lo.cc.u64 %rd72, %rd27, %rd32, %rd72;
	madc.hi.cc.u64 c, %rd27, %rd32, 0;
	addc.cc.u64 t, %rd73, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd73, %rd27, %rd33, t;
	madc.hi.cc.u64 c, %rd27, %rd33, nc;
	addc.cc.u64 t, %rd74, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd74, %rd27, %rd34, t;
	madc.hi.cc.u64 c, %rd27, %rd34, nc;
	addc.cc.u64 t, %rd75, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd75, %rd27, %rd35, t;
	madc.hi.cc.u64 c, %rd27, %rd35, nc;
	addc.cc.u64 t, %rd76, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd76, %rd27, %rd36, t;
	madc.hi.cc.u64 c, %rd27, %rd36, nc;
	addc.cc.u64 t, %rd77, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd77, %rd27, %rd37, t;
	madc.hi.u64 %rd100, %rd27, %rd37, nc;
	mad.lo.cc.u64 %rd73, %rd28, %rd32, %rd73;
	madc.hi.cc.u64 c, %rd28, %rd32, 0;
	addc.cc.u64 t, %rd74, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd74, %rd28, %rd33, t;
	madc.hi.cc.u64 c, %rd28, %rd33, nc;
	addc.cc.u64 t, %rd75, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd75, %rd28, %rd34, t;
	madc.hi.cc.u64 c, %rd28, %rd34, nc;
	addc.cc.u64 t, %rd76, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd76, %rd28, %rd35, t;
	madc.hi.cc.u64 c, %rd28, %rd35, nc;
	addc.cc.u64 t, %rd77, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd77, %rd28, %rd36, t;
	madc.hi.cc.u64 c, %rd28, %rd36, nc;
	addc.cc.u64 t, %rd100, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd100, %rd28, %rd37, t;
	madc.hi.u64 %rd123, %rd28, %rd37, nc;
	mad.lo.cc.u64 %rd74, %rd29, %rd32, %rd74;
	madc.hi.cc.u64 c, %rd29, %rd32, 0;
	addc.cc.u64 t, %rd75, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd75, %rd29, %rd33, t;
	madc.hi.cc.u64 c, %rd29, %rd33, nc;
	addc.cc.u64 t, %rd76, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd76, %rd29, %rd34, t;
	madc.hi.cc.u64 c, %rd29, %rd34, nc;
	addc.cc.u64 t, %rd77, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd77, %rd29, %rd35, t;
	madc.hi.cc.u64 c, %rd29, %rd35, nc;
	addc.cc.u64 t, %rd100, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd100, %rd29, %rd36, t;
	madc.hi.cc.u64 c, %rd29, %rd36, nc;
	addc.cc.u64 t, %rd123, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd123, %rd29, %rd37, t;
	madc.hi.u64 %rd146, %rd29, %rd37, nc;
	mad.lo.cc.u64 %rd75, %rd30, %rd32, %rd75;
	madc.hi.cc.u64 c, %rd30, %rd32, 0;
	addc.cc.u64 t, %rd76, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd76, %rd30, %rd33, t;
	madc.hi.cc.u64 c, %rd30, %rd33, nc;
	addc.cc.u64 t, %rd77, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd77, %rd30, %rd34, t;
	madc.hi.cc.u64 c, %rd30, %rd34, nc;
	addc.cc.u64 t, %rd100, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd100, %rd30, %rd35, t;
	madc.hi.cc.u64 c, %rd30, %rd35, nc;
	addc.cc.u64 t, %rd123, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd123, %rd30, %rd36, t;
	madc.hi.cc.u64 c, %rd30, %rd36, nc;
	addc.cc.u64 t, %rd146, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd146, %rd30, %rd37, t;
	madc.hi.u64 %rd169, %rd30, %rd37, nc;
	mad.lo.cc.u64 %rd76, %rd31, %rd32, %rd76;
	madc.hi.cc.u64 c, %rd31, %rd32, 0;
	addc.cc.u64 t, %rd77, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd77, %rd31, %rd33, t;
	madc.hi.cc.u64 c, %rd31, %rd33, nc;
	addc.cc.u64 t, %rd100, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd100, %rd31, %rd34, t;
	madc.hi.cc.u64 c, %rd31, %rd34, nc;
	addc.cc.u64 t, %rd123, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd123, %rd31, %rd35, t;
	madc.hi.cc.u64 c, %rd31, %rd35, nc;
	addc.cc.u64 t, %rd146, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd146, %rd31, %rd36, t;
	madc.hi.cc.u64 c, %rd31, %rd36, nc;
	addc.cc.u64 t, %rd169, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd169, %rd31, %rd37, t;
	madc.hi.u64 %rd170, %rd31, %rd37, nc;
	}
	// end inline asm
	mul.lo.s64 	%rd64, %rd50, %rd188;
	ld.u64 	%rd58, [%rd13];
	ld.u64 	%rd59, [%rd13+8];
	ld.u64 	%rd60, [%rd13+16];
	ld.u64 	%rd61, [%rd13+24];
	ld.u64 	%rd62, [%rd13+32];
	ld.u64 	%rd63, [%rd13+40];
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd64, %rd58, %rd50;
	madc.hi.cc.u64 c, %rd64, %rd58, 0;
	addc.cc.u64 t, %rd72, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd72, %rd64, %rd59, t;
	madc.hi.cc.u64 c, %rd64, %rd59, nc;
	addc.cc.u64 t, %rd73, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd73, %rd64, %rd60, t;
	madc.hi.cc.u64 c, %rd64, %rd60, nc;
	addc.cc.u64 t, %rd74, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd74, %rd64, %rd61, t;
	madc.hi.cc.u64 c, %rd64, %rd61, nc;
	addc.cc.u64 t, %rd75, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd75, %rd64, %rd62, t;
	madc.hi.cc.u64 c, %rd64, %rd62, nc;
	addc.cc.u64 t, %rd76, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd76, %rd64, %rd63, t;
	madc.hi.cc.u64 c, %rd64, %rd63, nc;
	addc.cc.u64 %rd77, %rd77, c;
	addc.u64 %rd102, 0, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd86, %rd72, %rd188;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd86, %rd58, %rd72;
	madc.hi.cc.u64 c, %rd86, %rd58, 0;
	addc.cc.u64 t, %rd73, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd73, %rd86, %rd59, t;
	madc.hi.cc.u64 c, %rd86, %rd59, nc;
	addc.cc.u64 t, %rd74, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd74, %rd86, %rd60, t;
	madc.hi.cc.u64 c, %rd86, %rd60, nc;
	addc.cc.u64 t, %rd75, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd75, %rd86, %rd61, t;
	madc.hi.cc.u64 c, %rd86, %rd61, nc;
	addc.cc.u64 t, %rd76, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd76, %rd86, %rd62, t;
	madc.hi.cc.u64 c, %rd86, %rd62, nc;
	addc.cc.u64 t, %rd77, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd77, %rd86, %rd63, t;
	madc.hi.cc.u64 c, %rd86, %rd63, nc;
	addc.cc.u64 c, c, %rd102;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd100, %rd100, c;
	addc.u64 %rd102, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd109, %rd73, %rd188;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd109, %rd58, %rd73;
	madc.hi.cc.u64 c, %rd109, %rd58, 0;
	addc.cc.u64 t, %rd74, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd74, %rd109, %rd59, t;
	madc.hi.cc.u64 c, %rd109, %rd59, nc;
	addc.cc.u64 t, %rd75, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd75, %rd109, %rd60, t;
	madc.hi.cc.u64 c, %rd109, %rd60, nc;
	addc.cc.u64 t, %rd76, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd76, %rd109, %rd61, t;
	madc.hi.cc.u64 c, %rd109, %rd61, nc;
	addc.cc.u64 t, %rd77, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd77, %rd109, %rd62, t;
	madc.hi.cc.u64 c, %rd109, %rd62, nc;
	addc.cc.u64 t, %rd100, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd100, %rd109, %rd63, t;
	madc.hi.cc.u64 c, %rd109, %rd63, nc;
	addc.cc.u64 c, c, %rd102;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd123, %rd123, c;
	addc.u64 %rd102, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd132, %rd74, %rd188;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd132, %rd58, %rd74;
	madc.hi.cc.u64 c, %rd132, %rd58, 0;
	addc.cc.u64 t, %rd75, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd75, %rd132, %rd59, t;
	madc.hi.cc.u64 c, %rd132, %rd59, nc;
	addc.cc.u64 t, %rd76, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd76, %rd132, %rd60, t;
	madc.hi.cc.u64 c, %rd132, %rd60, nc;
	addc.cc.u64 t, %rd77, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd77, %rd132, %rd61, t;
	madc.hi.cc.u64 c, %rd132, %rd61, nc;
	addc.cc.u64 t, %rd100, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd100, %rd132, %rd62, t;
	madc.hi.cc.u64 c, %rd132, %rd62, nc;
	addc.cc.u64 t, %rd123, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd123, %rd132, %rd63, t;
	madc.hi.cc.u64 c, %rd132, %rd63, nc;
	addc.cc.u64 c, c, %rd102;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd146, %rd146, c;
	addc.u64 %rd102, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd155, %rd75, %rd188;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd155, %rd58, %rd75;
	madc.hi.cc.u64 c, %rd155, %rd58, 0;
	addc.cc.u64 t, %rd76, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd76, %rd155, %rd59, t;
	madc.hi.cc.u64 c, %rd155, %rd59, nc;
	addc.cc.u64 t, %rd77, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd77, %rd155, %rd60, t;
	madc.hi.cc.u64 c, %rd155, %rd60, nc;
	addc.cc.u64 t, %rd100, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd100, %rd155, %rd61, t;
	madc.hi.cc.u64 c, %rd155, %rd61, nc;
	addc.cc.u64 t, %rd123, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd123, %rd155, %rd62, t;
	madc.hi.cc.u64 c, %rd155, %rd62, nc;
	addc.cc.u64 t, %rd146, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd146, %rd155, %rd63, t;
	madc.hi.cc.u64 c, %rd155, %rd63, nc;
	addc.cc.u64 c, c, %rd102;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd169, %rd169, c;
	addc.u64 %rd102, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd178, %rd76, %rd188;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd178, %rd58, %rd76;
	madc.hi.cc.u64 c, %rd178, %rd58, 0;
	addc.cc.u64 t, %rd77, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd77, %rd178, %rd59, t;
	madc.hi.cc.u64 c, %rd178, %rd59, nc;
	addc.cc.u64 t, %rd100, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd100, %rd178, %rd60, t;
	madc.hi.cc.u64 c, %rd178, %rd60, nc;
	addc.cc.u64 t, %rd123, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd123, %rd178, %rd61, t;
	madc.hi.cc.u64 c, %rd178, %rd61, nc;
	addc.cc.u64 t, %rd146, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd146, %rd178, %rd62, t;
	madc.hi.cc.u64 c, %rd178, %rd62, nc;
	addc.cc.u64 t, %rd169, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd169, %rd178, %rd63, t;
	madc.hi.cc.u64 c, %rd178, %rd63, nc;
	addc.cc.u64 c, c, %rd102;
	add.u64 %rd170, %rd170, c;
	}
	// end inline asm
	st.u64 	[%rd12], %rd77;
	st.u64 	[%rd12+8], %rd100;
	st.u64 	[%rd12+16], %rd123;
	st.u64 	[%rd12+24], %rd146;
	st.u64 	[%rd12+32], %rd169;
	st.u64 	[%rd12+40], %rd170;
	ld.u64 	%rd7, [%rd13+40];
	setp.lt.u64 	%p1, %rd170, %rd7;
	@%p1 bra 	LBB0_12;

	setp.gt.u64 	%p2, %rd170, %rd7;
	ld.u64 	%rd8, [%rd13+32];
	@%p2 bra 	LBB0_11;

	setp.lt.u64 	%p3, %rd169, %rd8;
	@%p3 bra 	LBB0_12;

	setp.gt.u64 	%p4, %rd169, %rd8;
	@%p4 bra 	LBB0_11;

	ld.u64 	%rd9, [%rd13+24];
	setp.lt.u64 	%p5, %rd146, %rd9;
	@%p5 bra 	LBB0_12;

	setp.gt.u64 	%p6, %rd146, %rd9;
	@%p6 bra 	LBB0_11;

	ld.u64 	%rd10, [%rd13+16];
	setp.lt.u64 	%p7, %rd123, %rd10;
	@%p7 bra 	LBB0_12;

	setp.gt.u64 	%p8, %rd123, %rd10;
	@%p8 bra 	LBB0_11;

	ld.u64 	%rd11, [%rd13+8];
	setp.lt.u64 	%p9, %rd100, %rd11;
	@%p9 bra 	LBB0_12;

	setp.gt.u64 	%p10, %rd100, %rd11;
	@%p10 bra 	LBB0_11;

	ld.u64 	%rd201, [%rd13];
	setp.lt.u64 	%p11, %rd77, %rd201;
	@%p11 bra 	LBB0_12;

LBB0_11:
	ld.param.u64 	%rd220, [_Z12mul_mont_384PyPKyS1_S1_y_param_0];
	ld.u64 	%rd214, [%rd13];
	ld.u64 	%rd215, [%rd13+8];
	ld.u64 	%rd216, [%rd13+16];
	ld.u64 	%rd217, [%rd13+24];
	// begin inline asm
	sub.cc.u64 %rd202, %rd77, %rd214;
	subc.cc.u64 %rd203, %rd100, %rd215;
	subc.cc.u64 %rd204, %rd123, %rd216;
	subc.cc.u64 %rd205, %rd146, %rd217;
	subc.cc.u64 %rd206, %rd169, %rd8;
	subc.u64 %rd207, %rd170, %rd7;
	// end inline asm
	st.u64 	[%rd220], %rd202;
	st.u64 	[%rd220+8], %rd203;
	st.u64 	[%rd220+16], %rd204;
	st.u64 	[%rd220+24], %rd205;
	st.u64 	[%rd220+32], %rd206;
	st.u64 	[%rd220+40], %rd207;

LBB0_12:
	ret;

}
	// .globl	_Z12sqr_mont_384PyPKyS1_y
.visible .func _Z12sqr_mont_384PyPKyS1_y(
	.param .b64 _Z12sqr_mont_384PyPKyS1_y_param_0,
	.param .b64 _Z12sqr_mont_384PyPKyS1_y_param_1,
	.param .b64 _Z12sqr_mont_384PyPKyS1_y_param_2,
	.param .b64 _Z12sqr_mont_384PyPKyS1_y_param_3
)
{
	.reg .pred 	%p<12>;
	.reg .b64 	%rd<262>;


	ld.param.u64 	%rd12, [_Z12sqr_mont_384PyPKyS1_y_param_0];
	ld.param.u64 	%rd210, [_Z12sqr_mont_384PyPKyS1_y_param_1];
	ld.param.u64 	%rd13, [_Z12sqr_mont_384PyPKyS1_y_param_2];
	ld.param.u64 	%rd211, [_Z12sqr_mont_384PyPKyS1_y_param_3];
	ld.u64 	%rd26, [%rd210];
	ld.u64 	%rd27, [%rd210+8];
	ld.u64 	%rd28, [%rd210+16];
	ld.u64 	%rd29, [%rd210+24];
	ld.u64 	%rd30, [%rd210+32];
	ld.u64 	%rd31, [%rd210+40];
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 nc;
	.reg .u64 t;
	mad.lo.cc.u64 %rd15, %rd26, %rd27, 0;
	madc.hi.cc.u64 c, %rd26, %rd27, 0;
	madc.lo.cc.u64 %rd16, %rd26, %rd28, c;
	madc.hi.cc.u64 c, %rd26, %rd28, 0;
	madc.lo.cc.u64 %rd17, %rd26, %rd29, c;
	madc.hi.cc.u64 c, %rd26, %rd29, 0;
	madc.lo.cc.u64 %rd18, %rd26, %rd30, c;
	madc.hi.cc.u64 c, %rd26, %rd30, 0;
	madc.lo.cc.u64 %rd19, %rd26, %rd31, c;
	madc.hi.u64 %rd20, %rd26, %rd31, 0;
	mad.lo.cc.u64 %rd17, %rd27, %rd28, %rd17;
	madc.hi.cc.u64 c, %rd27, %rd28, 0;
	addc.cc.u64 t, %rd18, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd18, %rd27, %rd29, t;
	madc.hi.cc.u64 c, %rd27, %rd29, nc;
	addc.cc.u64 t, %rd19, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd19, %rd27, %rd30, t;
	madc.hi.cc.u64 c, %rd27, %rd30, nc;
	addc.cc.u64 t, %rd20, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd20, %rd27, %rd31, t;
	madc.hi.u64 %rd21, %rd27, %rd31, nc;
	mad.lo.cc.u64 %rd19, %rd28, %rd29, %rd19;
	madc.hi.cc.u64 c, %rd28, %rd29, 0;
	addc.cc.u64 t, %rd20, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd20, %rd28, %rd30, t;
	madc.hi.cc.u64 c, %rd28, %rd30, nc;
	addc.cc.u64 t, %rd21, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd21, %rd28, %rd31, t;
	madc.hi.u64 %rd22, %rd28, %rd31, nc;
	mad.lo.cc.u64 %rd21, %rd29, %rd30, %rd21;
	madc.hi.cc.u64 c, %rd29, %rd30, 0;
	addc.cc.u64 t, %rd22, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd22, %rd29, %rd31, t;
	madc.hi.u64 %rd23, %rd29, %rd31, nc;
	mad.lo.cc.u64 %rd23, %rd30, %rd31, %rd23;
	madc.hi.u64 %rd24, %rd30, %rd31, 0;
	}
	// end inline asm
	shr.u64 	%rd194, %rd24, 63;
	shl.b64 	%rd224, %rd24, 1;
	shr.u64 	%rd225, %rd23, 63;
	or.b64  	%rd171, %rd224, %rd225;
	shl.b64 	%rd226, %rd23, 1;
	shr.u64 	%rd227, %rd22, 63;
	or.b64  	%rd148, %rd226, %rd227;
	shl.b64 	%rd228, %rd22, 1;
	shr.u64 	%rd229, %rd21, 63;
	or.b64  	%rd125, %rd228, %rd229;
	shl.b64 	%rd230, %rd21, 1;
	shr.u64 	%rd231, %rd20, 63;
	or.b64  	%rd102, %rd230, %rd231;
	shl.b64 	%rd232, %rd20, 1;
	shr.u64 	%rd233, %rd19, 63;
	or.b64  	%rd80, %rd232, %rd233;
	shl.b64 	%rd234, %rd19, 1;
	shr.u64 	%rd235, %rd18, 63;
	or.b64  	%rd79, %rd234, %rd235;
	shl.b64 	%rd236, %rd18, 1;
	shr.u64 	%rd237, %rd17, 63;
	or.b64  	%rd78, %rd236, %rd237;
	shl.b64 	%rd238, %rd17, 1;
	shr.u64 	%rd239, %rd16, 63;
	or.b64  	%rd77, %rd238, %rd239;
	shl.b64 	%rd240, %rd16, 1;
	shr.u64 	%rd241, %rd15, 63;
	or.b64  	%rd76, %rd240, %rd241;
	shl.b64 	%rd75, %rd15, 1;
	// begin inline asm
	{
	mad.lo.cc.u64 %rd74, %rd26, %rd26, 0;
	madc.hi.cc.u64 %rd75, %rd26, %rd26, %rd75;
	madc.lo.cc.u64 %rd76, %rd27, %rd27, %rd76;
	madc.hi.cc.u64 %rd77, %rd27, %rd27, %rd77;
	madc.lo.cc.u64 %rd78, %rd28, %rd28, %rd78;
	madc.hi.cc.u64 %rd79, %rd28, %rd28, %rd79;
	madc.lo.cc.u64 %rd80, %rd29, %rd29, %rd80;
	madc.hi.cc.u64 %rd102, %rd29, %rd29, %rd102;
	madc.lo.cc.u64 %rd125, %rd30, %rd30, %rd125;
	madc.hi.cc.u64 %rd148, %rd30, %rd30, %rd148;
	madc.lo.cc.u64 %rd171, %rd31, %rd31, %rd171;
	madc.hi.u64 %rd194, %rd31, %rd31, %rd194;
	}
	// end inline asm
	mul.lo.s64 	%rd88, %rd74, %rd211;
	ld.u64 	%rd82, [%rd13];
	ld.u64 	%rd83, [%rd13+8];
	ld.u64 	%rd84, [%rd13+16];
	ld.u64 	%rd85, [%rd13+24];
	ld.u64 	%rd86, [%rd13+32];
	ld.u64 	%rd87, [%rd13+40];
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd88, %rd82, %rd74;
	madc.hi.cc.u64 c, %rd88, %rd82, 0;
	addc.cc.u64 t, %rd75, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd75, %rd88, %rd83, t;
	madc.hi.cc.u64 c, %rd88, %rd83, nc;
	addc.cc.u64 t, %rd76, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd76, %rd88, %rd84, t;
	madc.hi.cc.u64 c, %rd88, %rd84, nc;
	addc.cc.u64 t, %rd77, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd77, %rd88, %rd85, t;
	madc.hi.cc.u64 c, %rd88, %rd85, nc;
	addc.cc.u64 t, %rd78, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd78, %rd88, %rd86, t;
	madc.hi.cc.u64 c, %rd88, %rd86, nc;
	addc.cc.u64 t, %rd79, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd79, %rd88, %rd87, t;
	madc.hi.cc.u64 c, %rd88, %rd87, nc;
	addc.cc.u64 %rd80, %rd80, c;
	addc.u64 %rd126, 0, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd110, %rd75, %rd211;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd110, %rd82, %rd75;
	madc.hi.cc.u64 c, %rd110, %rd82, 0;
	addc.cc.u64 t, %rd76, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd76, %rd110, %rd83, t;
	madc.hi.cc.u64 c, %rd110, %rd83, nc;
	addc.cc.u64 t, %rd77, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd77, %rd110, %rd84, t;
	madc.hi.cc.u64 c, %rd110, %rd84, nc;
	addc.cc.u64 t, %rd78, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd78, %rd110, %rd85, t;
	madc.hi.cc.u64 c, %rd110, %rd85, nc;
	addc.cc.u64 t, %rd79, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd79, %rd110, %rd86, t;
	madc.hi.cc.u64 c, %rd110, %rd86, nc;
	addc.cc.u64 t, %rd80, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd80, %rd110, %rd87, t;
	madc.hi.cc.u64 c, %rd110, %rd87, nc;
	addc.cc.u64 c, c, %rd126;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd102, %rd102, c;
	addc.u64 %rd126, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd133, %rd76, %rd211;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd133, %rd82, %rd76;
	madc.hi.cc.u64 c, %rd133, %rd82, 0;
	addc.cc.u64 t, %rd77, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd77, %rd133, %rd83, t;
	madc.hi.cc.u64 c, %rd133, %rd83, nc;
	addc.cc.u64 t, %rd78, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd78, %rd133, %rd84, t;
	madc.hi.cc.u64 c, %rd133, %rd84, nc;
	addc.cc.u64 t, %rd79, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd79, %rd133, %rd85, t;
	madc.hi.cc.u64 c, %rd133, %rd85, nc;
	addc.cc.u64 t, %rd80, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd80, %rd133, %rd86, t;
	madc.hi.cc.u64 c, %rd133, %rd86, nc;
	addc.cc.u64 t, %rd102, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd102, %rd133, %rd87, t;
	madc.hi.cc.u64 c, %rd133, %rd87, nc;
	addc.cc.u64 c, c, %rd126;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd125, %rd125, c;
	addc.u64 %rd126, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd156, %rd77, %rd211;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd156, %rd82, %rd77;
	madc.hi.cc.u64 c, %rd156, %rd82, 0;
	addc.cc.u64 t, %rd78, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd78, %rd156, %rd83, t;
	madc.hi.cc.u64 c, %rd156, %rd83, nc;
	addc.cc.u64 t, %rd79, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd79, %rd156, %rd84, t;
	madc.hi.cc.u64 c, %rd156, %rd84, nc;
	addc.cc.u64 t, %rd80, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd80, %rd156, %rd85, t;
	madc.hi.cc.u64 c, %rd156, %rd85, nc;
	addc.cc.u64 t, %rd102, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd102, %rd156, %rd86, t;
	madc.hi.cc.u64 c, %rd156, %rd86, nc;
	addc.cc.u64 t, %rd125, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd125, %rd156, %rd87, t;
	madc.hi.cc.u64 c, %rd156, %rd87, nc;
	addc.cc.u64 c, c, %rd126;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd148, %rd148, c;
	addc.u64 %rd126, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd179, %rd78, %rd211;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd179, %rd82, %rd78;
	madc.hi.cc.u64 c, %rd179, %rd82, 0;
	addc.cc.u64 t, %rd79, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd79, %rd179, %rd83, t;
	madc.hi.cc.u64 c, %rd179, %rd83, nc;
	addc.cc.u64 t, %rd80, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd80, %rd179, %rd84, t;
	madc.hi.cc.u64 c, %rd179, %rd84, nc;
	addc.cc.u64 t, %rd102, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd102, %rd179, %rd85, t;
	madc.hi.cc.u64 c, %rd179, %rd85, nc;
	addc.cc.u64 t, %rd125, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd125, %rd179, %rd86, t;
	madc.hi.cc.u64 c, %rd179, %rd86, nc;
	addc.cc.u64 t, %rd148, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd148, %rd179, %rd87, t;
	madc.hi.cc.u64 c, %rd179, %rd87, nc;
	addc.cc.u64 c, c, %rd126;
	addc.u64 nc, 0, 0;
	addc.cc.u64 %rd171, %rd171, c;
	addc.u64 %rd126, nc, 0;
	}
	// end inline asm
	mul.lo.s64 	%rd202, %rd79, %rd211;
	// begin inline asm
	{
	.reg .u64 c;
	.reg .u64 t;
	.reg .u64 nc;
	mad.lo.cc.u64 c, %rd202, %rd82, %rd79;
	madc.hi.cc.u64 c, %rd202, %rd82, 0;
	addc.cc.u64 t, %rd80, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd80, %rd202, %rd83, t;
	madc.hi.cc.u64 c, %rd202, %rd83, nc;
	addc.cc.u64 t, %rd102, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd102, %rd202, %rd84, t;
	madc.hi.cc.u64 c, %rd202, %rd84, nc;
	addc.cc.u64 t, %rd125, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd125, %rd202, %rd85, t;
	madc.hi.cc.u64 c, %rd202, %rd85, nc;
	addc.cc.u64 t, %rd148, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd148, %rd202, %rd86, t;
	madc.hi.cc.u64 c, %rd202, %rd86, nc;
	addc.cc.u64 t, %rd171, c;
	addc.u64 nc, 0, 0;
	mad.lo.cc.u64 %rd171, %rd202, %rd87, t;
	madc.hi.cc.u64 c, %rd202, %rd87, nc;
	addc.cc.u64 c, c, %rd126;
	add.u64 %rd194, %rd194, c;
	}
	// end inline asm
	st.u64 	[%rd12], %rd80;
	st.u64 	[%rd12+8], %rd102;
	st.u64 	[%rd12+16], %rd125;
	st.u64 	[%rd12+24], %rd148;
	st.u64 	[%rd12+32], %rd171;
	st.u64 	[%rd12+40], %rd194;
	ld.u64 	%rd7, [%rd13+40];
	setp.lt.u64 	%p1, %rd194, %rd7;
	@%p1 bra 	LBB1_12;

	setp.gt.u64 	%p2, %rd194, %rd7;
	ld.u64 	%rd8, [%rd13+32];
	@%p2 bra 	LBB1_11;

	setp.lt.u64 	%p3, %rd171, %rd8;
	@%p3 bra 	LBB1_12;

	setp.gt.u64 	%p4, %rd171, %rd8;
	@%p4 bra 	LBB1_11;

	ld.u64 	%rd9, [%rd13+24];
	setp.lt.u64 	%p5, %rd148, %rd9;
	@%p5 bra 	LBB1_12;

	setp.gt.u64 	%p6, %rd148, %rd9;
	@%p6 bra 	LBB1_11;

	ld.u64 	%rd10, [%rd13+16];
	setp.lt.u64 	%p7, %rd125, %rd10;
	@%p7 bra 	LBB1_12;

	setp.gt.u64 	%p8, %rd125, %rd10;
	@%p8 bra 	LBB1_11;

	ld.u64 	%rd11, [%rd13+8];
	setp.lt.u64 	%p9, %rd102, %rd11;
	@%p9 bra 	LBB1_12;

	setp.gt.u64 	%p10, %rd102, %rd11;
	@%p10 bra 	LBB1_11;

	ld.u64 	%rd242, [%rd13];
	setp.lt.u64 	%p11, %rd80, %rd242;
	@%p11 bra 	LBB1_12;

LBB1_11:
	ld.param.u64 	%rd261, [_Z12sqr_mont_384PyPKyS1_y_param_0];
	ld.u64 	%rd255, [%rd13];
	ld.u64 	%rd256, [%rd13+8];
	ld.u64 	%rd257, [%rd13+16];
	ld.u64 	%rd258, [%rd13+24];
	// begin inline asm
	sub.cc.u64 %rd243, %rd80, %rd255;
	subc.cc.u64 %rd244, %rd102, %rd256;
	subc.cc.u64 %rd245, %rd125, %rd257;
	subc.cc.u64 %rd246, %rd148, %rd258;
	subc.cc.u64 %rd247, %rd171, %rd8;
	subc.u64 %rd248, %rd194, %rd7;
	// end inline asm
	st.u64 	[%rd261], %rd243;
	st.u64 	[%rd261+8], %rd244;
	st.u64 	[%rd261+16], %rd245;
	st.u64 	[%rd261+24], %rd246;
	st.u64 	[%rd261+32], %rd247;
	st.u64 	[%rd261+40], %rd248;

LBB1_12:
	ret;

}
	// .globl	_Z11add_mod_384PyPKyS1_S1_
.visible .func _Z11add_mod_384PyPKyS1_S1_(
	.param .b64 _Z11add_mod_384PyPKyS1_S1__param_0,
	.param .b64 _Z11add_mod_384PyPKyS1_S1__param_1,
	.param .b64 _Z11add_mod_384PyPKyS1_S1__param_2,
	.param .b64 _Z11add_mod_384PyPKyS1_S1__param_3
)
{
	.reg .pred 	%p<12>;
	.reg .b64 	%rd<53>;


	ld.param.u64 	%rd13, [_Z11add_mod_384PyPKyS1_S1__param_0];
	ld.param.u64 	%rd32, [_Z11add_mod_384PyPKyS1_S1__param_1];
	ld.param.u64 	%rd33, [_Z11add_mod_384PyPKyS1_S1__param_2];
	ld.param.u64 	%rd7, [_Z11add_mod_384PyPKyS1_S1__param_3];
	ld.u64 	%rd20, [%rd32];
	ld.u64 	%rd21, [%rd32+8];
	ld.u64 	%rd22, [%rd32+16];
	ld.u64 	%rd23, [%rd32+24];
	ld.u64 	%rd24, [%rd32+32];
	ld.u64 	%rd25, [%rd32+40];
	ld.u64 	%rd26, [%rd33];
	ld.u64 	%rd27, [%rd33+8];
	ld.u64 	%rd28, [%rd33+16];
	ld.u64 	%rd29, [%rd33+24];
	ld.u64 	%rd30, [%rd33+32];
	ld.u64 	%rd31, [%rd33+40];
	// begin inline asm
	add.cc.u64 %rd14, %rd20, %rd26;
	addc.cc.u64 %rd15, %rd21, %rd27;
	addc.cc.u64 %rd16, %rd22, %rd28;
	addc.cc.u64 %rd17, %rd23, %rd29;
	addc.cc.u64 %rd18, %rd24, %rd30;
	addc.u64 %rd19, %rd25, %rd31;
	// end inline asm
	st.u64 	[%rd13], %rd14;
	st.u64 	[%rd13+8], %rd15;
	st.u64 	[%rd13+16], %rd16;
	st.u64 	[%rd13+24], %rd17;
	st.u64 	[%rd13+32], %rd18;
	st.u64 	[%rd13+40], %rd19;
	ld.u64 	%rd8, [%rd7+40];
	setp.lt.u64 	%p1, %rd19, %rd8;
	@%p1 bra 	LBB2_12;

	setp.gt.u64 	%p2, %rd19, %rd8;
	ld.u64 	%rd9, [%rd7+32];
	@%p2 bra 	LBB2_11;

	setp.lt.u64 	%p3, %rd18, %rd9;
	@%p3 bra 	LBB2_12;

	setp.gt.u64 	%p4, %rd18, %rd9;
	@%p4 bra 	LBB2_11;

	ld.u64 	%rd10, [%rd7+24];
	setp.lt.u64 	%p5, %rd17, %rd10;
	@%p5 bra 	LBB2_12;

	setp.gt.u64 	%p6, %rd17, %rd10;
	@%p6 bra 	LBB2_11;

	ld.u64 	%rd11, [%rd7+16];
	setp.lt.u64 	%p7, %rd16, %rd11;
	@%p7 bra 	LBB2_12;

	setp.gt.u64 	%p8, %rd16, %rd11;
	@%p8 bra 	LBB2_11;

	ld.u64 	%rd12, [%rd7+8];
	setp.lt.u64 	%p9, %rd15, %rd12;
	@%p9 bra 	LBB2_12;

	setp.gt.u64 	%p10, %rd15, %rd12;
	@%p10 bra 	LBB2_11;

	ld.u64 	%rd34, [%rd7];
	setp.lt.u64 	%p11, %rd14, %rd34;
	@%p11 bra 	LBB2_12;

LBB2_11:
	ld.u64 	%rd47, [%rd7];
	ld.u64 	%rd48, [%rd7+8];
	ld.u64 	%rd49, [%rd7+16];
	ld.u64 	%rd50, [%rd7+24];
	// begin inline asm
	sub.cc.u64 %rd35, %rd14, %rd47;
	subc.cc.u64 %rd36, %rd15, %rd48;
	subc.cc.u64 %rd37, %rd16, %rd49;
	subc.cc.u64 %rd38, %rd17, %rd50;
	subc.cc.u64 %rd39, %rd18, %rd9;
	subc.u64 %rd40, %rd19, %rd8;
	// end inline asm
	st.u64 	[%rd13], %rd35;
	st.u64 	[%rd13+8], %rd36;
	st.u64 	[%rd13+16], %rd37;
	st.u64 	[%rd13+24], %rd38;
	st.u64 	[%rd13+32], %rd39;
	st.u64 	[%rd13+40], %rd40;

LBB2_12:
	ret;

}
	// .globl	_Z11sub_mod_384PyPKyS1_S1_
.visible .func _Z11sub_mod_384PyPKyS1_S1_(
	.param .b64 _Z11sub_mod_384PyPKyS1_S1__param_0,
	.param .b64 _Z11sub_mod_384PyPKyS1_S1__param_1,
	.param .b64 _Z11sub_mod_384PyPKyS1_S1__param_2,
	.param .b64 _Z11sub_mod_384PyPKyS1_S1__param_3
)
{
	.reg .pred 	%p<12>;
	.reg .b64 	%rd<72>;


	ld.param.u64 	%rd25, [_Z11sub_mod_384PyPKyS1_S1__param_0];
	ld.param.u64 	%rd28, [_Z11sub_mod_384PyPKyS1_S1__param_1];
	ld.param.u64 	%rd26, [_Z11sub_mod_384PyPKyS1_S1__param_2];
	ld.param.u64 	%rd27, [_Z11sub_mod_384PyPKyS1_S1__param_3];
	ld.u64 	%rd71, [%rd28];
	ld.u64 	%rd70, [%rd28+8];
	ld.u64 	%rd69, [%rd28+16];
	ld.u64 	%rd68, [%rd28+24];
	ld.u64 	%rd67, [%rd28+32];
	ld.u64 	%rd7, [%rd26+40];
	ld.u64 	%rd66, [%rd28+40];
	setp.lt.u64 	%p1, %rd7, %rd66;
	@%p1 bra 	LBB3_12;

	setp.gt.u64 	%p2, %rd7, %rd66;
	@%p2 bra 	LBB3_11;

	ld.u64 	%rd9, [%rd26+32];
	setp.lt.u64 	%p3, %rd9, %rd67;
	@%p3 bra 	LBB3_12;

	setp.gt.u64 	%p4, %rd9, %rd67;
	@%p4 bra 	LBB3_11;

	ld.u64 	%rd10, [%rd26+24];
	setp.lt.u64 	%p5, %rd10, %rd68;
	@%p5 bra 	LBB3_12;

	setp.gt.u64 	%p6, %rd10, %rd68;
	@%p6 bra 	LBB3_11;

	ld.u64 	%rd11, [%rd26+16];
	setp.lt.u64 	%p7, %rd11, %rd69;
	@%p7 bra 	LBB3_12;

	setp.gt.u64 	%p8, %rd11, %rd69;
	@%p8 bra 	LBB3_11;

	ld.u64 	%rd12, [%rd26+8];
	setp.lt.u64 	%p9, %rd12, %rd70;
	@%p9 bra 	LBB3_12;

	setp.gt.u64 	%p10, %rd12, %rd70;
	@%p10 bra 	LBB3_11;

	ld.u64 	%rd29, [%rd26];
	setp.le.u64 	%p11, %rd29, %rd71;
	@%p11 bra 	LBB3_12;

LBB3_11:
	ld.u64 	%rd42, [%rd27];
	ld.u64 	%rd43, [%rd27+8];
	ld.u64 	%rd44, [%rd27+16];
	ld.u64 	%rd45, [%rd27+24];
	ld.u64 	%rd46, [%rd27+32];
	ld.u64 	%rd47, [%rd27+40];
	// begin inline asm
	add.cc.u64 %rd71, %rd71, %rd42;
	addc.cc.u64 %rd70, %rd70, %rd43;
	addc.cc.u64 %rd69, %rd69, %rd44;
	addc.cc.u64 %rd68, %rd68, %rd45;
	addc.cc.u64 %rd67, %rd67, %rd46;
	addc.u64 %rd66, %rd66, %rd47;
	// end inline asm

LBB3_12:
	ld.u64 	%rd60, [%rd26];
	ld.u64 	%rd61, [%rd26+8];
	ld.u64 	%rd62, [%rd26+16];
	ld.u64 	%rd63, [%rd26+24];
	ld.u64 	%rd64, [%rd26+32];
	// begin inline asm
	sub.cc.u64 %rd48, %rd71, %rd60;
	subc.cc.u64 %rd49, %rd70, %rd61;
	subc.cc.u64 %rd50, %rd69, %rd62;
	subc.cc.u64 %rd51, %rd68, %rd63;
	subc.cc.u64 %rd52, %rd67, %rd64;
	subc.u64 %rd53, %rd66, %rd7;
	// end inline asm
	st.u64 	[%rd25], %rd48;
	st.u64 	[%rd25+8], %rd49;
	st.u64 	[%rd25+16], %rd50;
	st.u64 	[%rd25+24], %rd51;
	st.u64 	[%rd25+32], %rd52;
	st.u64 	[%rd25+40], %rd53;
	ret;

}
	// .globl	_Z18sub_mod_384_unsafePyPKyS1_
.visible .func _Z18sub_mod_384_unsafePyPKyS1_(
	.param .b64 _Z18sub_mod_384_unsafePyPKyS1__param_0,
	.param .b64 _Z18sub_mod_384_unsafePyPKyS1__param_1,
	.param .b64 _Z18sub_mod_384_unsafePyPKyS1__param_2
)
{
	.reg .b64 	%rd<22>;


	ld.param.u64 	%rd19, [_Z18sub_mod_384_unsafePyPKyS1__param_0];
	ld.param.u64 	%rd20, [_Z18sub_mod_384_unsafePyPKyS1__param_1];
	ld.param.u64 	%rd21, [_Z18sub_mod_384_unsafePyPKyS1__param_2];
	ld.u64 	%rd7, [%rd20];
	ld.u64 	%rd8, [%rd20+8];
	ld.u64 	%rd9, [%rd20+16];
	ld.u64 	%rd10, [%rd20+24];
	ld.u64 	%rd11, [%rd20+32];
	ld.u64 	%rd12, [%rd20+40];
	ld.u64 	%rd13, [%rd21];
	ld.u64 	%rd14, [%rd21+8];
	ld.u64 	%rd15, [%rd21+16];
	ld.u64 	%rd16, [%rd21+24];
	ld.u64 	%rd17, [%rd21+32];
	ld.u64 	%rd18, [%rd21+40];
	// begin inline asm
	sub.cc.u64 %rd1, %rd7, %rd13;
	subc.cc.u64 %rd2, %rd8, %rd14;
	subc.cc.u64 %rd3, %rd9, %rd15;
	subc.cc.u64 %rd4, %rd10, %rd16;
	subc.cc.u64 %rd5, %rd11, %rd17;
	subc.u64 %rd6, %rd12, %rd18;
	// end inline asm
	st.u64 	[%rd19], %rd1;
	st.u64 	[%rd19+8], %rd2;
	st.u64 	[%rd19+16], %rd3;
	st.u64 	[%rd19+24], %rd4;
	st.u64 	[%rd19+32], %rd5;
	st.u64 	[%rd19+40], %rd6;
	ret;

}
	// .globl	_Z18add_mod_384_unsafePyPKyS1_
.visible .func _Z18add_mod_384_unsafePyPKyS1_(
	.param .b64 _Z18add_mod_384_unsafePyPKyS1__param_0,
	.param .b64 _Z18add_mod_384_unsafePyPKyS1__param_1,
	.param .b64 _Z18add_mod_384_unsafePyPKyS1__param_2
)
{
	.reg .b64 	%rd<22>;


	ld.param.u64 	%rd19, [_Z18add_mod_384_unsafePyPKyS1__param_0];
	ld.param.u64 	%rd20, [_Z18add_mod_384_unsafePyPKyS1__param_1];
	ld.param.u64 	%rd21, [_Z18add_mod_384_unsafePyPKyS1__param_2];
	ld.u64 	%rd7, [%rd20];
	ld.u64 	%rd8, [%rd20+8];
	ld.u64 	%rd9, [%rd20+16];
	ld.u64 	%rd10, [%rd20+24];
	ld.u64 	%rd11, [%rd20+32];
	ld.u64 	%rd12, [%rd20+40];
	ld.u64 	%rd13, [%rd21];
	ld.u64 	%rd14, [%rd21+8];
	ld.u64 	%rd15, [%rd21+16];
	ld.u64 	%rd16, [%rd21+24];
	ld.u64 	%rd17, [%rd21+32];
	ld.u64 	%rd18, [%rd21+40];
	// begin inline asm
	add.cc.u64 %rd1, %rd7, %rd13;
	addc.cc.u64 %rd2, %rd8, %rd14;
	addc.cc.u64 %rd3, %rd9, %rd15;
	addc.cc.u64 %rd4, %rd10, %rd16;
	addc.cc.u64 %rd5, %rd11, %rd17;
	addc.u64 %rd6, %rd12, %rd18;
	// end inline asm
	st.u64 	[%rd19], %rd1;
	st.u64 	[%rd19+8], %rd2;
	st.u64 	[%rd19+16], %rd3;
	st.u64 	[%rd19+24], %rd4;
	st.u64 	[%rd19+32], %rd5;
	st.u64 	[%rd19+40], %rd6;
	ret;

}
	// .globl	_Z16div_by_2_mod_384PyPKy
.visible .func _Z16div_by_2_mod_384PyPKy(
	.param .b64 _Z16div_by_2_mod_384PyPKy_param_0,
	.param .b64 _Z16div_by_2_mod_384PyPKy_param_1
)
{
	.reg .b64 	%rd<30>;


	ld.param.u64 	%rd1, [_Z16div_by_2_mod_384PyPKy_param_0];
	ld.param.u64 	%rd2, [_Z16div_by_2_mod_384PyPKy_param_1];
	ld.u64 	%rd3, [%rd2+8];
	shl.b64 	%rd4, %rd3, 63;
	ld.u64 	%rd5, [%rd2];
	shr.u64 	%rd6, %rd5, 1;
	or.b64  	%rd7, %rd6, %rd4;
	st.u64 	[%rd1], %rd7;
	ld.u64 	%rd8, [%rd2+16];
	shl.b64 	%rd9, %rd8, 63;
	ld.u64 	%rd10, [%rd2+8];
	shr.u64 	%rd11, %rd10, 1;
	or.b64  	%rd12, %rd11, %rd9;
	st.u64 	[%rd1+8], %rd12;
	ld.u64 	%rd13, [%rd2+24];
	shl.b64 	%rd14, %rd13, 63;
	ld.u64 	%rd15, [%rd2+16];
	shr.u64 	%rd16, %rd15, 1;
	or.b64  	%rd17, %rd16, %rd14;
	st.u64 	[%rd1+16], %rd17;
	ld.u64 	%rd18, [%rd2+32];
	shl.b64 	%rd19, %rd18, 63;
	ld.u64 	%rd20, [%rd2+24];
	shr.u64 	%rd21, %rd20, 1;
	or.b64  	%rd22, %rd21, %rd19;
	st.u64 	[%rd1+24], %rd22;
	ld.u64 	%rd23, [%rd2+40];
	shl.b64 	%rd24, %rd23, 63;
	ld.u64 	%rd25, [%rd2+32];
	shr.u64 	%rd26, %rd25, 1;
	or.b64  	%rd27, %rd26, %rd24;
	st.u64 	[%rd1+32], %rd27;
	ld.u64 	%rd28, [%rd2+40];
	shr.u64 	%rd29, %rd28, 1;
	st.u64 	[%rd1+40], %rd29;
	ret;

}
	// .globl	_Z12cneg_mod_384PyPKybS1_
.visible .func _Z12cneg_mod_384PyPKybS1_(
	.param .b64 _Z12cneg_mod_384PyPKybS1__param_0,
	.param .b64 _Z12cneg_mod_384PyPKybS1__param_1,
	.param .b32 _Z12cneg_mod_384PyPKybS1__param_2,
	.param .b64 _Z12cneg_mod_384PyPKybS1__param_3
)
{
	.reg .pred 	%p<13>;
	.reg .b16 	%rs<2>;
	.reg .b64 	%rd<76>;


	ld.param.u64 	%rd24, [_Z12cneg_mod_384PyPKybS1__param_0];
	ld.param.s8 	%rs1, [_Z12cneg_mod_384PyPKybS1__param_2];
	ld.param.u64 	%rd25, [_Z12cneg_mod_384PyPKybS1__param_1];
	ld.param.u64 	%rd26, [_Z12cneg_mod_384PyPKybS1__param_3];
	setp.eq.s16 	%p1, %rs1, 0;
	@%p1 bra 	LBB7_14;

	ld.u64 	%rd75, [%rd26];
	ld.u64 	%rd74, [%rd26+8];
	ld.u64 	%rd73, [%rd26+16];
	ld.u64 	%rd72, [%rd26+24];
	ld.u64 	%rd71, [%rd26+32];
	ld.u64 	%rd6, [%rd25+40];
	ld.u64 	%rd70, [%rd26+40];
	setp.lt.u64 	%p2, %rd6, %rd70;
	@%p2 bra 	LBB7_13;

	setp.gt.u64 	%p3, %rd6, %rd70;
	@%p3 bra 	LBB7_12;

	ld.u64 	%rd8, [%rd25+32];
	setp.lt.u64 	%p4, %rd8, %rd71;
	@%p4 bra 	LBB7_13;

	setp.gt.u64 	%p5, %rd8, %rd71;
	@%p5 bra 	LBB7_12;

	ld.u64 	%rd9, [%rd25+24];
	setp.lt.u64 	%p6, %rd9, %rd72;
	@%p6 bra 	LBB7_13;

	setp.gt.u64 	%p7, %rd9, %rd72;
	@%p7 bra 	LBB7_12;

	ld.u64 	%rd10, [%rd25+16];
	setp.lt.u64 	%p8, %rd10, %rd73;
	@%p8 bra 	LBB7_13;

	setp.gt.u64 	%p9, %rd10, %rd73;
	@%p9 bra 	LBB7_12;

	ld.u64 	%rd11, [%rd25+8];
	setp.lt.u64 	%p10, %rd11, %rd74;
	@%p10 bra 	LBB7_13;

	setp.gt.u64 	%p11, %rd11, %rd74;
	@%p11 bra 	LBB7_12;

	ld.u64 	%rd27, [%rd25];
	setp.le.u64 	%p12, %rd27, %rd75;
	@%p12 bra 	LBB7_13;

LBB7_12:
	// begin inline asm
	add.cc.u64 %rd75, %rd75, %rd75;
	addc.cc.u64 %rd74, %rd74, %rd74;
	addc.cc.u64 %rd73, %rd73, %rd73;
	addc.cc.u64 %rd72, %rd72, %rd72;
	addc.cc.u64 %rd71, %rd71, %rd71;
	addc.u64 %rd70, %rd70, %rd70;
	// end inline asm

LBB7_13:
	ld.u64 	%rd58, [%rd25];
	ld.u64 	%rd59, [%rd25+8];
	ld.u64 	%rd60, [%rd25+16];
	ld.u64 	%rd61, [%rd25+24];
	ld.u64 	%rd62, [%rd25+32];
	// begin inline asm
	sub.cc.u64 %rd46, %rd75, %rd58;
	subc.cc.u64 %rd47, %rd74, %rd59;
	subc.cc.u64 %rd48, %rd73, %rd60;
	subc.cc.u64 %rd49, %rd72, %rd61;
	subc.cc.u64 %rd50, %rd71, %rd62;
	subc.u64 %rd51, %rd70, %rd6;
	// end inline asm
	st.u64 	[%rd24], %rd46;
	st.u64 	[%rd24+8], %rd47;
	st.u64 	[%rd24+16], %rd48;
	st.u64 	[%rd24+24], %rd49;
	st.u64 	[%rd24+32], %rd50;
	st.u64 	[%rd24+40], %rd51;
	bra.uni 	LBB7_15;

LBB7_14:
	ld.u64 	%rd64, [%rd25];
	st.u64 	[%rd24], %rd64;
	ld.u64 	%rd65, [%rd25+8];
	st.u64 	[%rd24+8], %rd65;
	ld.u64 	%rd66, [%rd25+16];
	st.u64 	[%rd24+16], %rd66;
	ld.u64 	%rd67, [%rd25+24];
	st.u64 	[%rd24+24], %rd67;
	ld.u64 	%rd68, [%rd25+32];
	st.u64 	[%rd24+32], %rd68;
	ld.u64 	%rd69, [%rd25+40];
	st.u64 	[%rd24+40], %rd69;

LBB7_15:
	ret;

}

