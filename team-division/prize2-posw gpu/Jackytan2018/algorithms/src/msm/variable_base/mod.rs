// Copyright (C) 2019-2022 Aleo Systems Inc.
// This file is part of the snarkVM library.

// The snarkVM library is free software: you can redistribute it and/or modify
// it under the terms of the GNU General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.

// The snarkVM library is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
// GNU General Public License for more details.

// You should have received a copy of the GNU General Public License
// along with the snarkVM library. If not, see <https://www.gnu.org/licenses/>.

pub mod batched;
pub mod standard;

#[cfg(all(feature = "cuda", target_arch = "x86_64"))]
pub mod cuda;

#[cfg(target_arch = "x86_64")]
pub mod prefetch;

use snarkvm_curves::{bls12_377::G1Affine, traits::AffineCurve};
use snarkvm_fields::PrimeField;

use std::sync::Mutex;
use crate::ars_config::*; 

lazy_static::lazy_static!{
	static ref MSM_BRANCH_COUNT:Mutex<i32> = Mutex::new(0);
}

use core::any::TypeId;

#[cfg(all(feature = "cuda", target_arch = "x86_64"))]
use core::sync::atomic::{AtomicBool, Ordering};

#[cfg(all(feature = "cuda", target_arch = "x86_64"))]
static HAS_CUDA_FAILED: AtomicBool = AtomicBool::new(false);

pub struct VariableBase;

impl VariableBase {
    pub fn msm<G: AffineCurve>(bases: &[G], scalars: &[<G::ScalarField as PrimeField>::BigInteger]) -> G::Projective {
        if *MSM_BRANCH_COUNT.lock().unwrap() >= CONFIG.msm_branch_max {
			*MSM_BRANCH_COUNT.lock().unwrap() = 0;
		}
        if TypeId::of::<G>() == TypeId::of::<G1Affine>() {
			if scalars.len() > 20000 || scalars.len() <= 4 {
                if *MSM_BRANCH_COUNT.lock().unwrap() < CONFIG.msm_branch_limit {
                    *MSM_BRANCH_COUNT.lock().unwrap() += 1;
                    #[cfg(all(feature = "cuda", target_arch = "x86_64"))]
                    if !HAS_CUDA_FAILED.load(Ordering::SeqCst) {
                        match cuda::msm_cuda(bases, scalars, 0) {
                            Ok(x) => return x,
                            Err(_e) => {
                                HAS_CUDA_FAILED.store(true, Ordering::SeqCst);
                                eprintln!("CUDA failed, moving to the next MSM method");
                            }
                        }
                    }
                    batched::msm(bases, scalars)
                } else {
                    *MSM_BRANCH_COUNT.lock().unwrap() += 1;
                    batched::msm(bases, scalars)
                }
            }else{
                batched::msm(bases, scalars)
            }
        }        
        else {
            standard::msm(bases, scalars)
        }
    }   
    pub fn ars_msm<G: AffineCurve>(bases: &[G], scalars: &[<G::ScalarField as PrimeField>::BigInteger], round: usize,) -> G::Projective {
        if *MSM_BRANCH_COUNT.lock().unwrap() >= CONFIG.msm_branch_max {
			*MSM_BRANCH_COUNT.lock().unwrap() = 0;
		}
        if TypeId::of::<G>() == TypeId::of::<G1Affine>() {
			if scalars.len() > 20000 || scalars.len() <= 4 {
                if *MSM_BRANCH_COUNT.lock().unwrap() < CONFIG.msm_branch_limit {
                    *MSM_BRANCH_COUNT.lock().unwrap() += 1;
                    #[cfg(all(feature = "cuda", target_arch = "x86_64"))]
                    if !HAS_CUDA_FAILED.load(Ordering::SeqCst) {
                        match cuda::msm_cuda(bases, scalars, round) {
                            Ok(x) => return x,
                            Err(_e) => {
                                HAS_CUDA_FAILED.store(true, Ordering::SeqCst);
                                eprintln!("CUDA failed, moving to the next MSM method");
                            }
                        }
                    }
                    batched::msm(bases, scalars)
                } else {
                    *MSM_BRANCH_COUNT.lock().unwrap() += 1;
                    batched::msm(bases, scalars)
                }
            }else{
                batched::msm(bases, scalars)
            }
        }else {
            standard::msm(bases, scalars)
        }
    }    

    #[cfg(test)]
    fn msm_naive<G: AffineCurve>(bases: &[G], scalars: &[<G::ScalarField as PrimeField>::BigInteger]) -> G::Projective {
        use itertools::Itertools;
        use snarkvm_utilities::BitIteratorBE;

        bases.iter().zip_eq(scalars).map(|(base, scalar)| base.mul_bits(BitIteratorBE::new(*scalar))).sum()
    }

    #[cfg(test)]
    fn msm_naive_parallel<G: AffineCurve>(
        bases: &[G],
        scalars: &[<G::ScalarField as PrimeField>::BigInteger],
    ) -> G::Projective {
        use rayon::prelude::*;
        use snarkvm_utilities::BitIteratorBE;

        bases.par_iter().zip_eq(scalars).map(|(base, scalar)| base.mul_bits(BitIteratorBE::new(*scalar))).sum()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use snarkvm_curves::bls12_377::{Fr, G1Affine};
    use snarkvm_fields::PrimeField;
    use snarkvm_utilities::rand::test_rng;

    use rand_xorshift::XorShiftRng;

    fn create_scalar_bases<G: AffineCurve<ScalarField = F>, F: PrimeField>(
        rng: &mut XorShiftRng,
        size: usize,
    ) -> (Vec<G>, Vec<F::BigInteger>) {
        let bases = (0..size).map(|_| G::rand(rng)).collect::<Vec<_>>();
        let scalars = (0..size).map(|_| F::rand(rng).to_repr()).collect::<Vec<_>>();
        (bases, scalars)
    }

    #[test]
    fn test_msm() {
        let mut rng = test_rng();
        let (bases, scalars) = create_scalar_bases::<G1Affine, Fr>(&mut rng, 1000);

        let naive_a = VariableBase::msm_naive(bases.as_slice(), scalars.as_slice());
        let naive_b = VariableBase::msm_naive_parallel(bases.as_slice(), scalars.as_slice());
        assert_eq!(naive_a, naive_b);

        let candidate = standard::msm(bases.as_slice(), scalars.as_slice());
        assert_eq!(naive_a, candidate);

        let candidate = batched::msm(bases.as_slice(), scalars.as_slice());
        assert_eq!(naive_a, candidate);
    }

    #[cfg(all(feature = "cuda", target_arch = "x86_64"))]
    #[test]
    fn test_msm_cuda() {
        let mut rng = test_rng();
        for _ in 0..100 {
            let (bases, scalars) = create_scalar_bases::<G1Affine, Fr>(&mut rng, 1 << 10);
            let rust = standard::msm(bases.as_slice(), scalars.as_slice());

            let cuda = cuda::msm_cuda(bases.as_slice(), scalars.as_slice()).unwrap();
            assert_eq!(rust, cuda);
        }
    }
}